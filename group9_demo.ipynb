{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 1.75656849\n",
      "Iteration 2, loss = 1.25847158\n",
      "Iteration 3, loss = 0.93674447\n",
      "Iteration 4, loss = 0.78250504\n",
      "Iteration 5, loss = 0.45239019\n",
      "Iteration 6, loss = 0.64860064\n",
      "Iteration 7, loss = 0.89148949\n",
      "Iteration 8, loss = 0.89628426\n",
      "Iteration 9, loss = 0.68436507\n",
      "Iteration 10, loss = 0.44553033\n",
      "Iteration 11, loss = 0.31135963\n",
      "Iteration 12, loss = 0.68488940\n",
      "Iteration 13, loss = 0.51501239\n",
      "Iteration 14, loss = 0.39446852\n",
      "Iteration 15, loss = 0.23907090\n",
      "Iteration 16, loss = 0.17072825\n",
      "Iteration 17, loss = 0.12355390\n",
      "Iteration 18, loss = 0.11464844\n",
      "Iteration 19, loss = 0.11262966\n",
      "Iteration 20, loss = 0.12701084\n",
      "Iteration 21, loss = 0.13729304\n",
      "Iteration 22, loss = 0.12772886\n",
      "Iteration 23, loss = 0.11838175\n",
      "Iteration 24, loss = 0.13035640\n",
      "Iteration 25, loss = 0.10827780\n",
      "Iteration 26, loss = 0.11274951\n",
      "Iteration 27, loss = 0.10605618\n",
      "Iteration 28, loss = 0.11502779\n",
      "Iteration 29, loss = 0.10428568\n",
      "Iteration 30, loss = 0.10945139\n",
      "Iteration 31, loss = 0.11026311\n",
      "Iteration 32, loss = 0.11727694\n",
      "Iteration 33, loss = 0.10225128\n",
      "Iteration 34, loss = 0.12896392\n",
      "Iteration 35, loss = 0.14145606\n",
      "Iteration 36, loss = 0.11628596\n",
      "Iteration 37, loss = 0.11740222\n",
      "Iteration 38, loss = 0.10909990\n",
      "Iteration 39, loss = 0.11621320\n",
      "Iteration 40, loss = 0.10414945\n",
      "Iteration 41, loss = 0.11317331\n",
      "Iteration 42, loss = 0.13491453\n",
      "Iteration 43, loss = 0.10236808\n",
      "Iteration 44, loss = 0.10647981\n",
      "Iteration 45, loss = 0.11348572\n",
      "Iteration 46, loss = 0.11327577\n",
      "Iteration 47, loss = 0.11642363\n",
      "Iteration 48, loss = 0.10567918\n",
      "Iteration 49, loss = 0.11717040\n",
      "Iteration 50, loss = 0.11254234\n",
      "Iteration 51, loss = 0.12666509\n",
      "Iteration 52, loss = 0.17821987\n",
      "Iteration 53, loss = 0.17343338\n",
      "Iteration 54, loss = 0.11788532\n",
      "Iteration 55, loss = 0.12109402\n",
      "Iteration 56, loss = 0.21629089\n",
      "Iteration 57, loss = 0.11993994\n",
      "Iteration 58, loss = 0.15310208\n",
      "Iteration 59, loss = 0.11563634\n",
      "Iteration 60, loss = 0.19141454\n",
      "Iteration 61, loss = 0.11479919\n",
      "Iteration 62, loss = 0.11390773\n",
      "Iteration 63, loss = 0.12521800\n",
      "Iteration 64, loss = 0.11009122\n",
      "Iteration 65, loss = 0.11149192\n",
      "Iteration 66, loss = 0.11213767\n",
      "Iteration 67, loss = 0.12551580\n",
      "Iteration 68, loss = 0.11092979\n",
      "Iteration 69, loss = 0.10179396\n",
      "Iteration 70, loss = 0.13986536\n",
      "Iteration 71, loss = 0.16372085\n",
      "Iteration 72, loss = 0.20091362\n",
      "Iteration 73, loss = 0.14637531\n",
      "Iteration 74, loss = 0.18975628\n",
      "Iteration 75, loss = 0.17544829\n",
      "Iteration 76, loss = 0.18170796\n",
      "Iteration 77, loss = 0.16904629\n",
      "Iteration 78, loss = 0.11079416\n",
      "Iteration 79, loss = 0.10384770\n",
      "Iteration 80, loss = 0.18105286\n",
      "Iteration 81, loss = 0.10944538\n",
      "Iteration 82, loss = 0.11526464\n",
      "Iteration 83, loss = 0.11429518\n",
      "Iteration 84, loss = 0.11424629\n",
      "Iteration 85, loss = 0.12093149\n",
      "Iteration 86, loss = 0.15715484\n",
      "Iteration 87, loss = 0.13849136\n",
      "Iteration 88, loss = 0.13720956\n",
      "Iteration 89, loss = 0.12433015\n",
      "Iteration 90, loss = 0.11532161\n",
      "Iteration 91, loss = 0.10824266\n",
      "Iteration 92, loss = 0.11036803\n",
      "Iteration 93, loss = 0.10323640\n",
      "Iteration 94, loss = 0.10216500\n",
      "Iteration 95, loss = 0.11020749\n",
      "Iteration 96, loss = 0.13093311\n",
      "Iteration 97, loss = 0.11117947\n",
      "Iteration 98, loss = 0.10470604\n",
      "Iteration 99, loss = 0.10621403\n",
      "Iteration 100, loss = 0.11222777\n",
      "Iteration 101, loss = 0.10726725\n",
      "Iteration 102, loss = 0.10601578\n",
      "Iteration 103, loss = 0.11270915\n",
      "Iteration 104, loss = 0.10520780\n",
      "Iteration 105, loss = 0.11471660\n",
      "Iteration 106, loss = 0.12334927\n",
      "Iteration 107, loss = 0.11765983\n",
      "Iteration 108, loss = 0.13354705\n",
      "Iteration 109, loss = 0.11125764\n",
      "Iteration 110, loss = 0.10806806\n",
      "Iteration 111, loss = 0.10527253\n",
      "Iteration 112, loss = 0.10581755\n",
      "Iteration 113, loss = 0.15802201\n",
      "Iteration 114, loss = 0.11067681\n",
      "Iteration 115, loss = 0.12658905\n",
      "Iteration 116, loss = 0.13024749\n",
      "Iteration 117, loss = 0.13256927\n",
      "Iteration 118, loss = 0.16250281\n",
      "Iteration 119, loss = 0.21709855\n",
      "Iteration 120, loss = 0.12942375\n",
      "Iteration 121, loss = 0.11023638\n",
      "Iteration 122, loss = 0.12218752\n",
      "Iteration 123, loss = 0.12894032\n",
      "Iteration 124, loss = 0.14386636\n",
      "Iteration 125, loss = 0.12503335\n",
      "Iteration 126, loss = 0.12294480\n",
      "Iteration 127, loss = 0.10999974\n",
      "Iteration 128, loss = 0.12200389\n",
      "Iteration 129, loss = 0.12008846\n",
      "Iteration 130, loss = 0.11024588\n",
      "Iteration 131, loss = 0.10901585\n",
      "Iteration 132, loss = 0.10383752\n",
      "Iteration 133, loss = 0.10920479\n",
      "Iteration 134, loss = 0.10849638\n",
      "Iteration 135, loss = 0.10470396\n",
      "Iteration 136, loss = 0.10216516\n",
      "Iteration 137, loss = 0.10443117\n",
      "Iteration 138, loss = 0.10438306\n",
      "Iteration 139, loss = 0.11399948\n",
      "Iteration 140, loss = 0.10614487\n",
      "Iteration 141, loss = 0.10510596\n",
      "Iteration 142, loss = 0.10140066\n",
      "Iteration 143, loss = 0.11837334\n",
      "Iteration 144, loss = 0.12763601\n",
      "Iteration 145, loss = 0.11659506\n",
      "Iteration 146, loss = 0.13917944\n",
      "Iteration 147, loss = 0.10244341\n",
      "Iteration 148, loss = 0.10987233\n",
      "Iteration 149, loss = 0.10469120\n",
      "Iteration 150, loss = 0.10685057\n",
      "Iteration 151, loss = 0.13066747\n",
      "Iteration 152, loss = 0.13855754\n",
      "Iteration 153, loss = 0.13189990\n",
      "Iteration 154, loss = 0.11885149\n",
      "Iteration 155, loss = 0.10606975\n",
      "Iteration 156, loss = 0.10343114\n",
      "Iteration 157, loss = 0.11379860\n",
      "Iteration 158, loss = 0.15337284\n",
      "Iteration 159, loss = 0.13168641\n",
      "Iteration 160, loss = 0.11065800\n",
      "Iteration 161, loss = 0.12520094\n",
      "Iteration 162, loss = 0.12601124\n",
      "Iteration 163, loss = 0.11317822\n",
      "Iteration 164, loss = 0.11037171\n",
      "Iteration 165, loss = 0.11164607\n",
      "Iteration 166, loss = 0.15397133\n",
      "Iteration 167, loss = 0.15994972\n",
      "Iteration 168, loss = 0.12268129\n",
      "Iteration 169, loss = 0.20455459\n",
      "Iteration 170, loss = 0.14019968\n",
      "Iteration 171, loss = 0.18926024\n",
      "Iteration 172, loss = 0.11835671\n",
      "Iteration 173, loss = 0.12361765\n",
      "Iteration 174, loss = 0.14248573\n",
      "Iteration 175, loss = 0.13002291\n",
      "Iteration 176, loss = 0.11858727\n",
      "Iteration 177, loss = 0.11105275\n",
      "Iteration 178, loss = 0.11514967\n",
      "Iteration 179, loss = 0.11169458\n",
      "Iteration 180, loss = 0.11366814\n",
      "Iteration 181, loss = 0.13409495\n",
      "Iteration 182, loss = 0.12222463\n",
      "Iteration 183, loss = 0.13712096\n",
      "Iteration 184, loss = 0.22847682\n",
      "Iteration 185, loss = 3.71223842\n",
      "Iteration 186, loss = 6.53524208\n",
      "Iteration 187, loss = 4.58767444\n",
      "Iteration 188, loss = 1.51618467\n",
      "Iteration 189, loss = 1.52279454\n",
      "Iteration 190, loss = 1.26583882\n",
      "Iteration 191, loss = 2.90485079\n",
      "Iteration 192, loss = 3.81016211\n",
      "Iteration 193, loss = 2.07100006\n",
      "Iteration 194, loss = 1.65612006\n",
      "Iteration 195, loss = 1.25083772\n",
      "Iteration 196, loss = 1.03478112\n",
      "Iteration 197, loss = 0.82132863\n",
      "Iteration 198, loss = 0.51145929\n",
      "Iteration 199, loss = 0.55564429\n",
      "Iteration 200, loss = 0.42572999\n",
      "Iteration 201, loss = 0.52263645\n",
      "Iteration 202, loss = 0.59949832\n",
      "Iteration 203, loss = 0.34842931\n",
      "Iteration 204, loss = 0.73650139\n",
      "Iteration 205, loss = 1.11640000\n",
      "Iteration 206, loss = 0.90347493\n",
      "Iteration 207, loss = 0.65032746\n",
      "Iteration 208, loss = 0.39289926\n",
      "Iteration 209, loss = 0.41789600\n",
      "Iteration 210, loss = 0.31372608\n",
      "Iteration 211, loss = 0.31648474\n",
      "Iteration 212, loss = 0.39407020\n",
      "Iteration 213, loss = 0.30254073\n",
      "Iteration 214, loss = 0.24099846\n",
      "Iteration 215, loss = 0.40060674\n",
      "Iteration 216, loss = 0.61849759\n",
      "Iteration 217, loss = 0.61691806\n",
      "Iteration 218, loss = 0.47453152\n",
      "Iteration 219, loss = 0.24630783\n",
      "Iteration 220, loss = 0.38680436\n",
      "Iteration 221, loss = 0.39447385\n",
      "Iteration 222, loss = 0.43794775\n",
      "Iteration 223, loss = 0.33952280\n",
      "Iteration 224, loss = 0.22822411\n",
      "Iteration 225, loss = 0.21216999\n",
      "Iteration 226, loss = 0.15878377\n",
      "Iteration 227, loss = 0.19107433\n",
      "Iteration 228, loss = 0.19423438\n",
      "Iteration 229, loss = 0.17748571\n",
      "Iteration 230, loss = 0.21203924\n",
      "Iteration 231, loss = 0.18157293\n",
      "Iteration 232, loss = 0.13257437\n",
      "Iteration 233, loss = 0.29612125\n",
      "Iteration 234, loss = 0.34838678\n",
      "Iteration 235, loss = 0.36844787\n",
      "Iteration 236, loss = 0.28561520\n",
      "Iteration 237, loss = 0.19149596\n",
      "Iteration 238, loss = 0.22953448\n",
      "Iteration 239, loss = 0.19952820\n",
      "Iteration 240, loss = 0.20366803\n",
      "Iteration 241, loss = 0.14986335\n",
      "Iteration 242, loss = 0.14139705\n",
      "Iteration 243, loss = 0.13130033\n",
      "Iteration 244, loss = 0.14008033\n",
      "Iteration 245, loss = 0.13528862\n",
      "Iteration 246, loss = 0.15043834\n",
      "Iteration 247, loss = 0.12901745\n",
      "Iteration 248, loss = 0.12074134\n",
      "Iteration 249, loss = 0.12328365\n",
      "Iteration 250, loss = 0.14691522\n",
      "Iteration 251, loss = 0.18457011\n",
      "Iteration 252, loss = 0.21690106\n",
      "Iteration 253, loss = 0.18538980\n",
      "Iteration 254, loss = 0.24050557\n",
      "Iteration 255, loss = 0.31718636\n",
      "Iteration 256, loss = 0.21921009\n",
      "Iteration 257, loss = 0.14363237\n",
      "Iteration 258, loss = 0.17211887\n",
      "Iteration 259, loss = 0.12125549\n",
      "Iteration 260, loss = 0.13032353\n",
      "Iteration 261, loss = 0.19934272\n",
      "Iteration 262, loss = 0.16287524\n",
      "Iteration 263, loss = 0.13449135\n",
      "Iteration 264, loss = 0.12806377\n",
      "Iteration 265, loss = 0.15812801\n",
      "Iteration 266, loss = 0.13659291\n",
      "Iteration 267, loss = 0.11517399\n",
      "Iteration 268, loss = 0.10717898\n",
      "Iteration 269, loss = 0.11501165\n",
      "Iteration 270, loss = 0.12079848\n",
      "Iteration 271, loss = 0.12987443\n",
      "Iteration 272, loss = 0.10779128\n",
      "Iteration 273, loss = 0.12287454\n",
      "Iteration 274, loss = 0.11716871\n",
      "Iteration 275, loss = 0.12311012\n",
      "Iteration 276, loss = 0.11512541\n",
      "Iteration 277, loss = 0.11896859\n",
      "Iteration 278, loss = 0.12548389\n",
      "Iteration 279, loss = 0.10138106\n",
      "Iteration 280, loss = 0.10842141\n",
      "Iteration 281, loss = 0.10688964\n",
      "Iteration 282, loss = 0.11284794\n",
      "Iteration 283, loss = 0.10797870\n",
      "Iteration 284, loss = 0.12335048\n",
      "Iteration 285, loss = 0.11026517\n",
      "Iteration 286, loss = 0.11461017\n",
      "Iteration 287, loss = 0.11071807\n",
      "Iteration 288, loss = 0.10596141\n",
      "Iteration 289, loss = 0.11108333\n",
      "Iteration 290, loss = 0.10202994\n",
      "Iteration 291, loss = 0.11411487\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 292, loss = 0.18191160\n",
      "Iteration 293, loss = 0.10791868\n",
      "Iteration 294, loss = 0.12641805\n",
      "Iteration 295, loss = 0.14012531\n",
      "Iteration 296, loss = 0.11980537\n",
      "Iteration 297, loss = 0.13431253\n",
      "Iteration 298, loss = 0.10277967\n",
      "Iteration 299, loss = 0.12027281\n",
      "Iteration 300, loss = 0.12182401\n",
      "Iteration 301, loss = 0.11475939\n",
      "Iteration 302, loss = 0.12103165\n",
      "Iteration 303, loss = 0.11193683\n",
      "Iteration 304, loss = 0.13825747\n",
      "Iteration 305, loss = 0.17316928\n",
      "Iteration 306, loss = 0.11893260\n",
      "Iteration 307, loss = 0.12749599\n",
      "Iteration 308, loss = 0.10906635\n",
      "Iteration 309, loss = 0.13077741\n",
      "Iteration 310, loss = 0.12849297\n",
      "Iteration 311, loss = 0.14091106\n",
      "Iteration 312, loss = 0.16772176\n",
      "Iteration 313, loss = 0.14990077\n",
      "Iteration 314, loss = 0.10390204\n",
      "Iteration 315, loss = 0.13507221\n",
      "Iteration 316, loss = 0.12161292\n",
      "Iteration 317, loss = 0.12115132\n",
      "Iteration 318, loss = 0.11935144\n",
      "Iteration 319, loss = 0.10019029\n",
      "Iteration 320, loss = 0.11144573\n",
      "Iteration 321, loss = 0.10835374\n",
      "Iteration 322, loss = 0.11465040\n",
      "Iteration 323, loss = 0.11509497\n",
      "Iteration 324, loss = 0.11407992\n",
      "Iteration 325, loss = 0.12902781\n",
      "Iteration 326, loss = 0.16961232\n",
      "Iteration 327, loss = 0.13233759\n",
      "Iteration 328, loss = 0.11739827\n",
      "Iteration 329, loss = 0.13773619\n",
      "Iteration 330, loss = 0.12361094\n",
      "Iteration 331, loss = 0.11706166\n",
      "Iteration 332, loss = 0.11359440\n",
      "Iteration 333, loss = 0.11888893\n",
      "Iteration 334, loss = 0.13440270\n",
      "Iteration 335, loss = 0.12947096\n",
      "Iteration 336, loss = 0.11857106\n",
      "Iteration 337, loss = 0.12593033\n",
      "Iteration 338, loss = 0.11722701\n",
      "Iteration 339, loss = 0.12007455\n",
      "Iteration 340, loss = 0.11116804\n",
      "Iteration 341, loss = 0.10830296\n",
      "Iteration 342, loss = 0.11321176\n",
      "Iteration 343, loss = 0.12258538\n",
      "Iteration 344, loss = 0.13871699\n",
      "Iteration 345, loss = 0.13332803\n",
      "Iteration 346, loss = 0.12967713\n",
      "Iteration 347, loss = 0.14315277\n",
      "Iteration 348, loss = 0.10805072\n",
      "Iteration 349, loss = 0.12048190\n",
      "Iteration 350, loss = 0.13066923\n",
      "Iteration 351, loss = 0.15173512\n",
      "Iteration 352, loss = 0.13557707\n",
      "Iteration 353, loss = 0.12073338\n",
      "Iteration 354, loss = 0.12081722\n",
      "Iteration 355, loss = 0.12608034\n",
      "Iteration 356, loss = 0.11466045\n",
      "Iteration 357, loss = 0.15343224\n",
      "Iteration 358, loss = 0.23301347\n",
      "Iteration 359, loss = 0.19573941\n",
      "Iteration 360, loss = 0.13562735\n",
      "Iteration 361, loss = 0.14173931\n",
      "Iteration 362, loss = 0.15447243\n",
      "Iteration 363, loss = 0.13447468\n",
      "Iteration 364, loss = 0.11703950\n",
      "Iteration 365, loss = 0.11626833\n",
      "Iteration 366, loss = 0.12836248\n",
      "Iteration 367, loss = 0.11659258\n",
      "Iteration 368, loss = 0.12113139\n",
      "Iteration 369, loss = 0.11326233\n",
      "Iteration 370, loss = 0.11156499\n",
      "Iteration 371, loss = 0.11795334\n",
      "Iteration 372, loss = 0.10851908\n",
      "Iteration 373, loss = 0.12312430\n",
      "Iteration 374, loss = 0.14617629\n",
      "Iteration 375, loss = 0.13715806\n",
      "Iteration 376, loss = 0.14941839\n",
      "Iteration 377, loss = 0.23597446\n",
      "Iteration 378, loss = 0.22965119\n",
      "Iteration 379, loss = 0.15154721\n",
      "Iteration 380, loss = 0.10064552\n",
      "Iteration 381, loss = 0.13021587\n",
      "Iteration 382, loss = 0.14960085\n",
      "Iteration 383, loss = 0.12289976\n",
      "Iteration 384, loss = 0.13136074\n",
      "Iteration 385, loss = 0.10871077\n",
      "Iteration 386, loss = 0.10924704\n",
      "Iteration 387, loss = 0.11274936\n",
      "Iteration 388, loss = 0.10955428\n",
      "Iteration 389, loss = 0.11806400\n",
      "Iteration 390, loss = 0.11084318\n",
      "Iteration 391, loss = 0.12249124\n",
      "Iteration 392, loss = 0.10848947\n",
      "Iteration 393, loss = 0.10599278\n",
      "Iteration 394, loss = 0.11203013\n",
      "Iteration 395, loss = 0.11370607\n",
      "Iteration 396, loss = 0.11861399\n",
      "Iteration 397, loss = 0.12160256\n",
      "Iteration 398, loss = 0.14947112\n",
      "Iteration 399, loss = 0.14660850\n",
      "Iteration 400, loss = 0.16299830\n",
      "Iteration 401, loss = 0.13263796\n",
      "Iteration 402, loss = 0.12579496\n",
      "Iteration 403, loss = 0.13403045\n",
      "Iteration 404, loss = 0.10804719\n",
      "Iteration 405, loss = 0.12836437\n",
      "Iteration 406, loss = 0.13885461\n",
      "Iteration 407, loss = 0.12383606\n",
      "Iteration 408, loss = 0.12098223\n",
      "Iteration 409, loss = 0.12202295\n",
      "Iteration 410, loss = 0.11429437\n",
      "Iteration 411, loss = 0.11438443\n",
      "Iteration 412, loss = 0.11294972\n",
      "Iteration 413, loss = 0.10039900\n",
      "Iteration 414, loss = 0.12580425\n",
      "Iteration 415, loss = 0.12112316\n",
      "Iteration 416, loss = 0.10724292\n",
      "Iteration 417, loss = 0.11358955\n",
      "Iteration 418, loss = 0.11683731\n",
      "Iteration 419, loss = 0.10536943\n",
      "Iteration 420, loss = 0.11688257\n",
      "Iteration 421, loss = 0.12322860\n",
      "Iteration 422, loss = 0.10693956\n",
      "Iteration 423, loss = 0.10611613\n",
      "Iteration 424, loss = 0.10964242\n",
      "Iteration 425, loss = 0.10623811\n",
      "Iteration 426, loss = 0.10983004\n",
      "Iteration 427, loss = 0.10871396\n",
      "Iteration 428, loss = 0.12510572\n",
      "Iteration 429, loss = 0.13572256\n",
      "Iteration 430, loss = 0.14248482\n",
      "Iteration 431, loss = 0.12323521\n",
      "Iteration 432, loss = 0.10233264\n",
      "Iteration 433, loss = 0.10825920\n",
      "Iteration 434, loss = 0.10931260\n",
      "Iteration 435, loss = 0.10315011\n",
      "Iteration 436, loss = 0.10685009\n",
      "Iteration 437, loss = 0.10389936\n",
      "Iteration 438, loss = 0.11382935\n",
      "Iteration 439, loss = 0.11751229\n",
      "Iteration 440, loss = 0.10644147\n",
      "Iteration 441, loss = 0.12355803\n",
      "Iteration 442, loss = 0.11678804\n",
      "Iteration 443, loss = 0.11405685\n",
      "Iteration 444, loss = 0.11423768\n",
      "Iteration 445, loss = 0.10583801\n",
      "Iteration 446, loss = 0.10468866\n",
      "Iteration 447, loss = 0.11743416\n",
      "Iteration 448, loss = 0.10892239\n",
      "Iteration 449, loss = 0.10584074\n",
      "Iteration 450, loss = 0.10592832\n",
      "Iteration 451, loss = 0.12046555\n",
      "Iteration 452, loss = 0.10985686\n",
      "Iteration 453, loss = 0.10567589\n",
      "Iteration 454, loss = 0.10964298\n",
      "Iteration 455, loss = 0.11139149\n",
      "Iteration 456, loss = 0.10895857\n",
      "Iteration 457, loss = 0.10419233\n",
      "Iteration 458, loss = 0.12768376\n",
      "Iteration 459, loss = 0.12103372\n",
      "Iteration 460, loss = 0.10971614\n",
      "Iteration 461, loss = 0.10750629\n",
      "Iteration 462, loss = 0.11346794\n",
      "Iteration 463, loss = 0.12292386\n",
      "Iteration 464, loss = 0.15108157\n",
      "Iteration 465, loss = 0.13401933\n",
      "Iteration 466, loss = 0.11205765\n",
      "Iteration 467, loss = 0.12804529\n",
      "Iteration 468, loss = 0.12506106\n",
      "Iteration 469, loss = 0.11138482\n",
      "Iteration 470, loss = 0.10350406\n",
      "Iteration 471, loss = 0.12874536\n",
      "Iteration 472, loss = 0.10442259\n",
      "Iteration 473, loss = 0.14152350\n",
      "Iteration 474, loss = 0.13855713\n",
      "Iteration 475, loss = 0.10433358\n",
      "Iteration 476, loss = 0.10738203\n",
      "Iteration 477, loss = 0.11163667\n",
      "Iteration 478, loss = 0.10639591\n",
      "Iteration 479, loss = 0.13202313\n",
      "Iteration 480, loss = 0.11817704\n",
      "Iteration 481, loss = 0.11113059\n",
      "Iteration 482, loss = 0.12479275\n",
      "Iteration 483, loss = 0.13255210\n",
      "Iteration 484, loss = 0.10979610\n",
      "Iteration 485, loss = 0.11674661\n",
      "Iteration 486, loss = 0.12813817\n",
      "Iteration 487, loss = 0.11291344\n",
      "Iteration 488, loss = 0.11851516\n",
      "Iteration 489, loss = 0.11340456\n",
      "Iteration 490, loss = 0.11733767\n",
      "Iteration 491, loss = 0.13357348\n",
      "Iteration 492, loss = 0.15017091\n",
      "Iteration 493, loss = 0.15839204\n",
      "Iteration 494, loss = 0.14104815\n",
      "Iteration 495, loss = 0.15147401\n",
      "Iteration 496, loss = 0.12158503\n",
      "Iteration 497, loss = 0.11706467\n",
      "Iteration 498, loss = 0.12715560\n",
      "Iteration 499, loss = 0.11697085\n",
      "Iteration 500, loss = 0.14148822\n",
      "Iteration 501, loss = 0.12847174\n",
      "Iteration 502, loss = 0.13236835\n",
      "Iteration 503, loss = 0.11466238\n",
      "Iteration 504, loss = 0.12712716\n",
      "Iteration 505, loss = 0.12986179\n",
      "Iteration 506, loss = 0.10530420\n",
      "Iteration 507, loss = 0.11684997\n",
      "Iteration 508, loss = 0.11250360\n",
      "Iteration 509, loss = 0.14237728\n",
      "Iteration 510, loss = 0.13184121\n",
      "Iteration 511, loss = 0.13061043\n",
      "Iteration 512, loss = 0.12841494\n",
      "Iteration 513, loss = 0.11431257\n",
      "Iteration 514, loss = 0.13066011\n",
      "Iteration 515, loss = 0.11149378\n",
      "Iteration 516, loss = 0.10234460\n",
      "Iteration 517, loss = 0.11040852\n",
      "Iteration 518, loss = 0.11403030\n",
      "Iteration 519, loss = 0.10498115\n",
      "Iteration 520, loss = 0.10497086\n",
      "Iteration 521, loss = 0.10804192\n",
      "Iteration 522, loss = 0.10278685\n",
      "Iteration 523, loss = 0.10101149\n",
      "Iteration 524, loss = 0.10269098\n",
      "Iteration 525, loss = 0.10379143\n",
      "Iteration 526, loss = 0.10839135\n",
      "Iteration 527, loss = 0.10775529\n",
      "Iteration 528, loss = 0.11738264\n",
      "Iteration 529, loss = 0.11912977\n",
      "Iteration 530, loss = 0.11563131\n",
      "Iteration 531, loss = 0.11156922\n",
      "Iteration 532, loss = 0.10930502\n",
      "Iteration 533, loss = 0.11806945\n",
      "Iteration 534, loss = 0.11248441\n",
      "Iteration 535, loss = 0.10926569\n",
      "Iteration 536, loss = 0.12411182\n",
      "Iteration 537, loss = 0.11231681\n",
      "Iteration 538, loss = 0.13839807\n",
      "Iteration 539, loss = 0.18267268\n",
      "Iteration 540, loss = 0.26278553\n",
      "Iteration 541, loss = 0.29717102\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 542, loss = 0.32991325\n",
      "Iteration 543, loss = 0.16701026\n",
      "Iteration 544, loss = 0.16167456\n",
      "Iteration 545, loss = 0.19613450\n",
      "Iteration 546, loss = 0.19705538\n",
      "Iteration 547, loss = 0.16834074\n",
      "Iteration 548, loss = 0.12701130\n",
      "Iteration 549, loss = 0.13175717\n",
      "Iteration 550, loss = 0.10930990\n",
      "Iteration 551, loss = 0.11065679\n",
      "Iteration 552, loss = 0.10615206\n",
      "Iteration 553, loss = 0.11422002\n",
      "Iteration 554, loss = 0.10371387\n",
      "Iteration 555, loss = 0.10464592\n",
      "Iteration 556, loss = 0.12312439\n",
      "Iteration 557, loss = 0.10591001\n",
      "Iteration 558, loss = 0.12024308\n",
      "Iteration 559, loss = 0.11692968\n",
      "Iteration 560, loss = 0.11926287\n",
      "Iteration 561, loss = 0.10604223\n",
      "Iteration 562, loss = 0.11043109\n",
      "Iteration 563, loss = 0.11037155\n",
      "Iteration 564, loss = 0.10817170\n",
      "Iteration 565, loss = 0.10465407\n",
      "Iteration 566, loss = 0.10827881\n",
      "Iteration 567, loss = 0.10720582\n",
      "Iteration 568, loss = 0.11988168\n",
      "Iteration 569, loss = 0.11257244\n",
      "Iteration 570, loss = 0.11062067\n",
      "Iteration 571, loss = 0.10802171\n",
      "Iteration 572, loss = 0.10615345\n",
      "Iteration 573, loss = 0.10828639\n",
      "Iteration 574, loss = 0.10112103\n",
      "Iteration 575, loss = 0.10236552\n",
      "Iteration 576, loss = 0.11281944\n",
      "Iteration 577, loss = 0.10387721\n",
      "Iteration 578, loss = 0.10876732\n",
      "Iteration 579, loss = 0.10456192\n",
      "Iteration 580, loss = 0.10702691\n",
      "Iteration 581, loss = 0.10883032\n",
      "Iteration 582, loss = 0.11034779\n",
      "Iteration 583, loss = 0.10288359\n",
      "Iteration 584, loss = 0.10857631\n",
      "Iteration 585, loss = 0.12279712\n",
      "Iteration 586, loss = 0.13563881\n",
      "Iteration 587, loss = 0.14211858\n",
      "Iteration 588, loss = 0.10218156\n",
      "Iteration 589, loss = 0.12882208\n",
      "Iteration 590, loss = 0.11765270\n",
      "Iteration 591, loss = 0.13558297\n",
      "Iteration 592, loss = 0.13511820\n",
      "Iteration 593, loss = 0.11325054\n",
      "Iteration 594, loss = 0.11892897\n",
      "Iteration 595, loss = 0.11685077\n",
      "Iteration 596, loss = 0.11167508\n",
      "Iteration 597, loss = 0.10651749\n",
      "Iteration 598, loss = 0.11489846\n",
      "Iteration 599, loss = 0.10513715\n",
      "Iteration 600, loss = 0.11195948\n",
      "Iteration 601, loss = 0.10509932\n",
      "Iteration 602, loss = 0.10867487\n",
      "Iteration 603, loss = 0.10325527\n",
      "Iteration 604, loss = 0.11021310\n",
      "Iteration 605, loss = 0.11222864\n",
      "Iteration 606, loss = 0.11727152\n",
      "Iteration 607, loss = 0.10784963\n",
      "Iteration 608, loss = 0.11525419\n",
      "Iteration 609, loss = 0.10980097\n",
      "Iteration 610, loss = 0.10952609\n",
      "Iteration 611, loss = 0.10912629\n",
      "Iteration 612, loss = 0.10202047\n",
      "Iteration 613, loss = 0.11298483\n",
      "Iteration 614, loss = 0.10749639\n",
      "Iteration 615, loss = 0.10278480\n",
      "Iteration 616, loss = 0.12889195\n",
      "Iteration 617, loss = 0.10464636\n",
      "Iteration 618, loss = 0.11996876\n",
      "Iteration 619, loss = 0.13759010\n",
      "Iteration 620, loss = 0.12620793\n",
      "Iteration 621, loss = 0.11594978\n",
      "Iteration 622, loss = 0.10689761\n",
      "Iteration 623, loss = 0.10606339\n",
      "Iteration 624, loss = 0.10414413\n",
      "Iteration 625, loss = 0.12441286\n",
      "Iteration 626, loss = 0.12856543\n",
      "Iteration 627, loss = 0.11441171\n",
      "Iteration 628, loss = 0.12064015\n",
      "Iteration 629, loss = 0.11214656\n",
      "Iteration 630, loss = 0.12062007\n",
      "Iteration 631, loss = 0.13270896\n",
      "Iteration 632, loss = 0.25957884\n",
      "Iteration 633, loss = 0.63910047\n",
      "Iteration 634, loss = 0.89056137\n",
      "Iteration 635, loss = 0.70680349\n",
      "Iteration 636, loss = 1.20515152\n",
      "Iteration 637, loss = 1.20647718\n",
      "Iteration 638, loss = 0.77960805\n",
      "Iteration 639, loss = 0.67666040\n",
      "Iteration 640, loss = 0.65431777\n",
      "Iteration 641, loss = 0.73493028\n",
      "Iteration 642, loss = 1.20652669\n",
      "Iteration 643, loss = 2.05721744\n",
      "Iteration 644, loss = 1.07353906\n",
      "Iteration 645, loss = 1.83267894\n",
      "Iteration 646, loss = 1.00678630\n",
      "Iteration 647, loss = 1.00552573\n",
      "Iteration 648, loss = 1.31133232\n",
      "Iteration 649, loss = 1.18283422\n",
      "Iteration 650, loss = 0.60547522\n",
      "Iteration 651, loss = 0.69410434\n",
      "Iteration 652, loss = 1.78014653\n",
      "Iteration 653, loss = 1.12187420\n",
      "Iteration 654, loss = 4.99869812\n",
      "Iteration 655, loss = 1.39996165\n",
      "Iteration 656, loss = 1.50314000\n",
      "Iteration 657, loss = 2.59053070\n",
      "Iteration 658, loss = 2.27501541\n",
      "Iteration 659, loss = 2.43773321\n",
      "Iteration 660, loss = 2.11119922\n",
      "Iteration 661, loss = 1.40696655\n",
      "Iteration 662, loss = 0.98851241\n",
      "Iteration 663, loss = 1.04162492\n",
      "Iteration 664, loss = 0.77851516\n",
      "Iteration 665, loss = 1.02043328\n",
      "Iteration 666, loss = 0.98806167\n",
      "Iteration 667, loss = 0.91953510\n",
      "Iteration 668, loss = 1.60886683\n",
      "Iteration 669, loss = 1.13577663\n",
      "Iteration 670, loss = 1.08140385\n",
      "Iteration 671, loss = 0.85464589\n",
      "Iteration 672, loss = 1.41628600\n",
      "Iteration 673, loss = 1.01864688\n",
      "Iteration 674, loss = 1.07335141\n",
      "Iteration 675, loss = 0.75124700\n",
      "Iteration 676, loss = 1.07360230\n",
      "Iteration 677, loss = 0.79516995\n",
      "Iteration 678, loss = 0.56437999\n",
      "Iteration 679, loss = 0.79283599\n",
      "Iteration 680, loss = 0.74407302\n",
      "Iteration 681, loss = 0.88693814\n",
      "Iteration 682, loss = 0.88383232\n",
      "Iteration 683, loss = 1.07153757\n",
      "Iteration 684, loss = 0.57442899\n",
      "Iteration 685, loss = 0.72324602\n",
      "Iteration 686, loss = 0.62151342\n",
      "Iteration 687, loss = 0.51267020\n",
      "Iteration 688, loss = 0.37893271\n",
      "Iteration 689, loss = 0.31764075\n",
      "Iteration 690, loss = 0.28040392\n",
      "Iteration 691, loss = 0.56769610\n",
      "Iteration 692, loss = 0.53152230\n",
      "Iteration 693, loss = 0.63146493\n",
      "Iteration 694, loss = 0.41719821\n",
      "Iteration 695, loss = 0.81020160\n",
      "Iteration 696, loss = 0.69106092\n",
      "Iteration 697, loss = 0.91011369\n",
      "Iteration 698, loss = 0.59433557\n",
      "Iteration 699, loss = 0.70509956\n",
      "Iteration 700, loss = 0.60748810\n",
      "Iteration 701, loss = 0.33629354\n",
      "Iteration 702, loss = 0.54032122\n",
      "Iteration 703, loss = 0.64168351\n",
      "Iteration 704, loss = 0.41733430\n",
      "Iteration 705, loss = 0.34487890\n",
      "Iteration 706, loss = 0.47575424\n",
      "Iteration 707, loss = 0.51436723\n",
      "Iteration 708, loss = 0.47824477\n",
      "Iteration 709, loss = 0.47196702\n",
      "Iteration 710, loss = 0.43192200\n",
      "Iteration 711, loss = 0.28885757\n",
      "Iteration 712, loss = 0.25890148\n",
      "Iteration 713, loss = 0.27953321\n",
      "Iteration 714, loss = 0.23764291\n",
      "Iteration 715, loss = 0.28206343\n",
      "Iteration 716, loss = 0.24932666\n",
      "Iteration 717, loss = 0.16461306\n",
      "Iteration 718, loss = 0.14734267\n",
      "Iteration 719, loss = 0.13372799\n",
      "Iteration 720, loss = 0.17159992\n",
      "Iteration 721, loss = 0.19006936\n",
      "Iteration 722, loss = 0.18633953\n",
      "Iteration 723, loss = 0.18023233\n",
      "Iteration 724, loss = 0.12627638\n",
      "Iteration 725, loss = 0.12568137\n",
      "Iteration 726, loss = 0.11289428\n",
      "Iteration 727, loss = 0.13728200\n",
      "Iteration 728, loss = 0.14340295\n",
      "Iteration 729, loss = 0.12827035\n",
      "Iteration 730, loss = 0.12704316\n",
      "Iteration 731, loss = 0.11488310\n",
      "Iteration 732, loss = 0.14631430\n",
      "Iteration 733, loss = 0.17426106\n",
      "Iteration 734, loss = 0.11534604\n",
      "Iteration 735, loss = 0.11403493\n",
      "Iteration 736, loss = 0.11734530\n",
      "Iteration 737, loss = 0.18860367\n",
      "Iteration 738, loss = 0.19227268\n",
      "Iteration 739, loss = 0.13560176\n",
      "Iteration 740, loss = 0.14625130\n",
      "Iteration 741, loss = 0.13406537\n",
      "Iteration 742, loss = 0.12324001\n",
      "Iteration 743, loss = 0.13708513\n",
      "Iteration 744, loss = 0.14599745\n",
      "Iteration 745, loss = 0.20077989\n",
      "Iteration 746, loss = 0.18315166\n",
      "Iteration 747, loss = 0.15441023\n",
      "Iteration 748, loss = 0.20144529\n",
      "Iteration 749, loss = 0.13131843\n",
      "Iteration 750, loss = 0.17166653\n",
      "Iteration 751, loss = 0.18390292\n",
      "Iteration 752, loss = 0.15330516\n",
      "Iteration 753, loss = 0.24687455\n",
      "Iteration 754, loss = 0.23912343\n",
      "Iteration 755, loss = 0.23892236\n",
      "Iteration 756, loss = 0.14219813\n",
      "Iteration 757, loss = 0.18861531\n",
      "Iteration 758, loss = 0.14734757\n",
      "Iteration 759, loss = 0.11992220\n",
      "Iteration 760, loss = 0.21041537\n",
      "Iteration 761, loss = 0.20715180\n",
      "Iteration 762, loss = 0.33643449\n",
      "Iteration 763, loss = 0.40187606\n",
      "Iteration 764, loss = 0.32330500\n",
      "Iteration 765, loss = 0.20713433\n",
      "Iteration 766, loss = 0.13650730\n",
      "Iteration 767, loss = 0.18328429\n",
      "Iteration 768, loss = 0.14310323\n",
      "Iteration 769, loss = 0.13230099\n",
      "Iteration 770, loss = 0.13310783\n",
      "Iteration 771, loss = 0.14560469\n",
      "Iteration 772, loss = 0.12357532\n",
      "Iteration 773, loss = 0.12603625\n",
      "Iteration 774, loss = 0.12189217\n",
      "Iteration 775, loss = 0.12292995\n",
      "Iteration 776, loss = 0.13840372\n",
      "Iteration 777, loss = 0.12398015\n",
      "Iteration 778, loss = 0.16327240\n",
      "Iteration 779, loss = 0.17333192\n",
      "Iteration 780, loss = 0.17300584\n",
      "Iteration 781, loss = 0.13306803\n",
      "Iteration 782, loss = 0.14940711\n",
      "Iteration 783, loss = 0.13367154\n",
      "Iteration 784, loss = 0.17751559\n",
      "Iteration 785, loss = 0.13865939\n",
      "Iteration 786, loss = 0.12776856\n",
      "Iteration 787, loss = 0.14854364\n",
      "Iteration 788, loss = 0.15600879\n",
      "Iteration 789, loss = 0.16200793\n",
      "Iteration 790, loss = 0.14074303\n",
      "Iteration 791, loss = 0.12569676\n",
      "Iteration 792, loss = 0.12601516\n",
      "Iteration 793, loss = 0.11005963\n",
      "Iteration 794, loss = 0.12776407\n",
      "Iteration 795, loss = 0.13588114\n",
      "Iteration 796, loss = 0.11886429\n",
      "Iteration 797, loss = 0.11208820\n",
      "Iteration 798, loss = 0.11584980\n",
      "Iteration 799, loss = 0.11176993\n",
      "Iteration 800, loss = 0.12852927\n",
      "Iteration 801, loss = 0.12292794\n",
      "Iteration 802, loss = 0.11874142\n",
      "Iteration 803, loss = 0.12477788\n",
      "Iteration 804, loss = 0.13035977\n",
      "Iteration 805, loss = 0.11022909\n",
      "Iteration 806, loss = 0.12319455\n",
      "Iteration 807, loss = 0.11935963\n",
      "Iteration 808, loss = 0.11955270\n",
      "Iteration 809, loss = 0.13128266\n",
      "Iteration 810, loss = 0.11220231\n",
      "Iteration 811, loss = 0.10847723\n",
      "Iteration 812, loss = 0.13422009\n",
      "Iteration 813, loss = 0.11441110\n",
      "Iteration 814, loss = 0.11540048\n",
      "Iteration 815, loss = 0.14877303\n",
      "Iteration 816, loss = 0.11934351\n",
      "Iteration 817, loss = 0.11384398\n",
      "Iteration 818, loss = 0.19778673\n",
      "Iteration 819, loss = 0.41188437\n",
      "Iteration 820, loss = 0.42977793\n",
      "Iteration 821, loss = 0.25095783\n",
      "Iteration 822, loss = 0.19059350\n",
      "Iteration 823, loss = 0.20922389\n",
      "Iteration 824, loss = 0.13781650\n",
      "Iteration 825, loss = 0.12446582\n",
      "Iteration 826, loss = 0.17537969\n",
      "Iteration 827, loss = 0.22494287\n",
      "Iteration 828, loss = 0.23553715\n",
      "Iteration 829, loss = 0.13837803\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 830, loss = 0.14978376\n",
      "Iteration 831, loss = 0.16501854\n",
      "Iteration 832, loss = 0.12166016\n",
      "Iteration 833, loss = 0.12992646\n",
      "Iteration 834, loss = 0.14447327\n",
      "Iteration 835, loss = 0.10987214\n",
      "Iteration 836, loss = 0.12399350\n",
      "Iteration 837, loss = 0.13502612\n",
      "Iteration 838, loss = 0.11609259\n",
      "Iteration 839, loss = 0.13634071\n",
      "Iteration 840, loss = 0.12965200\n",
      "Iteration 841, loss = 0.13761268\n",
      "Iteration 842, loss = 0.14106280\n",
      "Iteration 843, loss = 0.10516126\n",
      "Iteration 844, loss = 0.12822956\n",
      "Iteration 845, loss = 0.11488536\n",
      "Iteration 846, loss = 0.11361240\n",
      "Iteration 847, loss = 0.11850159\n",
      "Iteration 848, loss = 0.11512623\n",
      "Iteration 849, loss = 0.13991369\n",
      "Iteration 850, loss = 0.14043499\n",
      "Iteration 851, loss = 0.11733877\n",
      "Iteration 852, loss = 0.12901060\n",
      "Iteration 853, loss = 0.12212395\n",
      "Iteration 854, loss = 0.11440022\n",
      "Iteration 855, loss = 0.13991602\n",
      "Iteration 856, loss = 0.11675314\n",
      "Iteration 857, loss = 0.12617270\n",
      "Iteration 858, loss = 0.13710790\n",
      "Iteration 859, loss = 0.10906663\n",
      "Iteration 860, loss = 0.10663973\n",
      "Iteration 861, loss = 0.11288864\n",
      "Iteration 862, loss = 0.10733320\n",
      "Iteration 863, loss = 0.11209205\n",
      "Iteration 864, loss = 0.11609963\n",
      "Iteration 865, loss = 0.11438074\n",
      "Iteration 866, loss = 0.12770730\n",
      "Iteration 867, loss = 0.11970954\n",
      "Iteration 868, loss = 0.13293953\n",
      "Iteration 869, loss = 0.12279051\n",
      "Iteration 870, loss = 0.10926212\n",
      "Iteration 871, loss = 0.10468235\n",
      "Iteration 872, loss = 0.11254690\n",
      "Iteration 873, loss = 0.10620645\n",
      "Iteration 874, loss = 0.11612621\n",
      "Iteration 875, loss = 0.13362661\n",
      "Iteration 876, loss = 0.14319158\n",
      "Iteration 877, loss = 0.12829229\n",
      "Iteration 878, loss = 0.10976120\n",
      "Iteration 879, loss = 0.11206208\n",
      "Iteration 880, loss = 0.10817738\n",
      "Iteration 881, loss = 0.10610628\n",
      "Iteration 882, loss = 0.10841713\n",
      "Iteration 883, loss = 0.10667359\n",
      "Iteration 884, loss = 0.10640535\n",
      "Iteration 885, loss = 0.11093196\n",
      "Iteration 886, loss = 0.11935632\n",
      "Iteration 887, loss = 0.11391253\n",
      "Iteration 888, loss = 0.10664271\n",
      "Iteration 889, loss = 0.11118837\n",
      "Iteration 890, loss = 0.11244952\n",
      "Iteration 891, loss = 0.12106706\n",
      "Iteration 892, loss = 0.11342707\n",
      "Iteration 893, loss = 0.11197080\n",
      "Iteration 894, loss = 0.11746371\n",
      "Iteration 895, loss = 0.10275921\n",
      "Iteration 896, loss = 0.12040637\n",
      "Iteration 897, loss = 0.10651867\n",
      "Iteration 898, loss = 0.10903939\n",
      "Iteration 899, loss = 0.12783740\n",
      "Iteration 900, loss = 0.11529101\n",
      "Iteration 901, loss = 0.12230315\n",
      "Iteration 902, loss = 0.10815217\n",
      "Iteration 903, loss = 0.10955888\n",
      "Iteration 904, loss = 0.10993316\n",
      "Iteration 905, loss = 0.10841030\n",
      "Iteration 906, loss = 0.12505188\n",
      "Iteration 907, loss = 0.11874706\n",
      "Iteration 908, loss = 0.11642144\n",
      "Iteration 909, loss = 0.13057937\n",
      "Iteration 910, loss = 0.12994710\n",
      "Iteration 911, loss = 0.12960976\n",
      "Iteration 912, loss = 0.11544185\n",
      "Iteration 913, loss = 0.12247421\n",
      "Iteration 914, loss = 0.10820460\n",
      "Iteration 915, loss = 0.10747734\n",
      "Iteration 916, loss = 0.10870879\n",
      "Iteration 917, loss = 0.11147765\n",
      "Iteration 918, loss = 0.11193320\n",
      "Iteration 919, loss = 0.10499220\n",
      "Iteration 920, loss = 0.10533770\n",
      "Iteration 921, loss = 0.10387989\n",
      "Iteration 922, loss = 0.10476406\n",
      "Iteration 923, loss = 0.10422138\n",
      "Iteration 924, loss = 0.10506779\n",
      "Iteration 925, loss = 0.10996807\n",
      "Iteration 926, loss = 0.10652614\n",
      "Iteration 927, loss = 0.10776700\n",
      "Iteration 928, loss = 0.12250986\n",
      "Iteration 929, loss = 0.14114891\n",
      "Iteration 930, loss = 0.12805972\n",
      "Iteration 931, loss = 0.14096416\n",
      "Iteration 932, loss = 0.12545191\n",
      "Iteration 933, loss = 0.12110233\n",
      "Iteration 934, loss = 0.12463917\n",
      "Iteration 935, loss = 0.12821201\n",
      "Iteration 936, loss = 0.11945231\n",
      "Iteration 937, loss = 0.11073619\n",
      "Iteration 938, loss = 0.10379055\n",
      "Iteration 939, loss = 0.10390066\n",
      "Iteration 940, loss = 0.10529775\n",
      "Iteration 941, loss = 0.10386201\n",
      "Iteration 942, loss = 0.10691049\n",
      "Iteration 943, loss = 0.10272695\n",
      "Iteration 944, loss = 0.10916100\n",
      "Iteration 945, loss = 0.10786088\n",
      "Iteration 946, loss = 0.10722531\n",
      "Iteration 947, loss = 0.10869093\n",
      "Iteration 948, loss = 0.10682973\n",
      "Iteration 949, loss = 0.10693656\n",
      "Iteration 950, loss = 0.11710615\n",
      "Iteration 951, loss = 0.14800559\n",
      "Iteration 952, loss = 0.11314779\n",
      "Iteration 953, loss = 0.11987943\n",
      "Iteration 954, loss = 0.11573159\n",
      "Iteration 955, loss = 0.10405647\n",
      "Iteration 956, loss = 0.10957078\n",
      "Iteration 957, loss = 0.10231213\n",
      "Iteration 958, loss = 0.10357042\n",
      "Iteration 959, loss = 0.11387002\n",
      "Iteration 960, loss = 0.10481730\n",
      "Iteration 961, loss = 0.10867879\n",
      "Iteration 962, loss = 0.10325361\n",
      "Iteration 963, loss = 0.13183991\n",
      "Iteration 964, loss = 0.11067955\n",
      "Iteration 965, loss = 0.12421529\n",
      "Iteration 966, loss = 0.10764633\n",
      "Iteration 967, loss = 0.11411627\n",
      "Iteration 968, loss = 0.11641610\n",
      "Iteration 969, loss = 0.11923954\n",
      "Iteration 970, loss = 0.18674556\n",
      "Iteration 971, loss = 0.12251758\n",
      "Iteration 972, loss = 0.11376749\n",
      "Iteration 973, loss = 0.15386722\n",
      "Iteration 974, loss = 0.14425272\n",
      "Iteration 975, loss = 0.12269981\n",
      "Iteration 976, loss = 0.12617366\n",
      "Iteration 977, loss = 0.11309956\n",
      "Iteration 978, loss = 0.10185124\n",
      "Iteration 979, loss = 0.10932828\n",
      "Iteration 980, loss = 0.10529852\n",
      "Iteration 981, loss = 0.11008912\n",
      "Iteration 982, loss = 0.10543980\n",
      "Iteration 983, loss = 0.10898382\n",
      "Iteration 984, loss = 0.15641010\n",
      "Iteration 985, loss = 0.17103488\n",
      "Iteration 986, loss = 0.13287361\n",
      "Iteration 987, loss = 0.11932187\n",
      "Iteration 988, loss = 0.10739350\n",
      "Iteration 989, loss = 0.12311506\n",
      "Iteration 990, loss = 0.11826731\n",
      "Iteration 991, loss = 0.13575593\n",
      "Iteration 992, loss = 0.11424864\n",
      "Iteration 993, loss = 0.11980798\n",
      "Iteration 994, loss = 0.12267178\n",
      "Iteration 995, loss = 0.10378988\n",
      "Iteration 996, loss = 0.10500321\n",
      "Iteration 997, loss = 0.11353108\n",
      "Iteration 998, loss = 0.11300862\n",
      "Iteration 999, loss = 0.11164657\n",
      "Iteration 1000, loss = 0.13485614\n",
      "Iteration 1001, loss = 0.13267625\n",
      "Iteration 1002, loss = 0.11639962\n",
      "Iteration 1003, loss = 0.11178541\n",
      "Iteration 1004, loss = 0.11520901\n",
      "Iteration 1005, loss = 0.10639062\n",
      "Iteration 1006, loss = 0.10522349\n",
      "Iteration 1007, loss = 0.11083013\n",
      "Iteration 1008, loss = 0.11167003\n",
      "Iteration 1009, loss = 0.11132903\n",
      "Iteration 1010, loss = 0.10935591\n",
      "Iteration 1011, loss = 0.10683860\n",
      "Iteration 1012, loss = 0.11982636\n",
      "Iteration 1013, loss = 0.12177731\n",
      "Iteration 1014, loss = 0.16538098\n",
      "Iteration 1015, loss = 0.13047401\n",
      "Iteration 1016, loss = 0.30477106\n",
      "Iteration 1017, loss = 0.40150322\n",
      "Iteration 1018, loss = 0.45701379\n",
      "Iteration 1019, loss = 0.30024626\n",
      "Iteration 1020, loss = 0.19583435\n",
      "Iteration 1021, loss = 0.13106235\n",
      "Iteration 1022, loss = 0.13635314\n",
      "Iteration 1023, loss = 0.11567569\n",
      "Iteration 1024, loss = 0.12613435\n",
      "Iteration 1025, loss = 0.14283754\n",
      "Iteration 1026, loss = 0.14103265\n",
      "Iteration 1027, loss = 0.11432705\n",
      "Iteration 1028, loss = 0.12847279\n",
      "Iteration 1029, loss = 0.12991261\n",
      "Iteration 1030, loss = 0.13406886\n",
      "Iteration 1031, loss = 0.14239008\n",
      "Iteration 1032, loss = 0.25414944\n",
      "Iteration 1033, loss = 0.16611471\n",
      "Iteration 1034, loss = 0.12383794\n",
      "Iteration 1035, loss = 0.13058171\n",
      "Iteration 1036, loss = 0.10947519\n",
      "Iteration 1037, loss = 0.10853690\n",
      "Iteration 1038, loss = 0.12748788\n",
      "Iteration 1039, loss = 0.13754335\n",
      "Iteration 1040, loss = 0.13684299\n",
      "Iteration 1041, loss = 0.12655165\n",
      "Iteration 1042, loss = 0.12078209\n",
      "Iteration 1043, loss = 0.10786268\n",
      "Iteration 1044, loss = 0.11125897\n",
      "Iteration 1045, loss = 0.10211942\n",
      "Iteration 1046, loss = 0.10903657\n",
      "Iteration 1047, loss = 0.10762859\n",
      "Iteration 1048, loss = 0.18538980\n",
      "Iteration 1049, loss = 0.11764657\n",
      "Iteration 1050, loss = 0.13183245\n",
      "Iteration 1051, loss = 0.15423174\n",
      "Iteration 1052, loss = 0.11958171\n",
      "Iteration 1053, loss = 0.11646985\n",
      "Iteration 1054, loss = 0.11669529\n",
      "Iteration 1055, loss = 0.11365685\n",
      "Iteration 1056, loss = 0.10513557\n",
      "Iteration 1057, loss = 0.14913431\n",
      "Iteration 1058, loss = 0.11754403\n",
      "Iteration 1059, loss = 0.11097250\n",
      "Iteration 1060, loss = 0.11040446\n",
      "Iteration 1061, loss = 0.12942398\n",
      "Iteration 1062, loss = 0.43965292\n",
      "Iteration 1063, loss = 0.73280001\n",
      "Iteration 1064, loss = 1.32893722\n",
      "Iteration 1065, loss = 1.72400769\n",
      "Iteration 1066, loss = 2.02833886\n",
      "Iteration 1067, loss = 2.22111291\n",
      "Iteration 1068, loss = 2.51374508\n",
      "Iteration 1069, loss = 3.04737757\n",
      "Iteration 1070, loss = 2.65983462\n",
      "Iteration 1071, loss = 1.69716249\n",
      "Iteration 1072, loss = 1.19028559\n",
      "Iteration 1073, loss = 0.98426769\n",
      "Iteration 1074, loss = 2.26404488\n",
      "Iteration 1075, loss = 1.04127405\n",
      "Iteration 1076, loss = 1.10678270\n",
      "Iteration 1077, loss = 0.77551462\n",
      "Iteration 1078, loss = 1.69157877\n",
      "Iteration 1079, loss = 2.07963588\n",
      "Iteration 1080, loss = 1.10633472\n",
      "Iteration 1081, loss = 0.86980417\n",
      "Iteration 1082, loss = 0.67101224\n",
      "Iteration 1083, loss = 0.92288174\n",
      "Iteration 1084, loss = 0.81164453\n",
      "Iteration 1085, loss = 0.77008897\n",
      "Iteration 1086, loss = 0.56440080\n",
      "Iteration 1087, loss = 0.67024925\n",
      "Iteration 1088, loss = 0.49039998\n",
      "Iteration 1089, loss = 0.44728151\n",
      "Iteration 1090, loss = 0.39156186\n",
      "Iteration 1091, loss = 0.59661615\n",
      "Iteration 1092, loss = 0.36090915\n",
      "Iteration 1093, loss = 0.36301564\n",
      "Iteration 1094, loss = 0.28885514\n",
      "Iteration 1095, loss = 0.18099927\n",
      "Iteration 1096, loss = 0.21953454\n",
      "Iteration 1097, loss = 0.21921665\n",
      "Iteration 1098, loss = 0.18034977\n",
      "Iteration 1099, loss = 0.19995257\n",
      "Iteration 1100, loss = 0.20329872\n",
      "Iteration 1101, loss = 0.16653222\n",
      "Iteration 1102, loss = 0.14941831\n",
      "Iteration 1103, loss = 0.19598404\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1104, loss = 0.25644945\n",
      "Iteration 1105, loss = 0.22066988\n",
      "Iteration 1106, loss = 0.16624094\n",
      "Iteration 1107, loss = 0.15555525\n",
      "Iteration 1108, loss = 0.18263601\n",
      "Iteration 1109, loss = 0.23066416\n",
      "Iteration 1110, loss = 0.17437538\n",
      "Iteration 1111, loss = 0.18161524\n",
      "Iteration 1112, loss = 0.17282752\n",
      "Iteration 1113, loss = 0.16105818\n",
      "Iteration 1114, loss = 0.51182744\n",
      "Iteration 1115, loss = 0.59358403\n",
      "Iteration 1116, loss = 0.53176124\n",
      "Iteration 1117, loss = 0.36161559\n",
      "Iteration 1118, loss = 0.20403338\n",
      "Iteration 1119, loss = 0.20417370\n",
      "Iteration 1120, loss = 0.20368503\n",
      "Iteration 1121, loss = 0.17246696\n",
      "Iteration 1122, loss = 0.28843969\n",
      "Iteration 1123, loss = 0.26552100\n",
      "Iteration 1124, loss = 0.26319231\n",
      "Iteration 1125, loss = 0.25362493\n",
      "Iteration 1126, loss = 0.16401650\n",
      "Iteration 1127, loss = 0.20643078\n",
      "Iteration 1128, loss = 0.16614024\n",
      "Iteration 1129, loss = 0.12256160\n",
      "Iteration 1130, loss = 0.12755343\n",
      "Iteration 1131, loss = 0.13354557\n",
      "Iteration 1132, loss = 0.12739738\n",
      "Iteration 1133, loss = 0.12782073\n",
      "Iteration 1134, loss = 0.11836318\n",
      "Iteration 1135, loss = 0.16294998\n",
      "Iteration 1136, loss = 0.15140639\n",
      "Iteration 1137, loss = 0.11721022\n",
      "Iteration 1138, loss = 0.33678912\n",
      "Iteration 1139, loss = 0.40299646\n",
      "Iteration 1140, loss = 0.29428932\n",
      "Iteration 1141, loss = 0.18086415\n",
      "Iteration 1142, loss = 0.20191609\n",
      "Iteration 1143, loss = 0.25726282\n",
      "Iteration 1144, loss = 0.16720438\n",
      "Iteration 1145, loss = 0.14146513\n",
      "Iteration 1146, loss = 0.14911239\n",
      "Iteration 1147, loss = 0.18695602\n",
      "Iteration 1148, loss = 0.20761337\n",
      "Iteration 1149, loss = 0.19214835\n",
      "Iteration 1150, loss = 0.18885250\n",
      "Iteration 1151, loss = 0.21069174\n",
      "Iteration 1152, loss = 0.18199455\n",
      "Iteration 1153, loss = 0.14869323\n",
      "Iteration 1154, loss = 0.11735790\n",
      "Iteration 1155, loss = 0.15619130\n",
      "Iteration 1156, loss = 0.12347761\n",
      "Iteration 1157, loss = 0.15323586\n",
      "Iteration 1158, loss = 0.16206823\n",
      "Iteration 1159, loss = 0.14572673\n",
      "Iteration 1160, loss = 0.13606178\n",
      "Iteration 1161, loss = 0.15890448\n",
      "Iteration 1162, loss = 0.21279973\n",
      "Iteration 1163, loss = 0.43711598\n",
      "Iteration 1164, loss = 0.86235486\n",
      "Iteration 1165, loss = 1.02380673\n",
      "Iteration 1166, loss = 1.07924350\n",
      "Iteration 1167, loss = 0.82964296\n",
      "Iteration 1168, loss = 1.46948753\n",
      "Iteration 1169, loss = 0.71846701\n",
      "Iteration 1170, loss = 1.49219516\n",
      "Iteration 1171, loss = 0.83635844\n",
      "Iteration 1172, loss = 0.88024680\n",
      "Iteration 1173, loss = 0.66757468\n",
      "Iteration 1174, loss = 0.82583592\n",
      "Iteration 1175, loss = 0.81318099\n",
      "Iteration 1176, loss = 0.60936402\n",
      "Iteration 1177, loss = 0.78353104\n",
      "Iteration 1178, loss = 0.45177232\n",
      "Iteration 1179, loss = 0.38916302\n",
      "Iteration 1180, loss = 0.31856707\n",
      "Iteration 1181, loss = 0.29590364\n",
      "Iteration 1182, loss = 0.16352551\n",
      "Iteration 1183, loss = 0.17325817\n",
      "Iteration 1184, loss = 0.16970511\n",
      "Iteration 1185, loss = 0.15487535\n",
      "Iteration 1186, loss = 0.14380084\n",
      "Iteration 1187, loss = 0.12778506\n",
      "Iteration 1188, loss = 0.12721226\n",
      "Iteration 1189, loss = 0.13366234\n",
      "Iteration 1190, loss = 0.17367744\n",
      "Iteration 1191, loss = 0.15933771\n",
      "Iteration 1192, loss = 0.12171616\n",
      "Iteration 1193, loss = 0.11371604\n",
      "Iteration 1194, loss = 0.11982461\n",
      "Iteration 1195, loss = 0.12930490\n",
      "Iteration 1196, loss = 0.13000859\n",
      "Iteration 1197, loss = 0.12922252\n",
      "Iteration 1198, loss = 0.13127617\n",
      "Iteration 1199, loss = 0.12424414\n",
      "Iteration 1200, loss = 0.11720388\n",
      "Iteration 1201, loss = 0.10783939\n",
      "Iteration 1202, loss = 0.10815996\n",
      "Iteration 1203, loss = 0.10544748\n",
      "Iteration 1204, loss = 0.12724744\n",
      "Iteration 1205, loss = 0.11183768\n",
      "Iteration 1206, loss = 0.13340302\n",
      "Iteration 1207, loss = 0.12570470\n",
      "Iteration 1208, loss = 0.10672571\n",
      "Iteration 1209, loss = 0.11190915\n",
      "Iteration 1210, loss = 0.11294569\n",
      "Iteration 1211, loss = 0.12116506\n",
      "Iteration 1212, loss = 0.15200686\n",
      "Iteration 1213, loss = 0.12905360\n",
      "Iteration 1214, loss = 0.10753767\n",
      "Iteration 1215, loss = 0.14644222\n",
      "Iteration 1216, loss = 0.12283082\n",
      "Iteration 1217, loss = 0.10244707\n",
      "Iteration 1218, loss = 0.11434664\n",
      "Iteration 1219, loss = 0.11838748\n",
      "Iteration 1220, loss = 0.12384504\n",
      "Iteration 1221, loss = 0.11494393\n",
      "Iteration 1222, loss = 0.12762885\n",
      "Iteration 1223, loss = 0.10833292\n",
      "Iteration 1224, loss = 0.14661158\n",
      "Iteration 1225, loss = 0.12046589\n",
      "Iteration 1226, loss = 0.11345025\n",
      "Iteration 1227, loss = 0.14327290\n",
      "Iteration 1228, loss = 0.10885335\n",
      "Iteration 1229, loss = 0.12466555\n",
      "Iteration 1230, loss = 0.11272532\n",
      "Iteration 1231, loss = 0.10972058\n",
      "Iteration 1232, loss = 0.11435483\n",
      "Iteration 1233, loss = 0.11913699\n",
      "Iteration 1234, loss = 0.12508975\n",
      "Iteration 1235, loss = 0.12401328\n",
      "Iteration 1236, loss = 0.11456627\n",
      "Iteration 1237, loss = 0.12042584\n",
      "Iteration 1238, loss = 0.12127857\n",
      "Iteration 1239, loss = 0.11617649\n",
      "Iteration 1240, loss = 0.14461882\n",
      "Iteration 1241, loss = 0.11554676\n",
      "Iteration 1242, loss = 0.13780845\n",
      "Iteration 1243, loss = 0.12318294\n",
      "Iteration 1244, loss = 0.13243044\n",
      "Iteration 1245, loss = 0.13875887\n",
      "Iteration 1246, loss = 0.12499927\n",
      "Iteration 1247, loss = 0.11011243\n",
      "Iteration 1248, loss = 0.11343484\n",
      "Iteration 1249, loss = 0.13443933\n",
      "Iteration 1250, loss = 0.10650103\n",
      "Iteration 1251, loss = 0.11531733\n",
      "Iteration 1252, loss = 0.11425787\n",
      "Iteration 1253, loss = 0.11358146\n",
      "Iteration 1254, loss = 0.12003969\n",
      "Iteration 1255, loss = 0.11788623\n",
      "Iteration 1256, loss = 0.13590865\n",
      "Iteration 1257, loss = 0.12758291\n",
      "Iteration 1258, loss = 0.11532530\n",
      "Iteration 1259, loss = 0.12879457\n",
      "Iteration 1260, loss = 0.11454469\n",
      "Iteration 1261, loss = 0.11972649\n",
      "Iteration 1262, loss = 0.10640307\n",
      "Iteration 1263, loss = 0.11053952\n",
      "Iteration 1264, loss = 0.11010503\n",
      "Iteration 1265, loss = 0.12056000\n",
      "Iteration 1266, loss = 0.13268258\n",
      "Iteration 1267, loss = 0.11138913\n",
      "Iteration 1268, loss = 0.13762496\n",
      "Iteration 1269, loss = 0.12471458\n",
      "Iteration 1270, loss = 0.11085192\n",
      "Iteration 1271, loss = 0.13403622\n",
      "Iteration 1272, loss = 0.15889167\n",
      "Iteration 1273, loss = 0.12726633\n",
      "Iteration 1274, loss = 0.10657826\n",
      "Iteration 1275, loss = 0.11340104\n",
      "Iteration 1276, loss = 0.10531253\n",
      "Iteration 1277, loss = 0.12312659\n",
      "Iteration 1278, loss = 0.11761507\n",
      "Iteration 1279, loss = 0.14444232\n",
      "Iteration 1280, loss = 0.14105190\n",
      "Iteration 1281, loss = 0.13933400\n",
      "Iteration 1282, loss = 0.12248992\n",
      "Iteration 1283, loss = 0.11759331\n",
      "Iteration 1284, loss = 0.14024274\n",
      "Iteration 1285, loss = 0.11744193\n",
      "Iteration 1286, loss = 0.12919988\n",
      "Iteration 1287, loss = 0.11251891\n",
      "Iteration 1288, loss = 0.20563764\n",
      "Iteration 1289, loss = 0.26192935\n",
      "Iteration 1290, loss = 0.16741516\n",
      "Iteration 1291, loss = 0.19406817\n",
      "Iteration 1292, loss = 0.24719840\n",
      "Iteration 1293, loss = 0.24824393\n",
      "Iteration 1294, loss = 0.15054914\n",
      "Iteration 1295, loss = 0.19627295\n",
      "Iteration 1296, loss = 0.13965610\n",
      "Iteration 1297, loss = 0.15552960\n",
      "Iteration 1298, loss = 0.15719862\n",
      "Iteration 1299, loss = 0.11565797\n",
      "Iteration 1300, loss = 0.13552268\n",
      "Iteration 1301, loss = 0.14240959\n",
      "Iteration 1302, loss = 0.12765150\n",
      "Iteration 1303, loss = 0.12751499\n",
      "Iteration 1304, loss = 0.13091274\n",
      "Iteration 1305, loss = 0.11986964\n",
      "Iteration 1306, loss = 0.12874001\n",
      "Iteration 1307, loss = 0.10528919\n",
      "Iteration 1308, loss = 0.12813532\n",
      "Iteration 1309, loss = 0.11432077\n",
      "Iteration 1310, loss = 0.13442255\n",
      "Iteration 1311, loss = 0.21469840\n",
      "Iteration 1312, loss = 0.52197059\n",
      "Iteration 1313, loss = 0.53863201\n",
      "Iteration 1314, loss = 0.53142976\n",
      "Iteration 1315, loss = 0.45167256\n",
      "Iteration 1316, loss = 0.25925385\n",
      "Iteration 1317, loss = 0.20165980\n",
      "Iteration 1318, loss = 0.32852353\n",
      "Iteration 1319, loss = 0.34868821\n",
      "Iteration 1320, loss = 0.26216803\n",
      "Iteration 1321, loss = 0.12902331\n",
      "Iteration 1322, loss = 0.14514103\n",
      "Iteration 1323, loss = 0.14612204\n",
      "Iteration 1324, loss = 0.13884291\n",
      "Iteration 1325, loss = 0.13101698\n",
      "Iteration 1326, loss = 0.11869444\n",
      "Iteration 1327, loss = 0.12341610\n",
      "Iteration 1328, loss = 0.13249554\n",
      "Iteration 1329, loss = 0.14555382\n",
      "Iteration 1330, loss = 0.13221570\n",
      "Iteration 1331, loss = 0.13494126\n",
      "Iteration 1332, loss = 0.13854182\n",
      "Iteration 1333, loss = 0.11582638\n",
      "Iteration 1334, loss = 0.34221441\n",
      "Iteration 1335, loss = 0.49398420\n",
      "Iteration 1336, loss = 0.52768437\n",
      "Iteration 1337, loss = 0.47307030\n",
      "Iteration 1338, loss = 0.36293105\n",
      "Iteration 1339, loss = 0.17757007\n",
      "Iteration 1340, loss = 0.25840933\n",
      "Iteration 1341, loss = 0.38293360\n",
      "Iteration 1342, loss = 0.42689955\n",
      "Iteration 1343, loss = 0.23553480\n",
      "Iteration 1344, loss = 0.45313589\n",
      "Iteration 1345, loss = 0.50877633\n",
      "Iteration 1346, loss = 0.52058001\n",
      "Iteration 1347, loss = 0.32767865\n",
      "Iteration 1348, loss = 0.29689649\n",
      "Iteration 1349, loss = 0.37851736\n",
      "Iteration 1350, loss = 0.21104186\n",
      "Iteration 1351, loss = 0.47637177\n",
      "Iteration 1352, loss = 0.28331158\n",
      "Iteration 1353, loss = 0.43627664\n",
      "Iteration 1354, loss = 0.23068144\n",
      "Iteration 1355, loss = 0.24078504\n",
      "Iteration 1356, loss = 0.18060199\n",
      "Iteration 1357, loss = 0.14797653\n",
      "Iteration 1358, loss = 0.23889712\n",
      "Iteration 1359, loss = 0.11839859\n",
      "Iteration 1360, loss = 0.11122908\n",
      "Iteration 1361, loss = 0.13899498\n",
      "Iteration 1362, loss = 0.12069359\n",
      "Iteration 1363, loss = 0.12892702\n",
      "Iteration 1364, loss = 0.16272083\n",
      "Iteration 1365, loss = 0.22303292\n",
      "Iteration 1366, loss = 0.14177998\n",
      "Iteration 1367, loss = 0.24102664\n",
      "Iteration 1368, loss = 0.23420707\n",
      "Iteration 1369, loss = 0.13294159\n",
      "Iteration 1370, loss = 0.25470292\n",
      "Iteration 1371, loss = 0.45064437\n",
      "Iteration 1372, loss = 0.48479964\n",
      "Iteration 1373, loss = 0.46360450\n",
      "Iteration 1374, loss = 0.37057204\n",
      "Iteration 1375, loss = 0.23013342\n",
      "Iteration 1376, loss = 0.20580318\n",
      "Iteration 1377, loss = 0.17296958\n",
      "Iteration 1378, loss = 0.13870696\n",
      "Iteration 1379, loss = 0.16834212\n",
      "Iteration 1380, loss = 0.24296860\n",
      "Iteration 1381, loss = 0.28130863\n",
      "Iteration 1382, loss = 0.21203730\n",
      "Iteration 1383, loss = 0.17539740\n",
      "Iteration 1384, loss = 0.13366976\n",
      "Iteration 1385, loss = 0.30969181\n",
      "Iteration 1386, loss = 0.41706968\n",
      "Iteration 1387, loss = 0.59607027\n",
      "Iteration 1388, loss = 0.42260981\n",
      "Iteration 1389, loss = 0.24345938\n",
      "Iteration 1390, loss = 0.16254551\n",
      "Iteration 1391, loss = 0.13335219\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1392, loss = 0.15164351\n",
      "Iteration 1393, loss = 0.12851200\n",
      "Iteration 1394, loss = 0.13395768\n",
      "Iteration 1395, loss = 0.13095371\n",
      "Iteration 1396, loss = 0.12568474\n",
      "Iteration 1397, loss = 0.10886861\n",
      "Iteration 1398, loss = 0.17254251\n",
      "Iteration 1399, loss = 0.23294824\n",
      "Iteration 1400, loss = 0.26072944\n",
      "Iteration 1401, loss = 0.21172090\n",
      "Iteration 1402, loss = 0.19598103\n",
      "Iteration 1403, loss = 0.28815693\n",
      "Iteration 1404, loss = 0.27525851\n",
      "Iteration 1405, loss = 0.28359513\n",
      "Iteration 1406, loss = 0.21395698\n",
      "Iteration 1407, loss = 0.23500257\n",
      "Iteration 1408, loss = 0.16339274\n",
      "Iteration 1409, loss = 0.17134022\n",
      "Iteration 1410, loss = 0.15015526\n",
      "Iteration 1411, loss = 0.16173143\n",
      "Iteration 1412, loss = 0.10143404\n",
      "Iteration 1413, loss = 0.10880948\n",
      "Iteration 1414, loss = 0.12220463\n",
      "Iteration 1415, loss = 0.12062428\n",
      "Iteration 1416, loss = 0.12161329\n",
      "Iteration 1417, loss = 0.10708825\n",
      "Iteration 1418, loss = 0.10348873\n",
      "Iteration 1419, loss = 0.11124239\n",
      "Iteration 1420, loss = 0.33176597\n",
      "Iteration 1421, loss = 0.55887652\n",
      "Iteration 1422, loss = 0.55600835\n",
      "Iteration 1423, loss = 0.78338916\n",
      "Iteration 1424, loss = 0.57145797\n",
      "Iteration 1425, loss = 0.28831857\n",
      "Iteration 1426, loss = 0.18586362\n",
      "Iteration 1427, loss = 0.22483347\n",
      "Iteration 1428, loss = 0.20933408\n",
      "Iteration 1429, loss = 0.15999969\n",
      "Iteration 1430, loss = 0.28759564\n",
      "Iteration 1431, loss = 0.14512866\n",
      "Iteration 1432, loss = 0.15040600\n",
      "Iteration 1433, loss = 0.14172057\n",
      "Iteration 1434, loss = 0.13087423\n",
      "Iteration 1435, loss = 0.15820426\n",
      "Iteration 1436, loss = 0.11401155\n",
      "Iteration 1437, loss = 0.12142723\n",
      "Iteration 1438, loss = 0.16639862\n",
      "Iteration 1439, loss = 0.13297972\n",
      "Iteration 1440, loss = 0.15036218\n",
      "Iteration 1441, loss = 0.12366643\n",
      "Iteration 1442, loss = 0.11347231\n",
      "Iteration 1443, loss = 0.10754890\n",
      "Iteration 1444, loss = 0.11033560\n",
      "Iteration 1445, loss = 0.10942435\n",
      "Iteration 1446, loss = 0.14867827\n",
      "Iteration 1447, loss = 0.12239782\n",
      "Iteration 1448, loss = 0.12040491\n",
      "Iteration 1449, loss = 0.11611507\n",
      "Iteration 1450, loss = 0.12374878\n",
      "Iteration 1451, loss = 0.11411753\n",
      "Iteration 1452, loss = 0.12307651\n",
      "Iteration 1453, loss = 0.12027056\n",
      "Iteration 1454, loss = 0.10402721\n",
      "Iteration 1455, loss = 0.11325688\n",
      "Iteration 1456, loss = 0.14536269\n",
      "Iteration 1457, loss = 0.11380763\n",
      "Iteration 1458, loss = 0.11257592\n",
      "Iteration 1459, loss = 0.11091901\n",
      "Iteration 1460, loss = 0.10786099\n",
      "Iteration 1461, loss = 0.12083793\n",
      "Iteration 1462, loss = 0.10794686\n",
      "Iteration 1463, loss = 0.10381141\n",
      "Iteration 1464, loss = 0.10616412\n",
      "Iteration 1465, loss = 0.10352376\n",
      "Iteration 1466, loss = 0.10169604\n",
      "Iteration 1467, loss = 0.10927790\n",
      "Iteration 1468, loss = 0.11083669\n",
      "Iteration 1469, loss = 0.13033067\n",
      "Iteration 1470, loss = 0.12817359\n",
      "Iteration 1471, loss = 0.13754793\n",
      "Iteration 1472, loss = 0.12410818\n",
      "Iteration 1473, loss = 0.12183230\n",
      "Iteration 1474, loss = 0.12732395\n",
      "Iteration 1475, loss = 0.10846853\n",
      "Iteration 1476, loss = 0.10832596\n",
      "Iteration 1477, loss = 0.12523084\n",
      "Iteration 1478, loss = 0.11669622\n",
      "Iteration 1479, loss = 0.10398222\n",
      "Iteration 1480, loss = 0.11576576\n",
      "Iteration 1481, loss = 0.10967754\n",
      "Iteration 1482, loss = 0.10828216\n",
      "Iteration 1483, loss = 0.10515774\n",
      "Iteration 1484, loss = 0.10482246\n",
      "Iteration 1485, loss = 0.10374639\n",
      "Iteration 1486, loss = 0.10797544\n",
      "Iteration 1487, loss = 0.10105333\n",
      "Iteration 1488, loss = 0.10732641\n",
      "Iteration 1489, loss = 0.14873189\n",
      "Iteration 1490, loss = 0.35836621\n",
      "Iteration 1491, loss = 0.41413426\n",
      "Iteration 1492, loss = 0.36566269\n",
      "Iteration 1493, loss = 0.16725012\n",
      "Iteration 1494, loss = 0.16749609\n",
      "Iteration 1495, loss = 0.14110721\n",
      "Iteration 1496, loss = 0.20454587\n",
      "Iteration 1497, loss = 0.52043699\n",
      "Iteration 1498, loss = 0.88331035\n",
      "Iteration 1499, loss = 0.42444872\n",
      "Iteration 1500, loss = 0.60375454\n",
      "Iteration 1501, loss = 0.75682165\n",
      "Iteration 1502, loss = 0.82173990\n",
      "Iteration 1503, loss = 0.46175730\n",
      "Iteration 1504, loss = 0.36098509\n",
      "Iteration 1505, loss = 0.22532832\n",
      "Iteration 1506, loss = 0.31535455\n",
      "Iteration 1507, loss = 0.16123793\n",
      "Iteration 1508, loss = 0.13917969\n",
      "Iteration 1509, loss = 0.15096465\n",
      "Iteration 1510, loss = 0.11480833\n",
      "Iteration 1511, loss = 0.11487182\n",
      "Iteration 1512, loss = 0.12665596\n",
      "Iteration 1513, loss = 0.13338415\n",
      "Iteration 1514, loss = 0.11675787\n",
      "Iteration 1515, loss = 0.13543761\n",
      "Iteration 1516, loss = 0.14256513\n",
      "Iteration 1517, loss = 0.12637536\n",
      "Iteration 1518, loss = 0.13355452\n",
      "Iteration 1519, loss = 0.13528124\n",
      "Iteration 1520, loss = 0.11466186\n",
      "Iteration 1521, loss = 0.11909278\n",
      "Iteration 1522, loss = 0.10176371\n",
      "Iteration 1523, loss = 0.11896747\n",
      "Iteration 1524, loss = 0.10163487\n",
      "Iteration 1525, loss = 0.10976025\n",
      "Iteration 1526, loss = 0.11170541\n",
      "Iteration 1527, loss = 0.13887772\n",
      "Iteration 1528, loss = 0.11884663\n",
      "Iteration 1529, loss = 0.12849087\n",
      "Iteration 1530, loss = 0.11854950\n",
      "Iteration 1531, loss = 0.11547228\n",
      "Iteration 1532, loss = 0.12926642\n",
      "Iteration 1533, loss = 0.11033069\n",
      "Iteration 1534, loss = 0.11040766\n",
      "Iteration 1535, loss = 0.11404544\n",
      "Iteration 1536, loss = 0.10719937\n",
      "Iteration 1537, loss = 0.12092182\n",
      "Iteration 1538, loss = 0.11318634\n",
      "Iteration 1539, loss = 0.11116848\n",
      "Iteration 1540, loss = 0.12422471\n",
      "Iteration 1541, loss = 0.11898788\n",
      "Iteration 1542, loss = 0.13462150\n",
      "Iteration 1543, loss = 0.11158770\n",
      "Iteration 1544, loss = 0.13027869\n",
      "Iteration 1545, loss = 0.12857824\n",
      "Iteration 1546, loss = 0.11468173\n",
      "Iteration 1547, loss = 0.13678322\n",
      "Iteration 1548, loss = 0.18170337\n",
      "Iteration 1549, loss = 0.18977738\n",
      "Iteration 1550, loss = 0.17023554\n",
      "Iteration 1551, loss = 0.13516203\n",
      "Iteration 1552, loss = 0.12852764\n",
      "Iteration 1553, loss = 0.11588135\n",
      "Iteration 1554, loss = 0.13769378\n",
      "Iteration 1555, loss = 0.11900588\n",
      "Iteration 1556, loss = 0.12932436\n",
      "Iteration 1557, loss = 0.12866185\n",
      "Iteration 1558, loss = 0.12830302\n",
      "Iteration 1559, loss = 0.12309642\n",
      "Iteration 1560, loss = 0.14320048\n",
      "Iteration 1561, loss = 0.26135524\n",
      "Iteration 1562, loss = 0.25042116\n",
      "Iteration 1563, loss = 0.16418046\n",
      "Iteration 1564, loss = 0.17409201\n",
      "Iteration 1565, loss = 0.24996684\n",
      "Iteration 1566, loss = 0.15278261\n",
      "Iteration 1567, loss = 0.14037893\n",
      "Iteration 1568, loss = 0.13583967\n",
      "Iteration 1569, loss = 0.14742483\n",
      "Iteration 1570, loss = 0.13958890\n",
      "Iteration 1571, loss = 0.14098418\n",
      "Iteration 1572, loss = 0.11324485\n",
      "Iteration 1573, loss = 0.11085870\n",
      "Iteration 1574, loss = 0.12529521\n",
      "Iteration 1575, loss = 0.11975034\n",
      "Iteration 1576, loss = 0.11083232\n",
      "Iteration 1577, loss = 0.10908122\n",
      "Iteration 1578, loss = 0.11364546\n",
      "Iteration 1579, loss = 0.15534091\n",
      "Iteration 1580, loss = 0.29188422\n",
      "Iteration 1581, loss = 0.31606853\n",
      "Iteration 1582, loss = 0.21671717\n",
      "Iteration 1583, loss = 0.15679451\n",
      "Iteration 1584, loss = 0.13893477\n",
      "Iteration 1585, loss = 0.13121720\n",
      "Iteration 1586, loss = 0.10967043\n",
      "Iteration 1587, loss = 0.11624327\n",
      "Iteration 1588, loss = 0.10991625\n",
      "Iteration 1589, loss = 0.14722611\n",
      "Iteration 1590, loss = 0.12724747\n",
      "Iteration 1591, loss = 0.12207430\n",
      "Iteration 1592, loss = 0.12448869\n",
      "Iteration 1593, loss = 0.12519211\n",
      "Iteration 1594, loss = 0.10689098\n",
      "Iteration 1595, loss = 0.12301955\n",
      "Iteration 1596, loss = 0.12185414\n",
      "Iteration 1597, loss = 0.10353465\n",
      "Iteration 1598, loss = 0.10640174\n",
      "Iteration 1599, loss = 0.10781618\n",
      "Iteration 1600, loss = 0.11196142\n",
      "Iteration 1601, loss = 0.10164992\n",
      "Iteration 1602, loss = 0.11195762\n",
      "Iteration 1603, loss = 0.10883810\n",
      "Iteration 1604, loss = 0.10464521\n",
      "Iteration 1605, loss = 0.12516428\n",
      "Iteration 1606, loss = 0.10900008\n",
      "Iteration 1607, loss = 0.10160642\n",
      "Iteration 1608, loss = 0.11040247\n",
      "Iteration 1609, loss = 0.10268640\n",
      "Iteration 1610, loss = 0.10127366\n",
      "Iteration 1611, loss = 0.10676299\n",
      "Iteration 1612, loss = 0.10713743\n",
      "Iteration 1613, loss = 0.10079832\n",
      "Iteration 1614, loss = 0.10526351\n",
      "Iteration 1615, loss = 0.11527306\n",
      "Iteration 1616, loss = 0.10792698\n",
      "Iteration 1617, loss = 0.10561009\n",
      "Iteration 1618, loss = 0.11528652\n",
      "Iteration 1619, loss = 0.11781684\n",
      "Iteration 1620, loss = 0.10325865\n",
      "Iteration 1621, loss = 0.10252240\n",
      "Iteration 1622, loss = 0.10235799\n",
      "Iteration 1623, loss = 0.10468648\n",
      "Iteration 1624, loss = 0.10336739\n",
      "Iteration 1625, loss = 0.10053765\n",
      "Iteration 1626, loss = 0.11202637\n",
      "Iteration 1627, loss = 0.10730253\n",
      "Iteration 1628, loss = 0.10980067\n",
      "Iteration 1629, loss = 0.10762431\n",
      "Iteration 1630, loss = 0.10749534\n",
      "Iteration 1631, loss = 0.11354242\n",
      "Iteration 1632, loss = 0.10730607\n",
      "Iteration 1633, loss = 0.11057912\n",
      "Iteration 1634, loss = 0.13039770\n",
      "Iteration 1635, loss = 0.10781746\n",
      "Iteration 1636, loss = 0.10759280\n",
      "Iteration 1637, loss = 0.12464541\n",
      "Iteration 1638, loss = 0.10348252\n",
      "Iteration 1639, loss = 0.12932474\n",
      "Iteration 1640, loss = 0.11327902\n",
      "Iteration 1641, loss = 0.12312975\n",
      "Iteration 1642, loss = 0.11204111\n",
      "Iteration 1643, loss = 0.12398993\n",
      "Iteration 1644, loss = 0.11232746\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1645, loss = 0.14602074\n",
      "Iteration 1646, loss = 0.18993827\n",
      "Iteration 1647, loss = 0.13846817\n",
      "Iteration 1648, loss = 0.10511695\n",
      "Iteration 1649, loss = 0.11030970\n",
      "Iteration 1650, loss = 0.10910268\n",
      "Iteration 1651, loss = 0.11030716\n",
      "Iteration 1652, loss = 0.10219941\n",
      "Iteration 1653, loss = 0.10105055\n",
      "Iteration 1654, loss = 0.10766170\n",
      "Iteration 1655, loss = 0.10525483\n",
      "Iteration 1656, loss = 0.10964846\n",
      "Iteration 1657, loss = 0.10871309\n",
      "Iteration 1658, loss = 0.09961295\n",
      "Iteration 1659, loss = 0.10146580\n",
      "Iteration 1660, loss = 0.11581000\n",
      "Iteration 1661, loss = 0.12322328\n",
      "Iteration 1662, loss = 0.17124707\n",
      "Iteration 1663, loss = 0.12974682\n",
      "Iteration 1664, loss = 0.14530650\n",
      "Iteration 1665, loss = 0.25292109\n",
      "Iteration 1666, loss = 0.25381627\n",
      "Iteration 1667, loss = 0.23044925\n",
      "Iteration 1668, loss = 0.20085205\n",
      "Iteration 1669, loss = 0.74478892\n",
      "Iteration 1670, loss = 0.71859144\n",
      "Iteration 1671, loss = 1.20619068\n",
      "Iteration 1672, loss = 1.12478511\n",
      "Iteration 1673, loss = 1.03902328\n",
      "Iteration 1674, loss = 1.21994147\n",
      "Iteration 1675, loss = 0.89505231\n",
      "Iteration 1676, loss = 1.29479438\n",
      "Iteration 1677, loss = 1.60053052\n",
      "Iteration 1678, loss = 2.16403009\n",
      "Iteration 1679, loss = 1.32929289\n",
      "Iteration 1680, loss = 1.36795070\n",
      "Iteration 1681, loss = 2.03907361\n",
      "Iteration 1682, loss = 0.93783499\n",
      "Iteration 1683, loss = 0.91680406\n",
      "Iteration 1684, loss = 1.24800633\n",
      "Iteration 1685, loss = 0.78826922\n",
      "Iteration 1686, loss = 0.75754695\n",
      "Iteration 1687, loss = 4.40768051\n",
      "Iteration 1688, loss = 2.13804249\n",
      "Iteration 1689, loss = 1.13102809\n",
      "Iteration 1690, loss = 1.00056477\n",
      "Iteration 1691, loss = 1.27397254\n",
      "Iteration 1692, loss = 1.42692324\n",
      "Iteration 1693, loss = 1.49819811\n",
      "Iteration 1694, loss = 0.74527371\n",
      "Iteration 1695, loss = 1.01551005\n",
      "Iteration 1696, loss = 0.80531305\n",
      "Iteration 1697, loss = 0.86095892\n",
      "Iteration 1698, loss = 0.51582718\n",
      "Iteration 1699, loss = 0.52074234\n",
      "Iteration 1700, loss = 0.63490790\n",
      "Iteration 1701, loss = 0.55425512\n",
      "Iteration 1702, loss = 0.23904929\n",
      "Iteration 1703, loss = 0.21224078\n",
      "Iteration 1704, loss = 0.21332886\n",
      "Iteration 1705, loss = 0.17656764\n",
      "Iteration 1706, loss = 0.47500320\n",
      "Iteration 1707, loss = 0.57231347\n",
      "Iteration 1708, loss = 0.69436447\n",
      "Iteration 1709, loss = 0.52118884\n",
      "Iteration 1710, loss = 0.46272691\n",
      "Iteration 1711, loss = 0.32208991\n",
      "Iteration 1712, loss = 0.25228553\n",
      "Iteration 1713, loss = 0.17203200\n",
      "Iteration 1714, loss = 0.21902935\n",
      "Iteration 1715, loss = 0.33556007\n",
      "Iteration 1716, loss = 0.27113326\n",
      "Iteration 1717, loss = 0.31718071\n",
      "Iteration 1718, loss = 0.19550345\n",
      "Iteration 1719, loss = 0.18326211\n",
      "Iteration 1720, loss = 0.15615442\n",
      "Iteration 1721, loss = 0.17651407\n",
      "Iteration 1722, loss = 0.17759904\n",
      "Iteration 1723, loss = 0.17086215\n",
      "Iteration 1724, loss = 0.16502406\n",
      "Iteration 1725, loss = 0.14127260\n",
      "Iteration 1726, loss = 0.14744381\n",
      "Iteration 1727, loss = 0.18564294\n",
      "Iteration 1728, loss = 0.14890708\n",
      "Iteration 1729, loss = 0.14531008\n",
      "Iteration 1730, loss = 0.17933556\n",
      "Iteration 1731, loss = 0.22779679\n",
      "Iteration 1732, loss = 0.20470254\n",
      "Iteration 1733, loss = 0.16424661\n",
      "Iteration 1734, loss = 0.17473341\n",
      "Iteration 1735, loss = 0.13089088\n",
      "Iteration 1736, loss = 0.12904302\n",
      "Iteration 1737, loss = 0.11567472\n",
      "Iteration 1738, loss = 0.21744306\n",
      "Iteration 1739, loss = 0.28928592\n",
      "Iteration 1740, loss = 0.19683209\n",
      "Iteration 1741, loss = 0.16783527\n",
      "Iteration 1742, loss = 0.15332639\n",
      "Iteration 1743, loss = 0.16760789\n",
      "Iteration 1744, loss = 0.13960966\n",
      "Iteration 1745, loss = 0.14754374\n",
      "Iteration 1746, loss = 0.12850240\n",
      "Iteration 1747, loss = 0.15800702\n",
      "Iteration 1748, loss = 0.17816433\n",
      "Iteration 1749, loss = 0.17824945\n",
      "Iteration 1750, loss = 0.15395824\n",
      "Iteration 1751, loss = 0.12484910\n",
      "Iteration 1752, loss = 0.15003963\n",
      "Iteration 1753, loss = 0.11822523\n",
      "Iteration 1754, loss = 0.14112041\n",
      "Iteration 1755, loss = 0.12269540\n",
      "Iteration 1756, loss = 0.12967055\n",
      "Iteration 1757, loss = 0.10647846\n",
      "Iteration 1758, loss = 0.11210906\n",
      "Iteration 1759, loss = 0.10958184\n",
      "Iteration 1760, loss = 0.10628966\n",
      "Iteration 1761, loss = 0.12219695\n",
      "Iteration 1762, loss = 0.11330356\n",
      "Iteration 1763, loss = 0.11934452\n",
      "Iteration 1764, loss = 0.11377987\n",
      "Iteration 1765, loss = 0.11162692\n",
      "Iteration 1766, loss = 0.13938747\n",
      "Iteration 1767, loss = 0.11584775\n",
      "Iteration 1768, loss = 0.10489228\n",
      "Iteration 1769, loss = 0.12421425\n",
      "Iteration 1770, loss = 0.14485303\n",
      "Iteration 1771, loss = 0.13172595\n",
      "Iteration 1772, loss = 0.15573232\n",
      "Iteration 1773, loss = 0.15633003\n",
      "Iteration 1774, loss = 0.10891658\n",
      "Iteration 1775, loss = 0.10451208\n",
      "Iteration 1776, loss = 0.11909260\n",
      "Iteration 1777, loss = 0.10869720\n",
      "Iteration 1778, loss = 0.10891253\n",
      "Iteration 1779, loss = 0.12879294\n",
      "Iteration 1780, loss = 0.11127778\n",
      "Iteration 1781, loss = 0.10913674\n",
      "Iteration 1782, loss = 0.12007342\n",
      "Iteration 1783, loss = 0.14281845\n",
      "Iteration 1784, loss = 0.12460620\n",
      "Iteration 1785, loss = 0.10959007\n",
      "Iteration 1786, loss = 0.10448158\n",
      "Iteration 1787, loss = 0.11138946\n",
      "Iteration 1788, loss = 0.11073824\n",
      "Iteration 1789, loss = 0.13850769\n",
      "Iteration 1790, loss = 0.14931940\n",
      "Iteration 1791, loss = 0.15671444\n",
      "Iteration 1792, loss = 0.16158350\n",
      "Iteration 1793, loss = 0.12809823\n",
      "Iteration 1794, loss = 0.14505010\n",
      "Iteration 1795, loss = 0.17261141\n",
      "Iteration 1796, loss = 0.15238457\n",
      "Iteration 1797, loss = 0.13079485\n",
      "Iteration 1798, loss = 0.12269003\n",
      "Iteration 1799, loss = 0.12737259\n",
      "Iteration 1800, loss = 0.12350281\n",
      "Iteration 1801, loss = 0.10990087\n",
      "Iteration 1802, loss = 0.10881041\n",
      "Iteration 1803, loss = 0.10789820\n",
      "Iteration 1804, loss = 0.10880659\n",
      "Iteration 1805, loss = 0.11775688\n",
      "Iteration 1806, loss = 0.14259334\n",
      "Iteration 1807, loss = 0.11632800\n",
      "Iteration 1808, loss = 0.12009002\n",
      "Iteration 1809, loss = 0.18788084\n",
      "Iteration 1810, loss = 0.13174211\n",
      "Iteration 1811, loss = 0.13270749\n",
      "Iteration 1812, loss = 0.12419182\n",
      "Iteration 1813, loss = 0.11926962\n",
      "Iteration 1814, loss = 0.12118194\n",
      "Iteration 1815, loss = 0.12126512\n",
      "Iteration 1816, loss = 0.13102699\n",
      "Iteration 1817, loss = 0.12007157\n",
      "Iteration 1818, loss = 0.11624902\n",
      "Iteration 1819, loss = 0.11478708\n",
      "Iteration 1820, loss = 0.11074778\n",
      "Iteration 1821, loss = 0.12277475\n",
      "Iteration 1822, loss = 0.10940056\n",
      "Iteration 1823, loss = 0.10728966\n",
      "Iteration 1824, loss = 0.10999828\n",
      "Iteration 1825, loss = 0.11922448\n",
      "Iteration 1826, loss = 0.13560663\n",
      "Iteration 1827, loss = 0.12496385\n",
      "Iteration 1828, loss = 0.12895648\n",
      "Iteration 1829, loss = 0.11622936\n",
      "Iteration 1830, loss = 0.10392443\n",
      "Iteration 1831, loss = 0.15629511\n",
      "Iteration 1832, loss = 0.13269054\n",
      "Iteration 1833, loss = 0.13112723\n",
      "Iteration 1834, loss = 0.12808455\n",
      "Iteration 1835, loss = 0.11884477\n",
      "Iteration 1836, loss = 0.11028190\n",
      "Iteration 1837, loss = 0.11321862\n",
      "Iteration 1838, loss = 0.11572337\n",
      "Iteration 1839, loss = 0.10214294\n",
      "Iteration 1840, loss = 0.14155105\n",
      "Iteration 1841, loss = 0.11746189\n",
      "Iteration 1842, loss = 0.11451437\n",
      "Iteration 1843, loss = 0.10961296\n",
      "Iteration 1844, loss = 0.12877099\n",
      "Iteration 1845, loss = 0.10953622\n",
      "Iteration 1846, loss = 0.09889110\n",
      "Iteration 1847, loss = 0.12358390\n",
      "Iteration 1848, loss = 0.11679993\n",
      "Iteration 1849, loss = 0.10620893\n",
      "Iteration 1850, loss = 0.10565900\n",
      "Iteration 1851, loss = 0.11226218\n",
      "Iteration 1852, loss = 0.13279061\n",
      "Iteration 1853, loss = 0.11449513\n",
      "Iteration 1854, loss = 0.11089885\n",
      "Iteration 1855, loss = 0.11202600\n",
      "Iteration 1856, loss = 0.11614384\n",
      "Iteration 1857, loss = 0.11884704\n",
      "Iteration 1858, loss = 0.10627514\n",
      "Iteration 1859, loss = 0.10201577\n",
      "Iteration 1860, loss = 0.10783778\n",
      "Iteration 1861, loss = 0.10797005\n",
      "Iteration 1862, loss = 0.10662000\n",
      "Iteration 1863, loss = 0.10452708\n",
      "Iteration 1864, loss = 0.10359299\n",
      "Iteration 1865, loss = 0.10207642\n",
      "Iteration 1866, loss = 0.11770297\n",
      "Iteration 1867, loss = 0.11340116\n",
      "Iteration 1868, loss = 0.11129901\n",
      "Iteration 1869, loss = 0.10849810\n",
      "Iteration 1870, loss = 0.11204656\n",
      "Iteration 1871, loss = 0.10792484\n",
      "Iteration 1872, loss = 0.11143490\n",
      "Iteration 1873, loss = 0.10812997\n",
      "Iteration 1874, loss = 0.12137821\n",
      "Iteration 1875, loss = 0.10662506\n",
      "Iteration 1876, loss = 0.14120972\n",
      "Iteration 1877, loss = 0.13382235\n",
      "Iteration 1878, loss = 0.10732491\n",
      "Iteration 1879, loss = 0.10926951\n",
      "Iteration 1880, loss = 0.10799767\n",
      "Iteration 1881, loss = 0.11940582\n",
      "Iteration 1882, loss = 0.11214927\n",
      "Iteration 1883, loss = 0.11297023\n",
      "Iteration 1884, loss = 0.11374414\n",
      "Iteration 1885, loss = 0.13075353\n",
      "Iteration 1886, loss = 0.11915160\n",
      "Iteration 1887, loss = 0.11202765\n",
      "Iteration 1888, loss = 0.11017047\n",
      "Iteration 1889, loss = 0.11134011\n",
      "Iteration 1890, loss = 0.11398726\n",
      "Iteration 1891, loss = 0.14343277\n",
      "Iteration 1892, loss = 0.12215295\n",
      "Iteration 1893, loss = 0.10570028\n",
      "Iteration 1894, loss = 0.10996522\n",
      "Iteration 1895, loss = 0.11172336\n",
      "Iteration 1896, loss = 0.11657054\n",
      "Iteration 1897, loss = 0.11679014\n",
      "Iteration 1898, loss = 0.11210285\n",
      "Iteration 1899, loss = 0.11328080\n",
      "Iteration 1900, loss = 0.10154089\n",
      "Iteration 1901, loss = 0.10651104\n",
      "Iteration 1902, loss = 0.10975399\n",
      "Iteration 1903, loss = 0.11413962\n",
      "Iteration 1904, loss = 0.11844535\n",
      "Iteration 1905, loss = 0.13531233\n",
      "Iteration 1906, loss = 0.10900299\n",
      "Iteration 1907, loss = 0.11598340\n",
      "Iteration 1908, loss = 0.11278774\n",
      "Iteration 1909, loss = 0.13498822\n",
      "Iteration 1910, loss = 0.11453262\n",
      "Iteration 1911, loss = 0.17134293\n",
      "Iteration 1912, loss = 0.13948105\n",
      "Iteration 1913, loss = 0.10967744\n",
      "Iteration 1914, loss = 0.10671069\n",
      "Iteration 1915, loss = 0.10520411\n",
      "Iteration 1916, loss = 0.10563573\n",
      "Iteration 1917, loss = 0.14358079\n",
      "Iteration 1918, loss = 0.12140011\n",
      "Iteration 1919, loss = 0.11540017\n",
      "Iteration 1920, loss = 0.11087536\n",
      "Iteration 1921, loss = 0.12960330\n",
      "Iteration 1922, loss = 0.10588045\n",
      "Iteration 1923, loss = 0.10948186\n",
      "Iteration 1924, loss = 0.10560389\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1925, loss = 0.11243529\n",
      "Iteration 1926, loss = 0.10647824\n",
      "Iteration 1927, loss = 0.11050730\n",
      "Iteration 1928, loss = 0.10040706\n",
      "Iteration 1929, loss = 0.11957913\n",
      "Iteration 1930, loss = 0.11781551\n",
      "Iteration 1931, loss = 0.10910444\n",
      "Iteration 1932, loss = 0.11470651\n",
      "Iteration 1933, loss = 0.21148543\n",
      "Iteration 1934, loss = 0.16162209\n",
      "Iteration 1935, loss = 0.18757844\n",
      "Iteration 1936, loss = 0.20834684\n",
      "Iteration 1937, loss = 0.14066388\n",
      "Iteration 1938, loss = 0.11774054\n",
      "Iteration 1939, loss = 0.11851502\n",
      "Iteration 1940, loss = 0.15395986\n",
      "Iteration 1941, loss = 0.13155468\n",
      "Iteration 1942, loss = 0.10728428\n",
      "Iteration 1943, loss = 0.14057543\n",
      "Iteration 1944, loss = 0.11843042\n",
      "Iteration 1945, loss = 0.14261839\n",
      "Iteration 1946, loss = 0.17155118\n",
      "Iteration 1947, loss = 0.13598402\n",
      "Iteration 1948, loss = 0.13693285\n",
      "Iteration 1949, loss = 0.12217175\n",
      "Iteration 1950, loss = 0.12929422\n",
      "Iteration 1951, loss = 0.14259492\n",
      "Iteration 1952, loss = 0.15913285\n",
      "Iteration 1953, loss = 0.40637660\n",
      "Iteration 1954, loss = 0.63260831\n",
      "Iteration 1955, loss = 0.54303167\n",
      "Iteration 1956, loss = 0.55909870\n",
      "Iteration 1957, loss = 0.46106095\n",
      "Iteration 1958, loss = 0.71668585\n",
      "Iteration 1959, loss = 1.03974206\n",
      "Iteration 1960, loss = 1.10615007\n",
      "Iteration 1961, loss = 1.33100806\n",
      "Iteration 1962, loss = 0.94820805\n",
      "Iteration 1963, loss = 0.89862482\n",
      "Iteration 1964, loss = 0.77230252\n",
      "Iteration 1965, loss = 0.93362419\n",
      "Iteration 1966, loss = 0.60196979\n",
      "Iteration 1967, loss = 0.69915080\n",
      "Iteration 1968, loss = 1.22270237\n",
      "Iteration 1969, loss = 2.34752456\n",
      "Iteration 1970, loss = 1.17522285\n",
      "Iteration 1971, loss = 1.06134071\n",
      "Iteration 1972, loss = 0.84320639\n",
      "Iteration 1973, loss = 0.71385557\n",
      "Iteration 1974, loss = 1.18929179\n",
      "Iteration 1975, loss = 0.79698043\n",
      "Iteration 1976, loss = 0.76101197\n",
      "Iteration 1977, loss = 0.78948083\n",
      "Iteration 1978, loss = 0.64692102\n",
      "Iteration 1979, loss = 0.47442324\n",
      "Iteration 1980, loss = 0.47266585\n",
      "Iteration 1981, loss = 0.46153372\n",
      "Iteration 1982, loss = 0.44185101\n",
      "Iteration 1983, loss = 0.26041115\n",
      "Iteration 1984, loss = 0.23787382\n",
      "Iteration 1985, loss = 0.18390409\n",
      "Iteration 1986, loss = 0.16004848\n",
      "Iteration 1987, loss = 0.12657915\n",
      "Iteration 1988, loss = 0.14614997\n",
      "Iteration 1989, loss = 0.14917758\n",
      "Iteration 1990, loss = 0.14225259\n",
      "Iteration 1991, loss = 0.12035776\n",
      "Iteration 1992, loss = 0.12281567\n",
      "Iteration 1993, loss = 0.13100641\n",
      "Iteration 1994, loss = 0.12202726\n",
      "Iteration 1995, loss = 0.12875758\n",
      "Iteration 1996, loss = 0.17628613\n",
      "Iteration 1997, loss = 0.22959624\n",
      "Iteration 1998, loss = 0.20709603\n",
      "Iteration 1999, loss = 0.16787540\n",
      "Iteration 2000, loss = 0.11616348\n",
      "Iteration 2001, loss = 0.12213228\n",
      "Iteration 2002, loss = 0.18631512\n",
      "Iteration 2003, loss = 0.16094314\n",
      "Iteration 2004, loss = 0.25959104\n",
      "Iteration 2005, loss = 0.13147345\n",
      "Iteration 2006, loss = 0.16212758\n",
      "Iteration 2007, loss = 0.15485584\n",
      "Iteration 2008, loss = 0.19922779\n",
      "Iteration 2009, loss = 0.19635297\n",
      "Iteration 2010, loss = 0.16483608\n",
      "Iteration 2011, loss = 0.21204771\n",
      "Iteration 2012, loss = 0.18765073\n",
      "Iteration 2013, loss = 0.17513144\n",
      "Iteration 2014, loss = 0.66408293\n",
      "Iteration 2015, loss = 0.78476415\n",
      "Iteration 2016, loss = 0.68469742\n",
      "Iteration 2017, loss = 1.13650043\n",
      "Iteration 2018, loss = 0.69646413\n",
      "Iteration 2019, loss = 2.12008389\n",
      "Iteration 2020, loss = 1.21481126\n",
      "Iteration 2021, loss = 1.15632102\n",
      "Iteration 2022, loss = 0.72896225\n",
      "Iteration 2023, loss = 1.13316798\n",
      "Iteration 2024, loss = 0.87025058\n",
      "Iteration 2025, loss = 0.94801562\n",
      "Iteration 2026, loss = 0.98196388\n",
      "Iteration 2027, loss = 0.73157420\n",
      "Iteration 2028, loss = 0.39504434\n",
      "Iteration 2029, loss = 0.75991461\n",
      "Iteration 2030, loss = 0.59252392\n",
      "Iteration 2031, loss = 0.45554236\n",
      "Iteration 2032, loss = 0.46363079\n",
      "Iteration 2033, loss = 0.35694759\n",
      "Iteration 2034, loss = 0.34781886\n",
      "Iteration 2035, loss = 0.41811674\n",
      "Iteration 2036, loss = 0.38571734\n",
      "Iteration 2037, loss = 0.25480142\n",
      "Iteration 2038, loss = 0.36004616\n",
      "Iteration 2039, loss = 0.50503605\n",
      "Iteration 2040, loss = 0.28083793\n",
      "Iteration 2041, loss = 0.25197480\n",
      "Iteration 2042, loss = 0.22528339\n",
      "Iteration 2043, loss = 0.27136453\n",
      "Iteration 2044, loss = 0.25759236\n",
      "Iteration 2045, loss = 0.22292351\n",
      "Iteration 2046, loss = 0.23234465\n",
      "Iteration 2047, loss = 0.21726948\n",
      "Iteration 2048, loss = 0.18944055\n",
      "Iteration 2049, loss = 0.16418288\n",
      "Iteration 2050, loss = 0.15398333\n",
      "Iteration 2051, loss = 0.19595749\n",
      "Iteration 2052, loss = 0.23501713\n",
      "Iteration 2053, loss = 0.22544399\n",
      "Iteration 2054, loss = 0.21712205\n",
      "Iteration 2055, loss = 0.18440952\n",
      "Iteration 2056, loss = 0.22190396\n",
      "Iteration 2057, loss = 0.29245249\n",
      "Iteration 2058, loss = 0.19184026\n",
      "Iteration 2059, loss = 0.11194571\n",
      "Iteration 2060, loss = 0.11693232\n",
      "Iteration 2061, loss = 0.17121561\n",
      "Iteration 2062, loss = 0.14502395\n",
      "Iteration 2063, loss = 0.11987518\n",
      "Iteration 2064, loss = 0.10920708\n",
      "Iteration 2065, loss = 0.12829981\n",
      "Iteration 2066, loss = 0.11537451\n",
      "Iteration 2067, loss = 0.13898026\n",
      "Iteration 2068, loss = 0.12349000\n",
      "Iteration 2069, loss = 0.11756553\n",
      "Iteration 2070, loss = 0.12804589\n",
      "Iteration 2071, loss = 0.11189335\n",
      "Iteration 2072, loss = 0.12105798\n",
      "Iteration 2073, loss = 0.13684296\n",
      "Iteration 2074, loss = 0.11315586\n",
      "Iteration 2075, loss = 0.10513815\n",
      "Iteration 2076, loss = 0.10448060\n",
      "Iteration 2077, loss = 0.10658822\n",
      "Iteration 2078, loss = 0.10899584\n",
      "Iteration 2079, loss = 0.10388753\n",
      "Iteration 2080, loss = 0.10750889\n",
      "Iteration 2081, loss = 0.11540360\n",
      "Iteration 2082, loss = 0.10234831\n",
      "Iteration 2083, loss = 0.11120418\n",
      "Iteration 2084, loss = 0.10622241\n",
      "Iteration 2085, loss = 0.10870091\n",
      "Iteration 2086, loss = 0.11040722\n",
      "Iteration 2087, loss = 0.10685825\n",
      "Iteration 2088, loss = 0.12482145\n",
      "Iteration 2089, loss = 0.14733977\n",
      "Iteration 2090, loss = 0.11953676\n",
      "Iteration 2091, loss = 0.11243825\n",
      "Iteration 2092, loss = 0.11820338\n",
      "Iteration 2093, loss = 0.10064889\n",
      "Iteration 2094, loss = 0.11430821\n",
      "Iteration 2095, loss = 0.12013879\n",
      "Iteration 2096, loss = 0.13137087\n",
      "Iteration 2097, loss = 0.13633228\n",
      "Iteration 2098, loss = 0.11895711\n",
      "Iteration 2099, loss = 0.11730388\n",
      "Iteration 2100, loss = 0.10322705\n",
      "Iteration 2101, loss = 0.21066508\n",
      "Iteration 2102, loss = 0.38580665\n",
      "Iteration 2103, loss = 0.26583042\n",
      "Iteration 2104, loss = 0.22221086\n",
      "Iteration 2105, loss = 0.11547251\n",
      "Iteration 2106, loss = 0.18087260\n",
      "Iteration 2107, loss = 0.15150713\n",
      "Iteration 2108, loss = 0.10987067\n",
      "Iteration 2109, loss = 0.11906013\n",
      "Iteration 2110, loss = 0.11430572\n",
      "Iteration 2111, loss = 0.10829822\n",
      "Iteration 2112, loss = 0.11431860\n",
      "Iteration 2113, loss = 0.10900076\n",
      "Iteration 2114, loss = 0.10473262\n",
      "Iteration 2115, loss = 0.10042384\n",
      "Iteration 2116, loss = 0.10449318\n",
      "Iteration 2117, loss = 0.11309902\n",
      "Iteration 2118, loss = 0.10822254\n",
      "Iteration 2119, loss = 0.10896298\n",
      "Iteration 2120, loss = 0.11073093\n",
      "Iteration 2121, loss = 0.11656249\n",
      "Iteration 2122, loss = 0.11066789\n",
      "Iteration 2123, loss = 0.11178425\n",
      "Iteration 2124, loss = 0.11943032\n",
      "Iteration 2125, loss = 0.10599199\n",
      "Iteration 2126, loss = 0.10304221\n",
      "Iteration 2127, loss = 0.10739661\n",
      "Iteration 2128, loss = 0.11256294\n",
      "Iteration 2129, loss = 0.10406466\n",
      "Iteration 2130, loss = 0.10626856\n",
      "Iteration 2131, loss = 0.11957587\n",
      "Iteration 2132, loss = 0.12732551\n",
      "Iteration 2133, loss = 0.12314167\n",
      "Iteration 2134, loss = 0.11275529\n",
      "Iteration 2135, loss = 0.10683650\n",
      "Iteration 2136, loss = 0.10804603\n",
      "Iteration 2137, loss = 0.11263930\n",
      "Iteration 2138, loss = 0.11296278\n",
      "Iteration 2139, loss = 0.12595367\n",
      "Iteration 2140, loss = 0.10994470\n",
      "Iteration 2141, loss = 0.13182362\n",
      "Iteration 2142, loss = 0.10953752\n",
      "Iteration 2143, loss = 0.12916135\n",
      "Iteration 2144, loss = 0.10490354\n",
      "Iteration 2145, loss = 0.10100074\n",
      "Iteration 2146, loss = 0.12884423\n",
      "Iteration 2147, loss = 0.11631708\n",
      "Iteration 2148, loss = 0.12608828\n",
      "Iteration 2149, loss = 0.13229601\n",
      "Iteration 2150, loss = 0.12565796\n",
      "Iteration 2151, loss = 0.12088027\n",
      "Iteration 2152, loss = 0.11333795\n",
      "Iteration 2153, loss = 0.10524614\n",
      "Iteration 2154, loss = 0.11044800\n",
      "Iteration 2155, loss = 0.12794877\n",
      "Iteration 2156, loss = 0.11409269\n",
      "Iteration 2157, loss = 0.10275309\n",
      "Iteration 2158, loss = 0.10547813\n",
      "Iteration 2159, loss = 0.10250445\n",
      "Iteration 2160, loss = 0.11069410\n",
      "Iteration 2161, loss = 0.10568697\n",
      "Iteration 2162, loss = 0.10979375\n",
      "Iteration 2163, loss = 0.10860086\n",
      "Iteration 2164, loss = 0.11169816\n",
      "Iteration 2165, loss = 0.11150389\n",
      "Iteration 2166, loss = 0.11666919\n",
      "Iteration 2167, loss = 0.10420407\n",
      "Iteration 2168, loss = 0.10615060\n",
      "Iteration 2169, loss = 0.11894753\n",
      "Iteration 2170, loss = 0.10462592\n",
      "Iteration 2171, loss = 0.10758560\n",
      "Iteration 2172, loss = 0.10606994\n",
      "Iteration 2173, loss = 0.11074491\n",
      "Iteration 2174, loss = 0.12204891\n",
      "Iteration 2175, loss = 0.10896909\n",
      "Iteration 2176, loss = 0.10498278\n",
      "Iteration 2177, loss = 0.11306163\n",
      "Iteration 2178, loss = 0.12737229\n",
      "Iteration 2179, loss = 0.12812699\n",
      "Iteration 2180, loss = 0.10669331\n",
      "Iteration 2181, loss = 0.10540955\n",
      "Iteration 2182, loss = 0.11319312\n",
      "Iteration 2183, loss = 0.10536673\n",
      "Iteration 2184, loss = 0.10576169\n",
      "Iteration 2185, loss = 0.10580536\n",
      "Iteration 2186, loss = 0.13622663\n",
      "Iteration 2187, loss = 0.11835031\n",
      "Iteration 2188, loss = 0.11476081\n",
      "Iteration 2189, loss = 0.12997906\n",
      "Iteration 2190, loss = 0.10614590\n",
      "Iteration 2191, loss = 0.10310685\n",
      "Iteration 2192, loss = 0.11270834\n",
      "Iteration 2193, loss = 0.10892942\n",
      "Iteration 2194, loss = 0.10082655\n",
      "Iteration 2195, loss = 0.10808284\n",
      "Iteration 2196, loss = 0.10043178\n",
      "Iteration 2197, loss = 0.10379842\n",
      "Iteration 2198, loss = 0.10269849\n",
      "Iteration 2199, loss = 0.11864881\n",
      "Iteration 2200, loss = 0.10755804\n",
      "Iteration 2201, loss = 0.10970930\n",
      "Iteration 2202, loss = 0.11433183\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 2203, loss = 0.11428722\n",
      "Iteration 2204, loss = 0.10925206\n",
      "Iteration 2205, loss = 0.11228300\n",
      "Iteration 2206, loss = 0.12150254\n",
      "Iteration 2207, loss = 0.14148918\n",
      "Iteration 2208, loss = 0.17150327\n",
      "Iteration 2209, loss = 0.14422938\n",
      "Iteration 2210, loss = 0.20729951\n",
      "Iteration 2211, loss = 0.18732560\n",
      "Iteration 2212, loss = 0.19810719\n",
      "Iteration 2213, loss = 0.16149813\n",
      "Iteration 2214, loss = 0.19660349\n",
      "Iteration 2215, loss = 0.13552664\n",
      "Iteration 2216, loss = 0.10997879\n",
      "Iteration 2217, loss = 0.15179175\n",
      "Iteration 2218, loss = 0.11060134\n",
      "Iteration 2219, loss = 0.10829002\n",
      "Iteration 2220, loss = 0.10882011\n",
      "Iteration 2221, loss = 0.10728292\n",
      "Iteration 2222, loss = 0.11428636\n",
      "Iteration 2223, loss = 0.11353540\n",
      "Iteration 2224, loss = 0.12143222\n",
      "Iteration 2225, loss = 0.11750620\n",
      "Iteration 2226, loss = 0.11598920\n",
      "Iteration 2227, loss = 0.10442665\n",
      "Iteration 2228, loss = 0.10653481\n",
      "Iteration 2229, loss = 0.10718606\n",
      "Iteration 2230, loss = 0.10601474\n",
      "Iteration 2231, loss = 0.10153710\n",
      "Iteration 2232, loss = 0.10363795\n",
      "Iteration 2233, loss = 0.10859992\n",
      "Iteration 2234, loss = 0.10052931\n",
      "Iteration 2235, loss = 0.11757850\n",
      "Iteration 2236, loss = 0.10589560\n",
      "Iteration 2237, loss = 0.12429550\n",
      "Iteration 2238, loss = 0.11175604\n",
      "Iteration 2239, loss = 0.11192048\n",
      "Iteration 2240, loss = 0.10444039\n",
      "Iteration 2241, loss = 0.11033189\n",
      "Iteration 2242, loss = 0.10904701\n",
      "Iteration 2243, loss = 0.10191017\n",
      "Iteration 2244, loss = 0.10474582\n",
      "Iteration 2245, loss = 0.11869334\n",
      "Iteration 2246, loss = 0.13900348\n",
      "Iteration 2247, loss = 0.18439733\n",
      "Iteration 2248, loss = 0.13889679\n",
      "Iteration 2249, loss = 0.14314060\n",
      "Iteration 2250, loss = 0.16844561\n",
      "Iteration 2251, loss = 0.13137011\n",
      "Iteration 2252, loss = 0.11763935\n",
      "Iteration 2253, loss = 0.14531185\n",
      "Iteration 2254, loss = 0.14260095\n",
      "Iteration 2255, loss = 0.13089620\n",
      "Iteration 2256, loss = 0.13090701\n",
      "Iteration 2257, loss = 0.10949923\n",
      "Iteration 2258, loss = 0.10510837\n",
      "Iteration 2259, loss = 0.14071006\n",
      "Iteration 2260, loss = 0.11988904\n",
      "Iteration 2261, loss = 0.12559887\n",
      "Iteration 2262, loss = 0.15355814\n",
      "Iteration 2263, loss = 0.11245782\n",
      "Iteration 2264, loss = 0.10524652\n",
      "Iteration 2265, loss = 0.11833019\n",
      "Iteration 2266, loss = 0.11700993\n",
      "Iteration 2267, loss = 0.17395113\n",
      "Iteration 2268, loss = 0.12476209\n",
      "Iteration 2269, loss = 0.20287661\n",
      "Iteration 2270, loss = 0.28389411\n",
      "Iteration 2271, loss = 0.47961856\n",
      "Iteration 2272, loss = 0.15199951\n",
      "Iteration 2273, loss = 0.14800409\n",
      "Iteration 2274, loss = 1.44351397\n",
      "Iteration 2275, loss = 2.91984803\n",
      "Iteration 2276, loss = 1.85190504\n",
      "Iteration 2277, loss = 2.01744881\n",
      "Iteration 2278, loss = 1.41699753\n",
      "Iteration 2279, loss = 2.82725764\n",
      "Iteration 2280, loss = 1.57959327\n",
      "Iteration 2281, loss = 1.14997750\n",
      "Iteration 2282, loss = 1.58477571\n",
      "Iteration 2283, loss = 0.98387517\n",
      "Iteration 2284, loss = 1.47262143\n",
      "Iteration 2285, loss = 1.05571759\n",
      "Iteration 2286, loss = 1.58384014\n",
      "Iteration 2287, loss = 0.70760311\n",
      "Iteration 2288, loss = 0.90121476\n",
      "Iteration 2289, loss = 0.86447356\n",
      "Iteration 2290, loss = 0.82150961\n",
      "Iteration 2291, loss = 1.08863688\n",
      "Iteration 2292, loss = 0.66967798\n",
      "Iteration 2293, loss = 0.40155504\n",
      "Iteration 2294, loss = 0.48473918\n",
      "Iteration 2295, loss = 0.43435532\n",
      "Iteration 2296, loss = 0.26299377\n",
      "Iteration 2297, loss = 0.25239988\n",
      "Iteration 2298, loss = 0.19817700\n",
      "Iteration 2299, loss = 0.19939325\n",
      "Iteration 2300, loss = 0.21837459\n",
      "Iteration 2301, loss = 0.24105546\n",
      "Iteration 2302, loss = 0.24288639\n",
      "Iteration 2303, loss = 0.16413897\n",
      "Iteration 2304, loss = 0.24334785\n",
      "Iteration 2305, loss = 0.28468643\n",
      "Iteration 2306, loss = 0.28781990\n",
      "Iteration 2307, loss = 0.44220504\n",
      "Iteration 2308, loss = 0.47507403\n",
      "Iteration 2309, loss = 0.42010312\n",
      "Iteration 2310, loss = 0.32447350\n",
      "Iteration 2311, loss = 0.34907870\n",
      "Iteration 2312, loss = 0.21225937\n",
      "Iteration 2313, loss = 0.23538378\n",
      "Iteration 2314, loss = 0.17693755\n",
      "Iteration 2315, loss = 0.36851532\n",
      "Iteration 2316, loss = 0.26815778\n",
      "Iteration 2317, loss = 0.52229567\n",
      "Iteration 2318, loss = 0.30923119\n",
      "Iteration 2319, loss = 0.21619991\n",
      "Iteration 2320, loss = 0.18224688\n",
      "Iteration 2321, loss = 0.39232726\n",
      "Iteration 2322, loss = 0.49796579\n",
      "Iteration 2323, loss = 0.45880365\n",
      "Iteration 2324, loss = 0.28724558\n",
      "Iteration 2325, loss = 0.18562933\n",
      "Iteration 2326, loss = 0.32586197\n",
      "Iteration 2327, loss = 0.25942436\n",
      "Iteration 2328, loss = 0.22667162\n",
      "Iteration 2329, loss = 0.32667024\n",
      "Iteration 2330, loss = 0.50136808\n",
      "Iteration 2331, loss = 0.26733134\n",
      "Iteration 2332, loss = 0.27906526\n",
      "Iteration 2333, loss = 0.14457408\n",
      "Iteration 2334, loss = 0.22151074\n",
      "Iteration 2335, loss = 0.17927702\n",
      "Iteration 2336, loss = 0.20273260\n",
      "Iteration 2337, loss = 0.16250720\n",
      "Iteration 2338, loss = 0.16424957\n",
      "Iteration 2339, loss = 0.20208978\n",
      "Iteration 2340, loss = 0.20222929\n",
      "Iteration 2341, loss = 0.16014575\n",
      "Iteration 2342, loss = 0.14442799\n",
      "Iteration 2343, loss = 0.25906817\n",
      "Iteration 2344, loss = 0.21042447\n",
      "Iteration 2345, loss = 0.16581878\n",
      "Iteration 2346, loss = 0.15262975\n",
      "Iteration 2347, loss = 0.16532479\n",
      "Iteration 2348, loss = 0.12530647\n",
      "Iteration 2349, loss = 0.12811132\n",
      "Iteration 2350, loss = 0.12980550\n",
      "Iteration 2351, loss = 0.13128794\n",
      "Iteration 2352, loss = 0.16890475\n",
      "Iteration 2353, loss = 0.18197225\n",
      "Iteration 2354, loss = 0.14108853\n",
      "Iteration 2355, loss = 0.16371991\n",
      "Iteration 2356, loss = 0.13219565\n",
      "Iteration 2357, loss = 0.11419658\n",
      "Iteration 2358, loss = 0.12170462\n",
      "Iteration 2359, loss = 0.11958425\n",
      "Iteration 2360, loss = 0.12332366\n",
      "Iteration 2361, loss = 0.13093813\n",
      "Iteration 2362, loss = 0.12260083\n",
      "Iteration 2363, loss = 0.12421855\n",
      "Iteration 2364, loss = 0.13189204\n",
      "Iteration 2365, loss = 0.12193404\n",
      "Iteration 2366, loss = 0.14670689\n",
      "Iteration 2367, loss = 0.15039966\n",
      "Iteration 2368, loss = 0.28471012\n",
      "Iteration 2369, loss = 0.51858930\n",
      "Iteration 2370, loss = 0.44920474\n",
      "Iteration 2371, loss = 0.37328680\n",
      "Iteration 2372, loss = 0.33190136\n",
      "Iteration 2373, loss = 0.28607368\n",
      "Iteration 2374, loss = 0.20002470\n",
      "Iteration 2375, loss = 0.15975584\n",
      "Iteration 2376, loss = 0.14731887\n",
      "Iteration 2377, loss = 0.14925332\n",
      "Iteration 2378, loss = 0.13801566\n",
      "Iteration 2379, loss = 0.13049941\n",
      "Iteration 2380, loss = 0.12646045\n",
      "Iteration 2381, loss = 0.14988283\n",
      "Iteration 2382, loss = 0.13125223\n",
      "Iteration 2383, loss = 0.16282650\n",
      "Iteration 2384, loss = 0.12767909\n",
      "Iteration 2385, loss = 0.13455252\n",
      "Iteration 2386, loss = 0.11093054\n",
      "Iteration 2387, loss = 0.14056802\n",
      "Iteration 2388, loss = 0.10213656\n",
      "Iteration 2389, loss = 0.12145433\n",
      "Iteration 2390, loss = 0.11225382\n",
      "Iteration 2391, loss = 0.11431953\n",
      "Iteration 2392, loss = 0.11833645\n",
      "Iteration 2393, loss = 0.11908026\n",
      "Iteration 2394, loss = 0.11873601\n",
      "Iteration 2395, loss = 0.10234309\n",
      "Iteration 2396, loss = 0.10565332\n",
      "Iteration 2397, loss = 0.10506900\n",
      "Iteration 2398, loss = 0.11833743\n",
      "Iteration 2399, loss = 0.10646152\n",
      "Iteration 2400, loss = 0.11295181\n",
      "Iteration 2401, loss = 0.10476444\n",
      "Iteration 2402, loss = 0.10970886\n",
      "Iteration 2403, loss = 0.11969355\n",
      "Iteration 2404, loss = 0.10577912\n",
      "Iteration 2405, loss = 0.11162569\n",
      "Iteration 2406, loss = 0.11339696\n",
      "Iteration 2407, loss = 0.10822756\n",
      "Iteration 2408, loss = 0.12926585\n",
      "Iteration 2409, loss = 0.11223529\n",
      "Iteration 2410, loss = 0.15397684\n",
      "Iteration 2411, loss = 0.13922812\n",
      "Iteration 2412, loss = 0.16600523\n",
      "Iteration 2413, loss = 0.21490026\n",
      "Iteration 2414, loss = 0.39172842\n",
      "Iteration 2415, loss = 0.42631641\n",
      "Iteration 2416, loss = 0.22100194\n",
      "Iteration 2417, loss = 0.22000779\n",
      "Iteration 2418, loss = 0.27900147\n",
      "Iteration 2419, loss = 0.19443109\n",
      "Iteration 2420, loss = 0.29087687\n",
      "Iteration 2421, loss = 0.47873912\n",
      "Iteration 2422, loss = 0.60204383\n",
      "Iteration 2423, loss = 0.33533117\n",
      "Iteration 2424, loss = 0.65632492\n",
      "Iteration 2425, loss = 0.87107612\n",
      "Iteration 2426, loss = 0.92353740\n",
      "Iteration 2427, loss = 1.39153457\n",
      "Iteration 2428, loss = 0.99214519\n",
      "Iteration 2429, loss = 0.72727001\n",
      "Iteration 2430, loss = 0.66684730\n",
      "Iteration 2431, loss = 0.93046913\n",
      "Iteration 2432, loss = 0.72477271\n",
      "Iteration 2433, loss = 0.75229041\n",
      "Iteration 2434, loss = 0.62026092\n",
      "Iteration 2435, loss = 0.55791263\n",
      "Iteration 2436, loss = 0.31822515\n",
      "Iteration 2437, loss = 0.49129198\n",
      "Iteration 2438, loss = 0.36767226\n",
      "Iteration 2439, loss = 0.27236959\n",
      "Iteration 2440, loss = 0.23475827\n",
      "Iteration 2441, loss = 0.20189554\n",
      "Iteration 2442, loss = 0.32392490\n",
      "Iteration 2443, loss = 0.58717507\n",
      "Iteration 2444, loss = 0.55220147\n",
      "Iteration 2445, loss = 0.47498876\n",
      "Iteration 2446, loss = 0.26895556\n",
      "Iteration 2447, loss = 0.26042157\n",
      "Iteration 2448, loss = 0.23061689\n",
      "Iteration 2449, loss = 0.18398123\n",
      "Iteration 2450, loss = 0.13904191\n",
      "Iteration 2451, loss = 0.17499483\n",
      "Iteration 2452, loss = 0.15442026\n",
      "Iteration 2453, loss = 0.12543652\n",
      "Iteration 2454, loss = 0.14256843\n",
      "Iteration 2455, loss = 0.11973254\n",
      "Iteration 2456, loss = 0.19617707\n",
      "Iteration 2457, loss = 0.20532798\n",
      "Iteration 2458, loss = 0.13991832\n",
      "Iteration 2459, loss = 0.18551590\n",
      "Iteration 2460, loss = 0.18210650\n",
      "Iteration 2461, loss = 0.16026667\n",
      "Iteration 2462, loss = 0.18947954\n",
      "Iteration 2463, loss = 0.12487306\n",
      "Iteration 2464, loss = 0.11694112\n",
      "Iteration 2465, loss = 0.11928969\n",
      "Iteration 2466, loss = 0.12929300\n",
      "Iteration 2467, loss = 0.16792340\n",
      "Iteration 2468, loss = 0.14077461\n",
      "Iteration 2469, loss = 0.14648131\n",
      "Iteration 2470, loss = 0.15336717\n",
      "Iteration 2471, loss = 0.12254865\n",
      "Iteration 2472, loss = 0.13148539\n",
      "Iteration 2473, loss = 0.12892087\n",
      "Iteration 2474, loss = 0.12205525\n",
      "Iteration 2475, loss = 0.12289723\n",
      "Iteration 2476, loss = 0.13447999\n",
      "Iteration 2477, loss = 0.13667045\n",
      "Iteration 2478, loss = 0.19824900\n",
      "Iteration 2479, loss = 0.52280931\n",
      "Iteration 2480, loss = 0.58790593\n",
      "Iteration 2481, loss = 0.50668373\n",
      "Iteration 2482, loss = 0.27584725\n",
      "Iteration 2483, loss = 0.24816237\n",
      "Iteration 2484, loss = 0.37937669\n",
      "Iteration 2485, loss = 0.36887220\n",
      "Iteration 2486, loss = 0.21750948\n",
      "Iteration 2487, loss = 0.35845985\n",
      "Iteration 2488, loss = 0.29899193\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 2489, loss = 0.30455802\n",
      "Iteration 2490, loss = 0.22651856\n",
      "Iteration 2491, loss = 0.25638024\n",
      "Iteration 2492, loss = 0.41181726\n",
      "Iteration 2493, loss = 0.34410526\n",
      "Iteration 2494, loss = 0.18777920\n",
      "Iteration 2495, loss = 0.12554859\n",
      "Iteration 2496, loss = 0.12614700\n",
      "Iteration 2497, loss = 0.28602622\n",
      "Iteration 2498, loss = 0.16603632\n",
      "Iteration 2499, loss = 0.21169328\n",
      "Iteration 2500, loss = 0.22519278\n",
      "Iteration 2501, loss = 0.16335777\n",
      "Iteration 2502, loss = 0.12736470\n",
      "Iteration 2503, loss = 0.13448535\n",
      "Iteration 2504, loss = 0.11526648\n",
      "Iteration 2505, loss = 0.15878009\n",
      "Iteration 2506, loss = 0.21358240\n",
      "Iteration 2507, loss = 0.16703663\n",
      "Iteration 2508, loss = 0.12309218\n",
      "Iteration 2509, loss = 0.13309909\n",
      "Iteration 2510, loss = 0.13889146\n",
      "Iteration 2511, loss = 0.12931368\n",
      "Iteration 2512, loss = 0.12933799\n",
      "Iteration 2513, loss = 0.20694809\n",
      "Iteration 2514, loss = 0.12472302\n",
      "Iteration 2515, loss = 0.11039303\n",
      "Iteration 2516, loss = 0.11405438\n",
      "Iteration 2517, loss = 0.10992704\n",
      "Iteration 2518, loss = 0.13755265\n",
      "Iteration 2519, loss = 0.18946634\n",
      "Iteration 2520, loss = 0.18547794\n",
      "Iteration 2521, loss = 0.13016464\n",
      "Iteration 2522, loss = 0.14443058\n",
      "Iteration 2523, loss = 0.12226891\n",
      "Iteration 2524, loss = 0.11040681\n",
      "Iteration 2525, loss = 0.10522480\n",
      "Iteration 2526, loss = 0.10687063\n",
      "Iteration 2527, loss = 0.11840828\n",
      "Iteration 2528, loss = 0.11725128\n",
      "Iteration 2529, loss = 0.11674824\n",
      "Iteration 2530, loss = 0.11106283\n",
      "Iteration 2531, loss = 0.10227669\n",
      "Iteration 2532, loss = 0.12368622\n",
      "Iteration 2533, loss = 0.11365540\n",
      "Iteration 2534, loss = 0.11581012\n",
      "Iteration 2535, loss = 0.12419822\n",
      "Iteration 2536, loss = 0.11675261\n",
      "Iteration 2537, loss = 0.12917244\n",
      "Iteration 2538, loss = 0.11364980\n",
      "Iteration 2539, loss = 0.11125069\n",
      "Iteration 2540, loss = 0.10367686\n",
      "Iteration 2541, loss = 0.12913497\n",
      "Iteration 2542, loss = 0.10547526\n",
      "Iteration 2543, loss = 0.11946757\n",
      "Iteration 2544, loss = 0.12928412\n",
      "Iteration 2545, loss = 0.11195951\n",
      "Iteration 2546, loss = 0.11149982\n",
      "Iteration 2547, loss = 0.10540470\n",
      "Iteration 2548, loss = 0.10376477\n",
      "Iteration 2549, loss = 0.10413524\n",
      "Iteration 2550, loss = 0.10104689\n",
      "Iteration 2551, loss = 0.12595082\n",
      "Iteration 2552, loss = 0.18694657\n",
      "Iteration 2553, loss = 0.15688122\n",
      "Iteration 2554, loss = 0.23565902\n",
      "Iteration 2555, loss = 0.29247184\n",
      "Iteration 2556, loss = 0.17898000\n",
      "Iteration 2557, loss = 0.17127775\n",
      "Iteration 2558, loss = 0.22767504\n",
      "Iteration 2559, loss = 0.20256883\n",
      "Iteration 2560, loss = 0.30280396\n",
      "Iteration 2561, loss = 0.16894770\n",
      "Iteration 2562, loss = 0.14686024\n",
      "Iteration 2563, loss = 0.17311646\n",
      "Iteration 2564, loss = 0.14044081\n",
      "Iteration 2565, loss = 0.34376450\n",
      "Iteration 2566, loss = 0.29874215\n",
      "Iteration 2567, loss = 0.19567704\n",
      "Iteration 2568, loss = 0.13151493\n",
      "Iteration 2569, loss = 0.11811161\n",
      "Iteration 2570, loss = 0.14126633\n",
      "Iteration 2571, loss = 0.12399389\n",
      "Iteration 2572, loss = 0.10197609\n",
      "Iteration 2573, loss = 0.10153356\n",
      "Iteration 2574, loss = 0.12451579\n",
      "Iteration 2575, loss = 0.11006304\n",
      "Iteration 2576, loss = 0.10232352\n",
      "Iteration 2577, loss = 0.11045619\n",
      "Iteration 2578, loss = 0.11560067\n",
      "Iteration 2579, loss = 0.12420440\n",
      "Iteration 2580, loss = 0.16816217\n",
      "Iteration 2581, loss = 0.18039916\n",
      "Iteration 2582, loss = 0.16519487\n",
      "Iteration 2583, loss = 0.18821978\n",
      "Iteration 2584, loss = 0.17504831\n",
      "Iteration 2585, loss = 0.13416453\n",
      "Iteration 2586, loss = 0.10525829\n",
      "Iteration 2587, loss = 0.12385008\n",
      "Iteration 2588, loss = 0.10514718\n",
      "Iteration 2589, loss = 0.10891110\n",
      "Iteration 2590, loss = 0.10794531\n",
      "Iteration 2591, loss = 0.11808100\n",
      "Iteration 2592, loss = 0.11696286\n",
      "Iteration 2593, loss = 0.11494058\n",
      "Iteration 2594, loss = 0.10777867\n",
      "Iteration 2595, loss = 0.10366390\n",
      "Iteration 2596, loss = 0.12364653\n",
      "Iteration 2597, loss = 0.12650790\n",
      "Iteration 2598, loss = 0.11026163\n",
      "Iteration 2599, loss = 0.10807354\n",
      "Iteration 2600, loss = 0.10610592\n",
      "Iteration 2601, loss = 0.10945334\n",
      "Iteration 2602, loss = 0.11595415\n",
      "Iteration 2603, loss = 0.11070204\n",
      "Iteration 2604, loss = 0.10904173\n",
      "Iteration 2605, loss = 0.11845680\n",
      "Iteration 2606, loss = 0.11732723\n",
      "Iteration 2607, loss = 0.10362943\n",
      "Iteration 2608, loss = 0.11675342\n",
      "Iteration 2609, loss = 0.12083724\n",
      "Iteration 2610, loss = 0.11426047\n",
      "Iteration 2611, loss = 0.10650201\n",
      "Iteration 2612, loss = 0.12635385\n",
      "Iteration 2613, loss = 0.11768893\n",
      "Iteration 2614, loss = 0.11181828\n",
      "Iteration 2615, loss = 0.12633999\n",
      "Iteration 2616, loss = 0.11088742\n",
      "Iteration 2617, loss = 0.12255824\n",
      "Iteration 2618, loss = 0.10624150\n",
      "Iteration 2619, loss = 0.11620188\n",
      "Iteration 2620, loss = 0.10880266\n",
      "Iteration 2621, loss = 0.12579301\n",
      "Iteration 2622, loss = 0.13148958\n",
      "Iteration 2623, loss = 0.14480173\n",
      "Iteration 2624, loss = 0.14238134\n",
      "Iteration 2625, loss = 0.11964907\n",
      "Iteration 2626, loss = 0.11916414\n",
      "Iteration 2627, loss = 0.11131316\n",
      "Iteration 2628, loss = 0.10572358\n",
      "Iteration 2629, loss = 0.10325450\n",
      "Iteration 2630, loss = 0.10173534\n",
      "Iteration 2631, loss = 0.10545794\n",
      "Iteration 2632, loss = 0.10344028\n",
      "Iteration 2633, loss = 0.10784126\n",
      "Iteration 2634, loss = 0.10244154\n",
      "Iteration 2635, loss = 0.10362818\n",
      "Iteration 2636, loss = 0.10605949\n",
      "Iteration 2637, loss = 0.11275115\n",
      "Iteration 2638, loss = 0.11217619\n",
      "Iteration 2639, loss = 0.10343001\n",
      "Iteration 2640, loss = 0.10817278\n",
      "Iteration 2641, loss = 0.11631548\n",
      "Iteration 2642, loss = 0.11073979\n",
      "Iteration 2643, loss = 0.10583495\n",
      "Iteration 2644, loss = 0.10056394\n",
      "Iteration 2645, loss = 0.10357306\n",
      "Iteration 2646, loss = 0.10846892\n",
      "Iteration 2647, loss = 0.11878099\n",
      "Iteration 2648, loss = 0.10684482\n",
      "Iteration 2649, loss = 0.10860392\n",
      "Iteration 2650, loss = 0.09967698\n",
      "Iteration 2651, loss = 0.11094545\n",
      "Iteration 2652, loss = 0.10902747\n",
      "Iteration 2653, loss = 0.10918089\n",
      "Iteration 2654, loss = 0.10942280\n",
      "Iteration 2655, loss = 0.10916161\n",
      "Iteration 2656, loss = 0.10413158\n",
      "Iteration 2657, loss = 0.10273347\n",
      "Iteration 2658, loss = 0.10332209\n",
      "Iteration 2659, loss = 0.10995721\n",
      "Iteration 2660, loss = 0.10607588\n",
      "Iteration 2661, loss = 0.10985965\n",
      "Iteration 2662, loss = 0.10863820\n",
      "Iteration 2663, loss = 0.10789490\n",
      "Iteration 2664, loss = 0.14431134\n",
      "Iteration 2665, loss = 0.11881177\n",
      "Iteration 2666, loss = 0.11647992\n",
      "Iteration 2667, loss = 0.12219204\n",
      "Iteration 2668, loss = 0.11594081\n",
      "Iteration 2669, loss = 0.11540752\n",
      "Iteration 2670, loss = 0.10277857\n",
      "Iteration 2671, loss = 0.12732765\n",
      "Iteration 2672, loss = 0.11756485\n",
      "Iteration 2673, loss = 0.12133394\n",
      "Iteration 2674, loss = 0.13017486\n",
      "Iteration 2675, loss = 0.12982543\n",
      "Iteration 2676, loss = 0.10318686\n",
      "Iteration 2677, loss = 0.12689824\n",
      "Iteration 2678, loss = 0.11149236\n",
      "Iteration 2679, loss = 0.13111086\n",
      "Iteration 2680, loss = 0.16422750\n",
      "Iteration 2681, loss = 0.39285774\n",
      "Iteration 2682, loss = 0.80751119\n",
      "Iteration 2683, loss = 0.77758231\n",
      "Iteration 2684, loss = 1.67515033\n",
      "Iteration 2685, loss = 1.41679351\n",
      "Iteration 2686, loss = 1.04366795\n",
      "Iteration 2687, loss = 0.71213709\n",
      "Iteration 2688, loss = 1.08993855\n",
      "Iteration 2689, loss = 0.91811196\n",
      "Iteration 2690, loss = 0.73921005\n",
      "Iteration 2691, loss = 1.12444805\n",
      "Iteration 2692, loss = 0.67512070\n",
      "Iteration 2693, loss = 0.84899897\n",
      "Iteration 2694, loss = 1.11692287\n",
      "Iteration 2695, loss = 1.14807882\n",
      "Iteration 2696, loss = 0.76246069\n",
      "Iteration 2697, loss = 0.65910120\n",
      "Iteration 2698, loss = 1.04013195\n",
      "Iteration 2699, loss = 0.94301808\n",
      "Iteration 2700, loss = 0.55967107\n",
      "Iteration 2701, loss = 1.95978895\n",
      "Iteration 2702, loss = 1.59594298\n",
      "Iteration 2703, loss = 1.55149792\n",
      "Iteration 2704, loss = 1.41593482\n",
      "Iteration 2705, loss = 1.24531457\n",
      "Iteration 2706, loss = 1.43619119\n",
      "Iteration 2707, loss = 0.66768229\n",
      "Iteration 2708, loss = 0.85642725\n",
      "Iteration 2709, loss = 0.97950213\n",
      "Iteration 2710, loss = 0.88163001\n",
      "Iteration 2711, loss = 0.56920815\n",
      "Iteration 2712, loss = 0.92596210\n",
      "Iteration 2713, loss = 0.72527548\n",
      "Iteration 2714, loss = 0.88420585\n",
      "Iteration 2715, loss = 0.54408115\n",
      "Iteration 2716, loss = 0.74805007\n",
      "Iteration 2717, loss = 0.44752202\n",
      "Iteration 2718, loss = 0.33214880\n",
      "Iteration 2719, loss = 0.46198017\n",
      "Iteration 2720, loss = 0.52244215\n",
      "Iteration 2721, loss = 0.50681604\n",
      "Iteration 2722, loss = 0.36746677\n",
      "Iteration 2723, loss = 0.41067329\n",
      "Iteration 2724, loss = 0.34205141\n",
      "Iteration 2725, loss = 0.26491277\n",
      "Iteration 2726, loss = 0.42373869\n",
      "Iteration 2727, loss = 0.57230103\n",
      "Iteration 2728, loss = 0.52007986\n",
      "Iteration 2729, loss = 0.43088985\n",
      "Iteration 2730, loss = 0.29772036\n",
      "Iteration 2731, loss = 0.30856037\n",
      "Iteration 2732, loss = 0.28100742\n",
      "Iteration 2733, loss = 0.33067087\n",
      "Iteration 2734, loss = 0.21895585\n",
      "Iteration 2735, loss = 0.13208374\n",
      "Iteration 2736, loss = 0.13903691\n",
      "Iteration 2737, loss = 0.10989012\n",
      "Iteration 2738, loss = 0.15389980\n",
      "Iteration 2739, loss = 0.19718497\n",
      "Iteration 2740, loss = 0.16044159\n",
      "Iteration 2741, loss = 0.16079615\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 2742, loss = 0.15048411\n",
      "Iteration 2743, loss = 0.11239315\n",
      "Iteration 2744, loss = 0.13813705\n",
      "Iteration 2745, loss = 0.12379096\n",
      "Iteration 2746, loss = 0.11106367\n",
      "Iteration 2747, loss = 0.11560464\n",
      "Iteration 2748, loss = 0.11672943\n",
      "Iteration 2749, loss = 0.11593783\n",
      "Iteration 2750, loss = 0.10747112\n",
      "Iteration 2751, loss = 0.10367196\n",
      "Iteration 2752, loss = 0.11053861\n",
      "Iteration 2753, loss = 0.10971924\n",
      "Iteration 2754, loss = 0.12687288\n",
      "Iteration 2755, loss = 0.10498528\n",
      "Iteration 2756, loss = 0.10828161\n",
      "Iteration 2757, loss = 0.10911633\n",
      "Iteration 2758, loss = 0.11247381\n",
      "Iteration 2759, loss = 0.14996151\n",
      "Iteration 2760, loss = 0.12902720\n",
      "Iteration 2761, loss = 0.14382869\n",
      "Iteration 2762, loss = 0.13528969\n",
      "Iteration 2763, loss = 0.10494517\n",
      "Iteration 2764, loss = 0.11608169\n",
      "Iteration 2765, loss = 0.13271271\n",
      "Iteration 2766, loss = 0.12057788\n",
      "Iteration 2767, loss = 0.13919943\n",
      "Iteration 2768, loss = 0.13293672\n",
      "Iteration 2769, loss = 0.10530626\n",
      "Iteration 2770, loss = 0.10839693\n",
      "Iteration 2771, loss = 0.10354139\n",
      "Iteration 2772, loss = 0.10856230\n",
      "Iteration 2773, loss = 0.10759316\n",
      "Iteration 2774, loss = 0.11273741\n",
      "Iteration 2775, loss = 0.11820364\n",
      "Iteration 2776, loss = 0.10773202\n",
      "Iteration 2777, loss = 0.11023579\n",
      "Iteration 2778, loss = 0.11080064\n",
      "Iteration 2779, loss = 0.11250033\n",
      "Iteration 2780, loss = 0.11267309\n",
      "Iteration 2781, loss = 0.14941815\n",
      "Iteration 2782, loss = 0.11099704\n",
      "Iteration 2783, loss = 0.42751771\n",
      "Iteration 2784, loss = 0.87870130\n",
      "Iteration 2785, loss = 0.58023727\n",
      "Iteration 2786, loss = 0.61527477\n",
      "Iteration 2787, loss = 0.41289719\n",
      "Iteration 2788, loss = 0.17659835\n",
      "Iteration 2789, loss = 0.27080287\n",
      "Iteration 2790, loss = 0.31663026\n",
      "Iteration 2791, loss = 0.18558164\n",
      "Iteration 2792, loss = 0.20556960\n",
      "Iteration 2793, loss = 0.30219583\n",
      "Iteration 2794, loss = 0.29142867\n",
      "Iteration 2795, loss = 0.15252616\n",
      "Iteration 2796, loss = 0.12879151\n",
      "Iteration 2797, loss = 0.12971992\n",
      "Iteration 2798, loss = 0.11391201\n",
      "Iteration 2799, loss = 0.10885816\n",
      "Iteration 2800, loss = 0.10429554\n",
      "Iteration 2801, loss = 0.13087007\n",
      "Iteration 2802, loss = 0.10977760\n",
      "Iteration 2803, loss = 0.12265445\n",
      "Iteration 2804, loss = 0.14656992\n",
      "Iteration 2805, loss = 0.12528060\n",
      "Iteration 2806, loss = 0.11708947\n",
      "Iteration 2807, loss = 0.12109792\n",
      "Iteration 2808, loss = 0.10388742\n",
      "Iteration 2809, loss = 0.12221439\n",
      "Iteration 2810, loss = 0.12820778\n",
      "Iteration 2811, loss = 0.12695877\n",
      "Iteration 2812, loss = 0.13886212\n",
      "Iteration 2813, loss = 0.10501428\n",
      "Iteration 2814, loss = 0.11936411\n",
      "Iteration 2815, loss = 0.12864031\n",
      "Iteration 2816, loss = 0.11059599\n",
      "Iteration 2817, loss = 0.11672891\n",
      "Iteration 2818, loss = 0.10818813\n",
      "Iteration 2819, loss = 0.11859026\n",
      "Iteration 2820, loss = 0.11431238\n",
      "Iteration 2821, loss = 0.11773998\n",
      "Iteration 2822, loss = 0.11200928\n",
      "Iteration 2823, loss = 0.11499762\n",
      "Iteration 2824, loss = 0.12006475\n",
      "Iteration 2825, loss = 0.11248118\n",
      "Iteration 2826, loss = 0.10230567\n",
      "Iteration 2827, loss = 0.12046232\n",
      "Iteration 2828, loss = 0.11313205\n",
      "Iteration 2829, loss = 0.10758740\n",
      "Iteration 2830, loss = 0.10565201\n",
      "Iteration 2831, loss = 0.12604038\n",
      "Iteration 2832, loss = 0.15320082\n",
      "Iteration 2833, loss = 0.11838374\n",
      "Iteration 2834, loss = 0.12883542\n",
      "Iteration 2835, loss = 0.12854720\n",
      "Iteration 2836, loss = 0.11335058\n",
      "Iteration 2837, loss = 0.11115885\n",
      "Iteration 2838, loss = 0.12306370\n",
      "Iteration 2839, loss = 0.13825163\n",
      "Iteration 2840, loss = 0.11725102\n",
      "Iteration 2841, loss = 0.12684541\n",
      "Iteration 2842, loss = 0.12516733\n",
      "Iteration 2843, loss = 0.17081747\n",
      "Iteration 2844, loss = 0.14889927\n",
      "Iteration 2845, loss = 0.11130085\n",
      "Iteration 2846, loss = 0.15606984\n",
      "Iteration 2847, loss = 0.12623936\n",
      "Iteration 2848, loss = 0.12176664\n",
      "Iteration 2849, loss = 0.12646232\n",
      "Iteration 2850, loss = 0.09964114\n",
      "Iteration 2851, loss = 0.11907997\n",
      "Iteration 2852, loss = 0.11451630\n",
      "Iteration 2853, loss = 0.10943706\n",
      "Iteration 2854, loss = 0.10614617\n",
      "Iteration 2855, loss = 0.11374882\n",
      "Iteration 2856, loss = 0.10844427\n",
      "Iteration 2857, loss = 0.12244668\n",
      "Iteration 2858, loss = 0.12791109\n",
      "Iteration 2859, loss = 0.11526771\n",
      "Iteration 2860, loss = 0.10996301\n",
      "Iteration 2861, loss = 0.11684069\n",
      "Iteration 2862, loss = 0.12793264\n",
      "Iteration 2863, loss = 0.15231805\n",
      "Iteration 2864, loss = 0.14379702\n",
      "Iteration 2865, loss = 0.12124648\n",
      "Iteration 2866, loss = 0.20840897\n",
      "Iteration 2867, loss = 0.20574630\n",
      "Iteration 2868, loss = 0.11957611\n",
      "Iteration 2869, loss = 0.11881798\n",
      "Iteration 2870, loss = 0.12420530\n",
      "Iteration 2871, loss = 0.11146048\n",
      "Iteration 2872, loss = 0.10542178\n",
      "Iteration 2873, loss = 0.12781158\n",
      "Iteration 2874, loss = 0.11561126\n",
      "Iteration 2875, loss = 0.10573091\n",
      "Iteration 2876, loss = 0.12041086\n",
      "Iteration 2877, loss = 0.11340021\n",
      "Iteration 2878, loss = 0.15049550\n",
      "Iteration 2879, loss = 0.13378728\n",
      "Iteration 2880, loss = 0.11225449\n",
      "Iteration 2881, loss = 0.12005683\n",
      "Iteration 2882, loss = 0.10679248\n",
      "Iteration 2883, loss = 0.11373368\n",
      "Iteration 2884, loss = 0.10923945\n",
      "Iteration 2885, loss = 0.10357130\n",
      "Iteration 2886, loss = 0.10526411\n",
      "Iteration 2887, loss = 0.11924383\n",
      "Iteration 2888, loss = 0.10277594\n",
      "Iteration 2889, loss = 0.12370471\n",
      "Iteration 2890, loss = 0.16692418\n",
      "Iteration 2891, loss = 0.11557022\n",
      "Iteration 2892, loss = 0.27352936\n",
      "Iteration 2893, loss = 0.38087540\n",
      "Iteration 2894, loss = 0.36148984\n",
      "Iteration 2895, loss = 0.19396512\n",
      "Iteration 2896, loss = 0.19502310\n",
      "Iteration 2897, loss = 0.16327286\n",
      "Iteration 2898, loss = 0.11804043\n",
      "Iteration 2899, loss = 0.12896784\n",
      "Iteration 2900, loss = 0.11678157\n",
      "Iteration 2901, loss = 0.11214667\n",
      "Iteration 2902, loss = 0.10362938\n",
      "Iteration 2903, loss = 0.12982993\n",
      "Iteration 2904, loss = 0.17715843\n",
      "Iteration 2905, loss = 0.14115581\n",
      "Iteration 2906, loss = 0.13706653\n",
      "Iteration 2907, loss = 0.13510655\n",
      "Iteration 2908, loss = 0.11475248\n",
      "Iteration 2909, loss = 0.10240313\n",
      "Iteration 2910, loss = 0.11169142\n",
      "Iteration 2911, loss = 0.13883952\n",
      "Iteration 2912, loss = 0.11086044\n",
      "Iteration 2913, loss = 0.10249582\n",
      "Iteration 2914, loss = 0.11336327\n",
      "Iteration 2915, loss = 0.10945224\n",
      "Iteration 2916, loss = 0.12158175\n",
      "Iteration 2917, loss = 0.12442208\n",
      "Iteration 2918, loss = 0.11229142\n",
      "Iteration 2919, loss = 0.11525501\n",
      "Iteration 2920, loss = 0.13372477\n",
      "Iteration 2921, loss = 0.12421556\n",
      "Iteration 2922, loss = 0.15560990\n",
      "Iteration 2923, loss = 0.11614036\n",
      "Iteration 2924, loss = 0.13178222\n",
      "Iteration 2925, loss = 0.14994363\n",
      "Iteration 2926, loss = 0.13793757\n",
      "Iteration 2927, loss = 0.13716401\n",
      "Iteration 2928, loss = 0.12022253\n",
      "Iteration 2929, loss = 0.12533336\n",
      "Iteration 2930, loss = 0.12372766\n",
      "Iteration 2931, loss = 0.12401093\n",
      "Iteration 2932, loss = 0.12746898\n",
      "Iteration 2933, loss = 0.13804444\n",
      "Iteration 2934, loss = 0.19053799\n",
      "Iteration 2935, loss = 0.13813248\n",
      "Iteration 2936, loss = 0.13830605\n",
      "Iteration 2937, loss = 0.13333168\n",
      "Iteration 2938, loss = 0.13297850\n",
      "Iteration 2939, loss = 0.12287779\n",
      "Iteration 2940, loss = 0.11582333\n",
      "Iteration 2941, loss = 0.10715014\n",
      "Iteration 2942, loss = 0.18503946\n",
      "Iteration 2943, loss = 0.16829606\n",
      "Iteration 2944, loss = 0.12632564\n",
      "Iteration 2945, loss = 0.13977502\n",
      "Iteration 2946, loss = 0.17988894\n",
      "Iteration 2947, loss = 0.21677377\n",
      "Iteration 2948, loss = 0.22580148\n",
      "Iteration 2949, loss = 0.18719656\n",
      "Iteration 2950, loss = 0.15587913\n",
      "Iteration 2951, loss = 0.12219663\n",
      "Iteration 2952, loss = 0.13482525\n",
      "Iteration 2953, loss = 0.21556645\n",
      "Iteration 2954, loss = 0.25578613\n",
      "Iteration 2955, loss = 0.32517271\n",
      "Iteration 2956, loss = 0.22555657\n",
      "Iteration 2957, loss = 0.21936073\n",
      "Iteration 2958, loss = 0.30852670\n",
      "Iteration 2959, loss = 0.86312098\n",
      "Iteration 2960, loss = 0.60997891\n",
      "Iteration 2961, loss = 0.38186473\n",
      "Iteration 2962, loss = 0.30643374\n",
      "Iteration 2963, loss = 0.31554327\n",
      "Iteration 2964, loss = 0.24996260\n",
      "Iteration 2965, loss = 0.19206675\n",
      "Iteration 2966, loss = 0.12409898\n",
      "Iteration 2967, loss = 0.15846659\n",
      "Iteration 2968, loss = 0.15051186\n",
      "Iteration 2969, loss = 0.13515080\n",
      "Iteration 2970, loss = 0.14404710\n",
      "Iteration 2971, loss = 0.15822810\n",
      "Iteration 2972, loss = 0.22745558\n",
      "Iteration 2973, loss = 0.18991850\n",
      "Iteration 2974, loss = 0.17154925\n",
      "Iteration 2975, loss = 0.14734939\n",
      "Iteration 2976, loss = 0.12152491\n",
      "Iteration 2977, loss = 0.27842920\n",
      "Iteration 2978, loss = 0.21382521\n",
      "Iteration 2979, loss = 0.20418022\n",
      "Iteration 2980, loss = 0.14765221\n",
      "Iteration 2981, loss = 0.15613868\n",
      "Iteration 2982, loss = 0.14026141\n",
      "Iteration 2983, loss = 0.22809624\n",
      "Iteration 2984, loss = 0.27289852\n",
      "Iteration 2985, loss = 0.27474785\n",
      "Iteration 2986, loss = 0.28459404\n",
      "Iteration 2987, loss = 0.85183474\n",
      "Iteration 2988, loss = 0.93424594\n",
      "Iteration 2989, loss = 0.91650818\n",
      "Iteration 2990, loss = 1.09357041\n",
      "Iteration 2991, loss = 0.59325494\n",
      "Iteration 2992, loss = 0.70041584\n",
      "Iteration 2993, loss = 0.60607398\n",
      "Iteration 2994, loss = 0.57977680\n",
      "Iteration 2995, loss = 0.47435165\n",
      "Iteration 2996, loss = 0.39480662\n",
      "Iteration 2997, loss = 0.26659234\n",
      "Iteration 2998, loss = 0.17334798\n",
      "Iteration 2999, loss = 0.74534222\n",
      "Iteration 3000, loss = 0.87562459\n",
      "Iteration 3001, loss = 0.83391830\n",
      "Iteration 3002, loss = 1.30323208\n",
      "Iteration 3003, loss = 1.11897882\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 3004, loss = 0.71734130\n",
      "Iteration 3005, loss = 0.78767761\n",
      "Iteration 3006, loss = 0.55509620\n",
      "Iteration 3007, loss = 0.78583058\n",
      "Iteration 3008, loss = 0.48505185\n",
      "Iteration 3009, loss = 0.60453460\n",
      "Iteration 3010, loss = 0.34079045\n",
      "Iteration 3011, loss = 0.25834387\n",
      "Iteration 3012, loss = 0.28837677\n",
      "Iteration 3013, loss = 0.21864289\n",
      "Iteration 3014, loss = 0.24037906\n",
      "Iteration 3015, loss = 0.38890222\n",
      "Iteration 3016, loss = 0.41464529\n",
      "Iteration 3017, loss = 0.73904040\n",
      "Iteration 3018, loss = 0.65437122\n",
      "Iteration 3019, loss = 0.59779846\n",
      "Iteration 3020, loss = 0.50084660\n",
      "Iteration 3021, loss = 0.32590628\n",
      "Iteration 3022, loss = 0.30362874\n",
      "Iteration 3023, loss = 0.30041326\n",
      "Iteration 3024, loss = 0.27837645\n",
      "Iteration 3025, loss = 0.28887194\n",
      "Iteration 3026, loss = 0.26594726\n",
      "Iteration 3027, loss = 0.19088003\n",
      "Iteration 3028, loss = 0.19078973\n",
      "Iteration 3029, loss = 0.23601881\n",
      "Iteration 3030, loss = 0.17348188\n",
      "Iteration 3031, loss = 0.13754373\n",
      "Iteration 3032, loss = 0.15787583\n",
      "Iteration 3033, loss = 0.14424737\n",
      "Iteration 3034, loss = 0.11934248\n",
      "Iteration 3035, loss = 0.79795817\n",
      "Iteration 3036, loss = 0.66040784\n",
      "Iteration 3037, loss = 1.12438174\n",
      "Iteration 3038, loss = 1.07902729\n",
      "Iteration 3039, loss = 0.96318961\n",
      "Iteration 3040, loss = 0.80321421\n",
      "Iteration 3041, loss = 0.63745259\n",
      "Iteration 3042, loss = 0.59995261\n",
      "Iteration 3043, loss = 0.95944783\n",
      "Iteration 3044, loss = 0.41608303\n",
      "Iteration 3045, loss = 0.31269434\n",
      "Iteration 3046, loss = 0.41296550\n",
      "Iteration 3047, loss = 1.05534589\n",
      "Iteration 3048, loss = 0.81935743\n",
      "Iteration 3049, loss = 1.00487900\n",
      "Iteration 3050, loss = 1.06773743\n",
      "Iteration 3051, loss = 1.05511050\n",
      "Iteration 3052, loss = 0.97093208\n",
      "Iteration 3053, loss = 0.75073292\n",
      "Iteration 3054, loss = 0.90907230\n",
      "Iteration 3055, loss = 0.53033244\n",
      "Iteration 3056, loss = 0.59643341\n",
      "Iteration 3057, loss = 1.24496895\n",
      "Iteration 3058, loss = 1.06249702\n",
      "Iteration 3059, loss = 1.18796890\n",
      "Iteration 3060, loss = 1.18947928\n",
      "Iteration 3061, loss = 1.35781246\n",
      "Iteration 3062, loss = 0.78572100\n",
      "Iteration 3063, loss = 0.75161610\n",
      "Iteration 3064, loss = 0.58115629\n",
      "Iteration 3065, loss = 0.63454370\n",
      "Iteration 3066, loss = 0.61628577\n",
      "Iteration 3067, loss = 0.95349871\n",
      "Iteration 3068, loss = 1.72041056\n",
      "Iteration 3069, loss = 1.50408837\n",
      "Iteration 3070, loss = 1.30129378\n",
      "Iteration 3071, loss = 0.71524773\n",
      "Iteration 3072, loss = 0.89730403\n",
      "Iteration 3073, loss = 0.80560384\n",
      "Iteration 3074, loss = 0.69807206\n",
      "Iteration 3075, loss = 0.78783377\n",
      "Iteration 3076, loss = 0.94024926\n",
      "Iteration 3077, loss = 0.57434912\n",
      "Iteration 3078, loss = 0.59199750\n",
      "Iteration 3079, loss = 0.58328459\n",
      "Iteration 3080, loss = 0.60818263\n",
      "Iteration 3081, loss = 0.63069711\n",
      "Iteration 3082, loss = 0.80066918\n",
      "Iteration 3083, loss = 0.44644567\n",
      "Iteration 3084, loss = 0.39972309\n",
      "Iteration 3085, loss = 0.45940114\n",
      "Iteration 3086, loss = 0.32755099\n",
      "Iteration 3087, loss = 0.23781402\n",
      "Iteration 3088, loss = 0.15292633\n",
      "Iteration 3089, loss = 0.16257255\n",
      "Iteration 3090, loss = 0.20013673\n",
      "Iteration 3091, loss = 0.17114880\n",
      "Iteration 3092, loss = 0.14999304\n",
      "Iteration 3093, loss = 0.13606751\n",
      "Iteration 3094, loss = 0.15396655\n",
      "Iteration 3095, loss = 0.15284423\n",
      "Iteration 3096, loss = 0.17635165\n",
      "Iteration 3097, loss = 0.12756303\n",
      "Iteration 3098, loss = 0.11907863\n",
      "Iteration 3099, loss = 0.12774085\n",
      "Iteration 3100, loss = 0.12156111\n",
      "Iteration 3101, loss = 0.12222475\n",
      "Iteration 3102, loss = 0.14608328\n",
      "Iteration 3103, loss = 0.12278186\n",
      "Iteration 3104, loss = 0.11902129\n",
      "Iteration 3105, loss = 0.13055800\n",
      "Iteration 3106, loss = 0.12065399\n",
      "Iteration 3107, loss = 0.11951644\n",
      "Iteration 3108, loss = 0.14229815\n",
      "Iteration 3109, loss = 0.12983168\n",
      "Iteration 3110, loss = 0.12228157\n",
      "Iteration 3111, loss = 0.11333676\n",
      "Iteration 3112, loss = 0.11608308\n",
      "Iteration 3113, loss = 0.11429479\n",
      "Iteration 3114, loss = 0.11382459\n",
      "Iteration 3115, loss = 0.12391851\n",
      "Iteration 3116, loss = 0.12545810\n",
      "Iteration 3117, loss = 0.12778652\n",
      "Iteration 3118, loss = 0.11550496\n",
      "Iteration 3119, loss = 0.11410898\n",
      "Iteration 3120, loss = 0.12052727\n",
      "Iteration 3121, loss = 0.11148403\n",
      "Iteration 3122, loss = 0.10991723\n",
      "Iteration 3123, loss = 0.11189322\n",
      "Iteration 3124, loss = 0.11367008\n",
      "Iteration 3125, loss = 0.10709039\n",
      "Iteration 3126, loss = 0.11045560\n",
      "Iteration 3127, loss = 0.11477280\n",
      "Iteration 3128, loss = 0.10411456\n",
      "Iteration 3129, loss = 0.10990020\n",
      "Iteration 3130, loss = 0.10530791\n",
      "Iteration 3131, loss = 0.12215066\n",
      "Iteration 3132, loss = 0.13060247\n",
      "Iteration 3133, loss = 0.13513128\n",
      "Iteration 3134, loss = 0.11875124\n",
      "Iteration 3135, loss = 0.13110835\n",
      "Iteration 3136, loss = 0.10800160\n",
      "Iteration 3137, loss = 0.10082665\n",
      "Iteration 3138, loss = 0.10423832\n",
      "Iteration 3139, loss = 0.11678124\n",
      "Iteration 3140, loss = 0.10728736\n",
      "Iteration 3141, loss = 0.10780356\n",
      "Iteration 3142, loss = 0.11521371\n",
      "Iteration 3143, loss = 0.11202222\n",
      "Iteration 3144, loss = 0.12225900\n",
      "Iteration 3145, loss = 0.11138345\n",
      "Iteration 3146, loss = 0.10902636\n",
      "Iteration 3147, loss = 0.10487675\n",
      "Iteration 3148, loss = 0.10163307\n",
      "Iteration 3149, loss = 0.12382771\n",
      "Iteration 3150, loss = 0.12386053\n",
      "Iteration 3151, loss = 0.13747491\n",
      "Iteration 3152, loss = 0.12574809\n",
      "Iteration 3153, loss = 0.11680861\n",
      "Iteration 3154, loss = 0.12022611\n",
      "Iteration 3155, loss = 0.10867806\n",
      "Iteration 3156, loss = 0.10718252\n",
      "Iteration 3157, loss = 0.10921790\n",
      "Iteration 3158, loss = 0.10842779\n",
      "Iteration 3159, loss = 0.11082574\n",
      "Iteration 3160, loss = 0.11080625\n",
      "Iteration 3161, loss = 0.11779724\n",
      "Iteration 3162, loss = 0.11577932\n",
      "Iteration 3163, loss = 0.10989052\n",
      "Iteration 3164, loss = 0.11355645\n",
      "Iteration 3165, loss = 0.11036862\n",
      "Iteration 3166, loss = 0.10756929\n",
      "Iteration 3167, loss = 0.10897650\n",
      "Iteration 3168, loss = 0.11117145\n",
      "Iteration 3169, loss = 0.10717083\n",
      "Iteration 3170, loss = 0.10512347\n",
      "Iteration 3171, loss = 0.10281888\n",
      "Iteration 3172, loss = 0.10938492\n",
      "Iteration 3173, loss = 0.10444470\n",
      "Iteration 3174, loss = 0.10667840\n",
      "Iteration 3175, loss = 0.10302062\n",
      "Iteration 3176, loss = 0.10515553\n",
      "Iteration 3177, loss = 0.10986575\n",
      "Iteration 3178, loss = 0.10816927\n",
      "Iteration 3179, loss = 0.11053557\n",
      "Iteration 3180, loss = 0.10671887\n",
      "Iteration 3181, loss = 0.10816082\n",
      "Iteration 3182, loss = 0.11417155\n",
      "Iteration 3183, loss = 0.10573238\n",
      "Iteration 3184, loss = 0.10899002\n",
      "Iteration 3185, loss = 0.10826372\n",
      "Iteration 3186, loss = 0.10651051\n",
      "Iteration 3187, loss = 0.11240438\n",
      "Iteration 3188, loss = 0.12726318\n",
      "Iteration 3189, loss = 0.11909279\n",
      "Iteration 3190, loss = 0.11751894\n",
      "Iteration 3191, loss = 0.10952083\n",
      "Iteration 3192, loss = 0.10510671\n",
      "Iteration 3193, loss = 0.10865183\n",
      "Iteration 3194, loss = 0.12525453\n",
      "Iteration 3195, loss = 0.12564136\n",
      "Iteration 3196, loss = 0.11977573\n",
      "Iteration 3197, loss = 0.11514162\n",
      "Iteration 3198, loss = 0.13117779\n",
      "Iteration 3199, loss = 0.13316071\n",
      "Iteration 3200, loss = 0.15270300\n",
      "Iteration 3201, loss = 0.13989038\n",
      "Iteration 3202, loss = 0.11594055\n",
      "Iteration 3203, loss = 0.11543934\n",
      "Iteration 3204, loss = 0.10411855\n",
      "Iteration 3205, loss = 0.10316094\n",
      "Iteration 3206, loss = 0.10608812\n",
      "Iteration 3207, loss = 0.10286169\n",
      "Iteration 3208, loss = 0.10725278\n",
      "Iteration 3209, loss = 0.10241939\n",
      "Iteration 3210, loss = 0.10450452\n",
      "Iteration 3211, loss = 0.10975045\n",
      "Iteration 3212, loss = 0.10922923\n",
      "Iteration 3213, loss = 0.10551595\n",
      "Iteration 3214, loss = 0.11025939\n",
      "Iteration 3215, loss = 0.11498821\n",
      "Iteration 3216, loss = 0.10765801\n",
      "Iteration 3217, loss = 0.11646271\n",
      "Iteration 3218, loss = 0.10772095\n",
      "Iteration 3219, loss = 0.10751448\n",
      "Iteration 3220, loss = 0.11349907\n",
      "Iteration 3221, loss = 0.10160225\n",
      "Iteration 3222, loss = 0.10187466\n",
      "Iteration 3223, loss = 0.11039106\n",
      "Iteration 3224, loss = 0.11525586\n",
      "Iteration 3225, loss = 0.10942659\n",
      "Iteration 3226, loss = 0.10804057\n",
      "Iteration 3227, loss = 0.11433686\n",
      "Iteration 3228, loss = 0.10981619\n",
      "Iteration 3229, loss = 0.10484656\n",
      "Iteration 3230, loss = 0.10266307\n",
      "Iteration 3231, loss = 0.10486849\n",
      "Iteration 3232, loss = 0.10627515\n",
      "Iteration 3233, loss = 0.10878183\n",
      "Iteration 3234, loss = 0.10908283\n",
      "Iteration 3235, loss = 0.10179835\n",
      "Iteration 3236, loss = 0.10279647\n",
      "Iteration 3237, loss = 0.10214111\n",
      "Iteration 3238, loss = 0.10524470\n",
      "Iteration 3239, loss = 0.11889879\n",
      "Iteration 3240, loss = 0.13122557\n",
      "Iteration 3241, loss = 0.10951887\n",
      "Iteration 3242, loss = 0.10935586\n",
      "Iteration 3243, loss = 0.10764645\n",
      "Iteration 3244, loss = 0.10608591\n",
      "Iteration 3245, loss = 0.10502987\n",
      "Iteration 3246, loss = 0.10423017\n",
      "Iteration 3247, loss = 0.10885738\n",
      "Iteration 3248, loss = 0.10519701\n",
      "Iteration 3249, loss = 0.11396306\n",
      "Iteration 3250, loss = 0.10923505\n",
      "Iteration 3251, loss = 0.10939453\n",
      "Iteration 3252, loss = 0.10666134\n",
      "Iteration 3253, loss = 0.10731057\n",
      "Iteration 3254, loss = 0.11179523\n",
      "Iteration 3255, loss = 0.12018408\n",
      "Iteration 3256, loss = 0.12716698\n",
      "Iteration 3257, loss = 0.09876612\n",
      "Iteration 3258, loss = 0.11556057\n",
      "Iteration 3259, loss = 0.10425699\n",
      "Iteration 3260, loss = 0.10336680\n",
      "Iteration 3261, loss = 0.10647414\n",
      "Iteration 3262, loss = 0.10218761\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 3263, loss = 0.11613975\n",
      "Iteration 3264, loss = 0.11952049\n",
      "Iteration 3265, loss = 0.11946333\n",
      "Iteration 3266, loss = 0.11026326\n",
      "Iteration 3267, loss = 0.12062084\n",
      "Iteration 3268, loss = 0.10887463\n",
      "Iteration 3269, loss = 0.11245275\n",
      "Iteration 3270, loss = 0.11070157\n",
      "Iteration 3271, loss = 0.10297460\n",
      "Iteration 3272, loss = 0.10334734\n",
      "Iteration 3273, loss = 0.10442820\n",
      "Iteration 3274, loss = 0.10174334\n",
      "Iteration 3275, loss = 0.10204718\n",
      "Iteration 3276, loss = 0.10246983\n",
      "Iteration 3277, loss = 0.10256019\n",
      "Iteration 3278, loss = 0.11297079\n",
      "Iteration 3279, loss = 0.11931460\n",
      "Iteration 3280, loss = 0.10797755\n",
      "Iteration 3281, loss = 0.11455541\n",
      "Iteration 3282, loss = 0.11011159\n",
      "Iteration 3283, loss = 0.10031549\n",
      "Iteration 3284, loss = 0.10428088\n",
      "Iteration 3285, loss = 0.11357041\n",
      "Iteration 3286, loss = 0.12066619\n",
      "Iteration 3287, loss = 0.11249090\n",
      "Iteration 3288, loss = 0.11543552\n",
      "Iteration 3289, loss = 0.12767066\n",
      "Iteration 3290, loss = 0.11327369\n",
      "Iteration 3291, loss = 0.10553443\n",
      "Iteration 3292, loss = 0.10290912\n",
      "Iteration 3293, loss = 0.12856752\n",
      "Iteration 3294, loss = 0.15923572\n",
      "Iteration 3295, loss = 0.13691333\n",
      "Iteration 3296, loss = 0.12178104\n",
      "Iteration 3297, loss = 0.11647923\n",
      "Iteration 3298, loss = 0.10897050\n",
      "Iteration 3299, loss = 0.11577045\n",
      "Iteration 3300, loss = 0.10548499\n",
      "Iteration 3301, loss = 0.10566937\n",
      "Iteration 3302, loss = 0.11702112\n",
      "Iteration 3303, loss = 0.10529300\n",
      "Iteration 3304, loss = 0.10216442\n",
      "Iteration 3305, loss = 0.10548729\n",
      "Iteration 3306, loss = 0.10196796\n",
      "Iteration 3307, loss = 0.10507715\n",
      "Iteration 3308, loss = 0.10868671\n",
      "Iteration 3309, loss = 0.10493363\n",
      "Iteration 3310, loss = 0.10278125\n",
      "Iteration 3311, loss = 0.10213525\n",
      "Iteration 3312, loss = 0.10477342\n",
      "Iteration 3313, loss = 0.10655938\n",
      "Iteration 3314, loss = 0.11617588\n",
      "Iteration 3315, loss = 0.11711876\n",
      "Iteration 3316, loss = 0.10507614\n",
      "Iteration 3317, loss = 0.10360628\n",
      "Iteration 3318, loss = 0.10579366\n",
      "Iteration 3319, loss = 0.10648703\n",
      "Iteration 3320, loss = 0.10463720\n",
      "Iteration 3321, loss = 0.10382360\n",
      "Iteration 3322, loss = 0.10608174\n",
      "Iteration 3323, loss = 0.11014471\n",
      "Iteration 3324, loss = 0.12027662\n",
      "Iteration 3325, loss = 0.10529118\n",
      "Iteration 3326, loss = 0.10677414\n",
      "Iteration 3327, loss = 0.10326500\n",
      "Iteration 3328, loss = 0.10514109\n",
      "Iteration 3329, loss = 0.11586804\n",
      "Iteration 3330, loss = 0.10287427\n",
      "Iteration 3331, loss = 0.10369551\n",
      "Iteration 3332, loss = 0.10819407\n",
      "Iteration 3333, loss = 0.10738608\n",
      "Iteration 3334, loss = 0.10448115\n",
      "Iteration 3335, loss = 0.11800665\n",
      "Iteration 3336, loss = 0.12389438\n",
      "Iteration 3337, loss = 0.11089006\n",
      "Iteration 3338, loss = 0.11527917\n",
      "Iteration 3339, loss = 0.11440466\n",
      "Iteration 3340, loss = 0.10495061\n",
      "Iteration 3341, loss = 0.10163000\n",
      "Iteration 3342, loss = 0.10535497\n",
      "Iteration 3343, loss = 0.10478590\n",
      "Iteration 3344, loss = 0.10861237\n",
      "Iteration 3345, loss = 0.10553747\n",
      "Iteration 3346, loss = 0.11138979\n",
      "Iteration 3347, loss = 0.10963297\n",
      "Iteration 3348, loss = 0.11536244\n",
      "Iteration 3349, loss = 0.11109670\n",
      "Iteration 3350, loss = 0.13980620\n",
      "Iteration 3351, loss = 0.10268193\n",
      "Iteration 3352, loss = 0.11605821\n",
      "Iteration 3353, loss = 0.12732258\n",
      "Iteration 3354, loss = 0.10342996\n",
      "Iteration 3355, loss = 0.12947262\n",
      "Iteration 3356, loss = 0.11040229\n",
      "Iteration 3357, loss = 0.14045251\n",
      "Iteration 3358, loss = 0.12030691\n",
      "Iteration 3359, loss = 0.10944962\n",
      "Iteration 3360, loss = 0.11966378\n",
      "Iteration 3361, loss = 0.13396566\n",
      "Iteration 3362, loss = 0.13043743\n",
      "Iteration 3363, loss = 0.11848831\n",
      "Iteration 3364, loss = 0.10941643\n",
      "Iteration 3365, loss = 0.10607466\n",
      "Iteration 3366, loss = 0.11076312\n",
      "Iteration 3367, loss = 0.10545664\n",
      "Iteration 3368, loss = 0.11013248\n",
      "Iteration 3369, loss = 0.10732341\n",
      "Iteration 3370, loss = 0.10532437\n",
      "Iteration 3371, loss = 0.11189027\n",
      "Iteration 3372, loss = 0.11748409\n",
      "Iteration 3373, loss = 0.11943884\n",
      "Iteration 3374, loss = 0.11144058\n",
      "Iteration 3375, loss = 0.15602254\n",
      "Iteration 3376, loss = 0.10767238\n",
      "Iteration 3377, loss = 0.11354253\n",
      "Iteration 3378, loss = 0.11084404\n",
      "Iteration 3379, loss = 0.10801274\n",
      "Iteration 3380, loss = 0.10805629\n",
      "Iteration 3381, loss = 0.10606937\n",
      "Iteration 3382, loss = 0.10760937\n",
      "Iteration 3383, loss = 0.12719465\n",
      "Iteration 3384, loss = 0.12544953\n",
      "Iteration 3385, loss = 0.11287797\n",
      "Iteration 3386, loss = 0.16139768\n",
      "Iteration 3387, loss = 0.13004936\n",
      "Iteration 3388, loss = 0.27446530\n",
      "Iteration 3389, loss = 0.24827132\n",
      "Iteration 3390, loss = 0.15449515\n",
      "Iteration 3391, loss = 0.16676856\n",
      "Iteration 3392, loss = 0.17287033\n",
      "Iteration 3393, loss = 0.31767020\n",
      "Iteration 3394, loss = 1.17429162\n",
      "Iteration 3395, loss = 3.29562880\n",
      "Iteration 3396, loss = 4.27583886\n",
      "Iteration 3397, loss = 4.40135907\n",
      "Iteration 3398, loss = 2.70767570\n",
      "Iteration 3399, loss = 2.33694460\n",
      "Iteration 3400, loss = 1.94260706\n",
      "Iteration 3401, loss = 1.17103008\n",
      "Iteration 3402, loss = 0.85311320\n",
      "Iteration 3403, loss = 1.72744178\n",
      "Iteration 3404, loss = 1.25144745\n",
      "Iteration 3405, loss = 1.26790100\n",
      "Iteration 3406, loss = 0.77573408\n",
      "Iteration 3407, loss = 0.85791420\n",
      "Iteration 3408, loss = 1.11031491\n",
      "Iteration 3409, loss = 0.79297945\n",
      "Iteration 3410, loss = 0.80515178\n",
      "Iteration 3411, loss = 0.97256203\n",
      "Iteration 3412, loss = 0.92846758\n",
      "Iteration 3413, loss = 0.92777986\n",
      "Iteration 3414, loss = 1.02664702\n",
      "Iteration 3415, loss = 0.80510285\n",
      "Iteration 3416, loss = 0.94125889\n",
      "Iteration 3417, loss = 1.05037653\n",
      "Iteration 3418, loss = 0.73480476\n",
      "Iteration 3419, loss = 0.78295673\n",
      "Iteration 3420, loss = 0.84645329\n",
      "Iteration 3421, loss = 1.35072820\n",
      "Iteration 3422, loss = 0.77423255\n",
      "Iteration 3423, loss = 0.74608672\n",
      "Iteration 3424, loss = 0.78506973\n",
      "Iteration 3425, loss = 0.73083355\n",
      "Iteration 3426, loss = 0.84645773\n",
      "Iteration 3427, loss = 0.71004321\n",
      "Iteration 3428, loss = 0.68055668\n",
      "Iteration 3429, loss = 1.09969251\n",
      "Iteration 3430, loss = 1.09619933\n",
      "Iteration 3431, loss = 1.27445818\n",
      "Iteration 3432, loss = 1.05160041\n",
      "Iteration 3433, loss = 0.69101621\n",
      "Iteration 3434, loss = 0.89873519\n",
      "Iteration 3435, loss = 0.87439745\n",
      "Iteration 3436, loss = 0.90259205\n",
      "Iteration 3437, loss = 0.70044334\n",
      "Iteration 3438, loss = 0.71694351\n",
      "Iteration 3439, loss = 0.58676036\n",
      "Iteration 3440, loss = 0.59140698\n",
      "Iteration 3441, loss = 0.73234955\n",
      "Iteration 3442, loss = 0.53277162\n",
      "Iteration 3443, loss = 0.64839183\n",
      "Iteration 3444, loss = 0.52409140\n",
      "Iteration 3445, loss = 0.54776198\n",
      "Iteration 3446, loss = 0.38766736\n",
      "Iteration 3447, loss = 0.48101607\n",
      "Iteration 3448, loss = 0.40104971\n",
      "Iteration 3449, loss = 0.30434451\n",
      "Iteration 3450, loss = 0.22833188\n",
      "Iteration 3451, loss = 0.36301998\n",
      "Iteration 3452, loss = 0.39820497\n",
      "Iteration 3453, loss = 0.71466918\n",
      "Iteration 3454, loss = 0.65160406\n",
      "Iteration 3455, loss = 0.50142862\n",
      "Iteration 3456, loss = 0.39259849\n",
      "Iteration 3457, loss = 0.29709338\n",
      "Iteration 3458, loss = 0.36168705\n",
      "Iteration 3459, loss = 0.23839837\n",
      "Iteration 3460, loss = 0.17965852\n",
      "Iteration 3461, loss = 0.30515761\n",
      "Iteration 3462, loss = 0.25618609\n",
      "Iteration 3463, loss = 0.20186818\n",
      "Iteration 3464, loss = 0.28078690\n",
      "Iteration 3465, loss = 0.25543817\n",
      "Iteration 3466, loss = 0.18416248\n",
      "Iteration 3467, loss = 0.17009502\n",
      "Iteration 3468, loss = 0.20606405\n",
      "Iteration 3469, loss = 0.17221518\n",
      "Iteration 3470, loss = 0.17441154\n",
      "Iteration 3471, loss = 0.15584100\n",
      "Iteration 3472, loss = 0.18556418\n",
      "Iteration 3473, loss = 0.20048587\n",
      "Iteration 3474, loss = 0.37108774\n",
      "Iteration 3475, loss = 0.20178644\n",
      "Iteration 3476, loss = 0.17719724\n",
      "Iteration 3477, loss = 0.14546782\n",
      "Iteration 3478, loss = 0.11536984\n",
      "Iteration 3479, loss = 0.16420745\n",
      "Iteration 3480, loss = 0.34294480\n",
      "Iteration 3481, loss = 0.19478426\n",
      "Iteration 3482, loss = 0.24127216\n",
      "Iteration 3483, loss = 0.24238447\n",
      "Iteration 3484, loss = 0.27268103\n",
      "Iteration 3485, loss = 0.27893122\n",
      "Iteration 3486, loss = 0.24755665\n",
      "Iteration 3487, loss = 0.32317785\n",
      "Iteration 3488, loss = 0.17662354\n",
      "Iteration 3489, loss = 0.20220694\n",
      "Iteration 3490, loss = 0.13283995\n",
      "Iteration 3491, loss = 1.24673595\n",
      "Iteration 3492, loss = 1.18963690\n",
      "Iteration 3493, loss = 1.23709692\n",
      "Iteration 3494, loss = 1.06441164\n",
      "Iteration 3495, loss = 0.71910448\n",
      "Iteration 3496, loss = 0.77627945\n",
      "Iteration 3497, loss = 0.69544252\n",
      "Iteration 3498, loss = 0.70711125\n",
      "Iteration 3499, loss = 0.58598574\n",
      "Iteration 3500, loss = 0.56482600\n",
      "Iteration 3501, loss = 0.52033488\n",
      "Iteration 3502, loss = 0.20027297\n",
      "Iteration 3503, loss = 0.21809624\n",
      "Iteration 3504, loss = 0.25872858\n",
      "Iteration 3505, loss = 0.14604911\n",
      "Iteration 3506, loss = 0.12327176\n",
      "Iteration 3507, loss = 0.14549008\n",
      "Iteration 3508, loss = 0.14956680\n",
      "Iteration 3509, loss = 0.14106125\n",
      "Iteration 3510, loss = 0.18689101\n",
      "Iteration 3511, loss = 0.17709800\n",
      "Iteration 3512, loss = 0.14003704\n",
      "Iteration 3513, loss = 0.15396755\n",
      "Iteration 3514, loss = 0.12025730\n",
      "Iteration 3515, loss = 0.12434017\n",
      "Iteration 3516, loss = 0.11291568\n",
      "Iteration 3517, loss = 0.12809863\n",
      "Iteration 3518, loss = 0.10799686\n",
      "Iteration 3519, loss = 0.12265091\n",
      "Iteration 3520, loss = 0.11143277\n",
      "Iteration 3521, loss = 0.12805513\n",
      "Iteration 3522, loss = 0.11194761\n",
      "Iteration 3523, loss = 0.11112140\n",
      "Iteration 3524, loss = 0.11675964\n",
      "Iteration 3525, loss = 0.13411573\n",
      "Iteration 3526, loss = 0.11150301\n",
      "Iteration 3527, loss = 0.11253068\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 3528, loss = 0.12097141\n",
      "Iteration 3529, loss = 0.10328665\n",
      "Iteration 3530, loss = 0.10827545\n",
      "Iteration 3531, loss = 0.13199910\n",
      "Iteration 3532, loss = 0.12652584\n",
      "Iteration 3533, loss = 0.10769482\n",
      "Iteration 3534, loss = 0.12219057\n",
      "Iteration 3535, loss = 0.11756291\n",
      "Iteration 3536, loss = 0.12999864\n",
      "Iteration 3537, loss = 0.12340015\n",
      "Iteration 3538, loss = 0.11152317\n",
      "Iteration 3539, loss = 0.12000401\n",
      "Iteration 3540, loss = 0.10948066\n",
      "Iteration 3541, loss = 0.10822011\n",
      "Iteration 3542, loss = 0.12723496\n",
      "Iteration 3543, loss = 0.10689229\n",
      "Iteration 3544, loss = 0.11901851\n",
      "Iteration 3545, loss = 0.12855528\n",
      "Iteration 3546, loss = 0.11430521\n",
      "Iteration 3547, loss = 0.12818722\n",
      "Iteration 3548, loss = 0.11216496\n",
      "Iteration 3549, loss = 0.10592083\n",
      "Iteration 3550, loss = 0.10489569\n",
      "Iteration 3551, loss = 0.11713357\n",
      "Iteration 3552, loss = 0.10528740\n",
      "Iteration 3553, loss = 0.10697186\n",
      "Iteration 3554, loss = 0.11847261\n",
      "Iteration 3555, loss = 0.10565196\n",
      "Iteration 3556, loss = 0.10764148\n",
      "Iteration 3557, loss = 0.12246368\n",
      "Iteration 3558, loss = 0.11025005\n",
      "Iteration 3559, loss = 0.11380696\n",
      "Iteration 3560, loss = 0.10832449\n",
      "Iteration 3561, loss = 0.11441183\n",
      "Iteration 3562, loss = 0.11682680\n",
      "Iteration 3563, loss = 0.11337267\n",
      "Iteration 3564, loss = 0.10736426\n",
      "Iteration 3565, loss = 0.10278001\n",
      "Iteration 3566, loss = 0.11145197\n",
      "Iteration 3567, loss = 0.11279935\n",
      "Iteration 3568, loss = 0.10257418\n",
      "Iteration 3569, loss = 0.13187358\n",
      "Iteration 3570, loss = 0.11240274\n",
      "Iteration 3571, loss = 0.13872481\n",
      "Iteration 3572, loss = 0.16191529\n",
      "Iteration 3573, loss = 0.12114851\n",
      "Iteration 3574, loss = 0.11823360\n",
      "Iteration 3575, loss = 0.10916536\n",
      "Iteration 3576, loss = 0.10437995\n",
      "Iteration 3577, loss = 0.10768555\n",
      "Iteration 3578, loss = 0.12765920\n",
      "Iteration 3579, loss = 0.11869193\n",
      "Iteration 3580, loss = 0.12229621\n",
      "Iteration 3581, loss = 0.11802342\n",
      "Iteration 3582, loss = 0.11791926\n",
      "Iteration 3583, loss = 0.10541448\n",
      "Iteration 3584, loss = 0.11028465\n",
      "Iteration 3585, loss = 0.11027774\n",
      "Iteration 3586, loss = 0.10828554\n",
      "Iteration 3587, loss = 0.10765455\n",
      "Iteration 3588, loss = 0.10835813\n",
      "Iteration 3589, loss = 0.10169692\n",
      "Iteration 3590, loss = 0.11642351\n",
      "Iteration 3591, loss = 0.14421063\n",
      "Iteration 3592, loss = 0.13416058\n",
      "Iteration 3593, loss = 0.13151572\n",
      "Iteration 3594, loss = 0.11214553\n",
      "Iteration 3595, loss = 0.10958928\n",
      "Iteration 3596, loss = 0.11438007\n",
      "Iteration 3597, loss = 0.18412169\n",
      "Iteration 3598, loss = 0.26849385\n",
      "Iteration 3599, loss = 0.20438812\n",
      "Iteration 3600, loss = 0.12756101\n",
      "Iteration 3601, loss = 0.17954864\n",
      "Iteration 3602, loss = 0.13640716\n",
      "Iteration 3603, loss = 0.14853908\n",
      "Iteration 3604, loss = 0.13526242\n",
      "Iteration 3605, loss = 0.13004676\n",
      "Iteration 3606, loss = 0.11801162\n",
      "Iteration 3607, loss = 0.15696271\n",
      "Iteration 3608, loss = 0.26548796\n",
      "Iteration 3609, loss = 0.19095437\n",
      "Iteration 3610, loss = 0.14413508\n",
      "Iteration 3611, loss = 0.16283731\n",
      "Iteration 3612, loss = 0.10980890\n",
      "Iteration 3613, loss = 0.11282778\n",
      "Iteration 3614, loss = 0.15892531\n",
      "Iteration 3615, loss = 0.14374558\n",
      "Iteration 3616, loss = 0.13276639\n",
      "Iteration 3617, loss = 0.11438537\n",
      "Iteration 3618, loss = 0.11839898\n",
      "Iteration 3619, loss = 0.11580890\n",
      "Iteration 3620, loss = 0.12431118\n",
      "Iteration 3621, loss = 0.11561568\n",
      "Iteration 3622, loss = 0.13271504\n",
      "Iteration 3623, loss = 0.13081118\n",
      "Iteration 3624, loss = 0.13176211\n",
      "Iteration 3625, loss = 0.12503811\n",
      "Iteration 3626, loss = 0.10408190\n",
      "Iteration 3627, loss = 0.10571022\n",
      "Iteration 3628, loss = 0.11923351\n",
      "Iteration 3629, loss = 0.11014269\n",
      "Iteration 3630, loss = 0.10340565\n",
      "Iteration 3631, loss = 0.10918088\n",
      "Iteration 3632, loss = 0.10683108\n",
      "Iteration 3633, loss = 0.11599152\n",
      "Iteration 3634, loss = 0.11093478\n",
      "Iteration 3635, loss = 0.11291652\n",
      "Iteration 3636, loss = 0.14825164\n",
      "Iteration 3637, loss = 0.13732022\n",
      "Iteration 3638, loss = 0.10786425\n",
      "Iteration 3639, loss = 0.11661181\n",
      "Iteration 3640, loss = 0.10992507\n",
      "Iteration 3641, loss = 0.10842209\n",
      "Iteration 3642, loss = 0.10412065\n",
      "Iteration 3643, loss = 0.10434840\n",
      "Iteration 3644, loss = 0.12724426\n",
      "Iteration 3645, loss = 0.13429742\n",
      "Iteration 3646, loss = 0.12871482\n",
      "Iteration 3647, loss = 0.13582134\n",
      "Iteration 3648, loss = 0.13343541\n",
      "Iteration 3649, loss = 0.13644113\n",
      "Iteration 3650, loss = 0.11269319\n",
      "Iteration 3651, loss = 0.11150863\n",
      "Iteration 3652, loss = 0.11171556\n",
      "Iteration 3653, loss = 0.10815502\n",
      "Iteration 3654, loss = 0.10806848\n",
      "Iteration 3655, loss = 0.12810090\n",
      "Iteration 3656, loss = 0.11349311\n",
      "Iteration 3657, loss = 0.10335395\n",
      "Iteration 3658, loss = 0.10478195\n",
      "Iteration 3659, loss = 0.10199917\n",
      "Iteration 3660, loss = 0.11224284\n",
      "Iteration 3661, loss = 0.12735750\n",
      "Iteration 3662, loss = 0.13104654\n",
      "Iteration 3663, loss = 0.14513726\n",
      "Iteration 3664, loss = 0.10067593\n",
      "Iteration 3665, loss = 0.18436783\n",
      "Iteration 3666, loss = 0.20839397\n",
      "Iteration 3667, loss = 0.13091165\n",
      "Iteration 3668, loss = 0.16167535\n",
      "Iteration 3669, loss = 0.12383913\n",
      "Iteration 3670, loss = 0.13066237\n",
      "Iteration 3671, loss = 0.12411647\n",
      "Iteration 3672, loss = 0.11235372\n",
      "Iteration 3673, loss = 0.10980709\n",
      "Iteration 3674, loss = 0.11111794\n",
      "Iteration 3675, loss = 0.12477761\n",
      "Iteration 3676, loss = 0.11117221\n",
      "Iteration 3677, loss = 0.11298334\n",
      "Iteration 3678, loss = 0.10361905\n",
      "Iteration 3679, loss = 0.11220317\n",
      "Iteration 3680, loss = 0.10925707\n",
      "Iteration 3681, loss = 0.12073487\n",
      "Iteration 3682, loss = 0.11611148\n",
      "Iteration 3683, loss = 0.11735604\n",
      "Iteration 3684, loss = 0.10728428\n",
      "Iteration 3685, loss = 0.10281847\n",
      "Iteration 3686, loss = 0.10648566\n",
      "Iteration 3687, loss = 0.13569376\n",
      "Iteration 3688, loss = 0.11074418\n",
      "Iteration 3689, loss = 0.10969385\n",
      "Iteration 3690, loss = 0.11283767\n",
      "Iteration 3691, loss = 0.11787196\n",
      "Iteration 3692, loss = 0.11594193\n",
      "Iteration 3693, loss = 0.14181461\n",
      "Iteration 3694, loss = 0.13746708\n",
      "Iteration 3695, loss = 0.12823731\n",
      "Iteration 3696, loss = 0.11585770\n",
      "Iteration 3697, loss = 0.11891653\n",
      "Iteration 3698, loss = 0.10298053\n",
      "Iteration 3699, loss = 0.11304711\n",
      "Iteration 3700, loss = 0.10869436\n",
      "Iteration 3701, loss = 0.11546375\n",
      "Iteration 3702, loss = 0.11252992\n",
      "Iteration 3703, loss = 0.11140213\n",
      "Iteration 3704, loss = 0.10534585\n",
      "Iteration 3705, loss = 0.10956000\n",
      "Iteration 3706, loss = 0.10634322\n",
      "Iteration 3707, loss = 0.10947192\n",
      "Iteration 3708, loss = 0.10331630\n",
      "Iteration 3709, loss = 0.11016324\n",
      "Iteration 3710, loss = 0.11811130\n",
      "Iteration 3711, loss = 0.11630435\n",
      "Iteration 3712, loss = 0.09981890\n",
      "Iteration 3713, loss = 0.10815683\n",
      "Iteration 3714, loss = 0.11388187\n",
      "Iteration 3715, loss = 0.13323240\n",
      "Iteration 3716, loss = 0.10745346\n",
      "Iteration 3717, loss = 0.14154429\n",
      "Iteration 3718, loss = 0.13765345\n",
      "Iteration 3719, loss = 0.11908572\n",
      "Iteration 3720, loss = 0.12217002\n",
      "Iteration 3721, loss = 0.11427113\n",
      "Iteration 3722, loss = 0.12468605\n",
      "Iteration 3723, loss = 0.13848146\n",
      "Iteration 3724, loss = 0.11717496\n",
      "Iteration 3725, loss = 0.10998356\n",
      "Iteration 3726, loss = 0.11927706\n",
      "Iteration 3727, loss = 0.10733919\n",
      "Iteration 3728, loss = 0.12967033\n",
      "Iteration 3729, loss = 0.11218866\n",
      "Iteration 3730, loss = 0.11492344\n",
      "Iteration 3731, loss = 0.11029703\n",
      "Iteration 3732, loss = 0.10134625\n",
      "Iteration 3733, loss = 0.11754390\n",
      "Iteration 3734, loss = 0.13059433\n",
      "Iteration 3735, loss = 0.11695021\n",
      "Iteration 3736, loss = 0.14265437\n",
      "Iteration 3737, loss = 0.11198233\n",
      "Iteration 3738, loss = 0.12918196\n",
      "Iteration 3739, loss = 0.11523067\n",
      "Iteration 3740, loss = 0.11930424\n",
      "Iteration 3741, loss = 0.12405436\n",
      "Iteration 3742, loss = 0.10777000\n",
      "Iteration 3743, loss = 0.15576304\n",
      "Iteration 3744, loss = 0.12670925\n",
      "Iteration 3745, loss = 0.19679698\n",
      "Iteration 3746, loss = 0.18858713\n",
      "Iteration 3747, loss = 0.11206570\n",
      "Iteration 3748, loss = 0.15689521\n",
      "Iteration 3749, loss = 0.11700516\n",
      "Iteration 3750, loss = 0.12363244\n",
      "Iteration 3751, loss = 0.12049506\n",
      "Iteration 3752, loss = 0.13010610\n",
      "Iteration 3753, loss = 0.11736169\n",
      "Iteration 3754, loss = 0.14316573\n",
      "Iteration 3755, loss = 0.12552149\n",
      "Iteration 3756, loss = 0.12410202\n",
      "Iteration 3757, loss = 0.13617801\n",
      "Iteration 3758, loss = 0.23073021\n",
      "Iteration 3759, loss = 0.46340221\n",
      "Iteration 3760, loss = 0.53259294\n",
      "Iteration 3761, loss = 0.73244855\n",
      "Iteration 3762, loss = 0.32453797\n",
      "Iteration 3763, loss = 0.25526925\n",
      "Iteration 3764, loss = 0.19215093\n",
      "Iteration 3765, loss = 0.19390608\n",
      "Iteration 3766, loss = 0.22193080\n",
      "Iteration 3767, loss = 0.20058800\n",
      "Iteration 3768, loss = 0.17014465\n",
      "Iteration 3769, loss = 0.13571618\n",
      "Iteration 3770, loss = 0.15588475\n",
      "Iteration 3771, loss = 0.12246637\n",
      "Iteration 3772, loss = 0.11916746\n",
      "Iteration 3773, loss = 0.14241097\n",
      "Iteration 3774, loss = 0.11425176\n",
      "Iteration 3775, loss = 0.10576427\n",
      "Iteration 3776, loss = 0.11592659\n",
      "Iteration 3777, loss = 0.10553378\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 3778, loss = 0.10485339\n",
      "Iteration 3779, loss = 0.10583833\n",
      "Iteration 3780, loss = 0.11370368\n",
      "Iteration 3781, loss = 0.10695107\n",
      "Iteration 3782, loss = 0.10540719\n",
      "Iteration 3783, loss = 0.10571491\n",
      "Iteration 3784, loss = 0.10220910\n",
      "Iteration 3785, loss = 0.10627849\n",
      "Iteration 3786, loss = 0.14115401\n",
      "Iteration 3787, loss = 0.13797510\n",
      "Iteration 3788, loss = 0.10299737\n",
      "Iteration 3789, loss = 0.10906784\n",
      "Iteration 3790, loss = 0.10730762\n",
      "Iteration 3791, loss = 0.11468351\n",
      "Iteration 3792, loss = 0.10953304\n",
      "Iteration 3793, loss = 0.10770921\n",
      "Iteration 3794, loss = 0.10767412\n",
      "Iteration 3795, loss = 0.10543037\n",
      "Iteration 3796, loss = 0.10521666\n",
      "Iteration 3797, loss = 0.10615817\n",
      "Iteration 3798, loss = 0.10104268\n",
      "Iteration 3799, loss = 0.10220521\n",
      "Iteration 3800, loss = 0.11107855\n",
      "Iteration 3801, loss = 0.10179904\n",
      "Iteration 3802, loss = 0.10608233\n",
      "Iteration 3803, loss = 0.10928124\n",
      "Iteration 3804, loss = 0.11181386\n",
      "Iteration 3805, loss = 0.12228732\n",
      "Iteration 3806, loss = 0.10534920\n",
      "Iteration 3807, loss = 0.11670847\n",
      "Iteration 3808, loss = 0.12430062\n",
      "Iteration 3809, loss = 0.10266309\n",
      "Iteration 3810, loss = 0.10484754\n",
      "Iteration 3811, loss = 0.10385602\n",
      "Iteration 3812, loss = 0.10464761\n",
      "Iteration 3813, loss = 0.10676538\n",
      "Iteration 3814, loss = 0.11587549\n",
      "Iteration 3815, loss = 0.10832707\n",
      "Iteration 3816, loss = 0.12017223\n",
      "Iteration 3817, loss = 0.10712099\n",
      "Iteration 3818, loss = 0.10472624\n",
      "Iteration 3819, loss = 0.11444540\n",
      "Iteration 3820, loss = 0.10835901\n",
      "Iteration 3821, loss = 0.11339750\n",
      "Iteration 3822, loss = 0.12338679\n",
      "Iteration 3823, loss = 0.16678324\n",
      "Iteration 3824, loss = 0.14217546\n",
      "Iteration 3825, loss = 0.10901440\n",
      "Iteration 3826, loss = 0.13783972\n",
      "Iteration 3827, loss = 0.14166704\n",
      "Iteration 3828, loss = 0.25696657\n",
      "Iteration 3829, loss = 0.25052841\n",
      "Iteration 3830, loss = 0.14171751\n",
      "Iteration 3831, loss = 0.16231999\n",
      "Iteration 3832, loss = 0.20300651\n",
      "Iteration 3833, loss = 0.16941373\n",
      "Iteration 3834, loss = 0.11634689\n",
      "Iteration 3835, loss = 0.12837112\n",
      "Iteration 3836, loss = 0.11322232\n",
      "Iteration 3837, loss = 0.10569385\n",
      "Iteration 3838, loss = 0.11181025\n",
      "Iteration 3839, loss = 0.11430978\n",
      "Iteration 3840, loss = 0.12713779\n",
      "Iteration 3841, loss = 0.14591432\n",
      "Iteration 3842, loss = 0.11466147\n",
      "Iteration 3843, loss = 0.10766687\n",
      "Iteration 3844, loss = 0.13482513\n",
      "Iteration 3845, loss = 0.11708229\n",
      "Iteration 3846, loss = 0.10700491\n",
      "Iteration 3847, loss = 0.10826926\n",
      "Iteration 3848, loss = 0.11056972\n",
      "Iteration 3849, loss = 0.10262615\n",
      "Iteration 3850, loss = 0.10685421\n",
      "Iteration 3851, loss = 0.12760687\n",
      "Iteration 3852, loss = 0.11509166\n",
      "Iteration 3853, loss = 0.10603355\n",
      "Iteration 3854, loss = 0.10631109\n",
      "Iteration 3855, loss = 0.10949002\n",
      "Iteration 3856, loss = 0.11493861\n",
      "Iteration 3857, loss = 0.10779906\n",
      "Iteration 3858, loss = 0.10809406\n",
      "Iteration 3859, loss = 0.10374076\n",
      "Iteration 3860, loss = 0.10516292\n",
      "Iteration 3861, loss = 0.10408623\n",
      "Iteration 3862, loss = 0.12514531\n",
      "Iteration 3863, loss = 0.10571208\n",
      "Iteration 3864, loss = 0.27486229\n",
      "Iteration 3865, loss = 0.44200649\n",
      "Iteration 3866, loss = 0.44536426\n",
      "Iteration 3867, loss = 0.22047769\n",
      "Iteration 3868, loss = 0.15017587\n",
      "Iteration 3869, loss = 0.20069014\n",
      "Iteration 3870, loss = 0.19848093\n",
      "Iteration 3871, loss = 0.28852813\n",
      "Iteration 3872, loss = 0.15152319\n",
      "Iteration 3873, loss = 0.14951458\n",
      "Iteration 3874, loss = 0.13475248\n",
      "Iteration 3875, loss = 0.18033020\n",
      "Iteration 3876, loss = 0.18525784\n",
      "Iteration 3877, loss = 0.18745967\n",
      "Iteration 3878, loss = 0.14385010\n",
      "Iteration 3879, loss = 0.16183427\n",
      "Iteration 3880, loss = 0.14929866\n",
      "Iteration 3881, loss = 0.12612743\n",
      "Iteration 3882, loss = 0.17258918\n",
      "Iteration 3883, loss = 0.17692257\n",
      "Iteration 3884, loss = 0.12489013\n",
      "Iteration 3885, loss = 0.12139070\n",
      "Iteration 3886, loss = 0.13943027\n",
      "Iteration 3887, loss = 0.10359643\n",
      "Iteration 3888, loss = 0.12727492\n",
      "Iteration 3889, loss = 0.10846611\n",
      "Iteration 3890, loss = 0.11042890\n",
      "Iteration 3891, loss = 0.12543327\n",
      "Iteration 3892, loss = 0.11389820\n",
      "Iteration 3893, loss = 0.12755428\n",
      "Iteration 3894, loss = 0.11571050\n",
      "Iteration 3895, loss = 0.10233497\n",
      "Iteration 3896, loss = 0.11114851\n",
      "Iteration 3897, loss = 0.11106831\n",
      "Iteration 3898, loss = 0.12415902\n",
      "Iteration 3899, loss = 0.10348953\n",
      "Iteration 3900, loss = 0.11109105\n",
      "CV Accuracy: 0.971429\n",
      "# Tuning hyper-parameters for precision\n",
      "\n",
      "Best parameters set found :\n",
      "\n",
      "{'C': 2, 'gamma': 0.001953125, 'kernel': 'rbf'}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.957 (+/-0.040) for {'C': 0.125, 'gamma': 0.00048828125, 'kernel': 'rbf'}\n",
      "0.965 (+/-0.043) for {'C': 0.125, 'gamma': 0.001953125, 'kernel': 'rbf'}\n",
      "0.964 (+/-0.045) for {'C': 0.125, 'gamma': 0.0078125, 'kernel': 'rbf'}\n",
      "0.328 (+/-0.005) for {'C': 0.125, 'gamma': 32, 'kernel': 'rbf'}\n",
      "0.907 (+/-0.059) for {'C': 0.125, 'gamma': 0.125, 'kernel': 'rbf'}\n",
      "0.428 (+/-0.408) for {'C': 0.125, 'gamma': 0.5, 'kernel': 'rbf'}\n",
      "0.328 (+/-0.005) for {'C': 0.125, 'gamma': 2, 'kernel': 'rbf'}\n",
      "0.328 (+/-0.005) for {'C': 0.125, 'gamma': 8, 'kernel': 'rbf'}\n",
      "0.965 (+/-0.043) for {'C': 0.5, 'gamma': 0.00048828125, 'kernel': 'rbf'}\n",
      "0.965 (+/-0.046) for {'C': 0.5, 'gamma': 0.001953125, 'kernel': 'rbf'}\n",
      "0.964 (+/-0.045) for {'C': 0.5, 'gamma': 0.0078125, 'kernel': 'rbf'}\n",
      "0.379 (+/-0.308) for {'C': 0.5, 'gamma': 32, 'kernel': 'rbf'}\n",
      "0.936 (+/-0.055) for {'C': 0.5, 'gamma': 0.125, 'kernel': 'rbf'}\n",
      "0.867 (+/-0.099) for {'C': 0.5, 'gamma': 0.5, 'kernel': 'rbf'}\n",
      "0.478 (+/-0.467) for {'C': 0.5, 'gamma': 2, 'kernel': 'rbf'}\n",
      "0.379 (+/-0.308) for {'C': 0.5, 'gamma': 8, 'kernel': 'rbf'}\n",
      "0.965 (+/-0.046) for {'C': 2, 'gamma': 0.00048828125, 'kernel': 'rbf'}\n",
      "0.968 (+/-0.047) for {'C': 2, 'gamma': 0.001953125, 'kernel': 'rbf'}\n",
      "0.968 (+/-0.047) for {'C': 2, 'gamma': 0.0078125, 'kernel': 'rbf'}\n",
      "0.472 (+/-0.448) for {'C': 2, 'gamma': 32, 'kernel': 'rbf'}\n",
      "0.941 (+/-0.054) for {'C': 2, 'gamma': 0.125, 'kernel': 'rbf'}\n",
      "0.905 (+/-0.067) for {'C': 2, 'gamma': 0.5, 'kernel': 'rbf'}\n",
      "0.847 (+/-0.090) for {'C': 2, 'gamma': 2, 'kernel': 'rbf'}\n",
      "0.472 (+/-0.448) for {'C': 2, 'gamma': 8, 'kernel': 'rbf'}\n",
      "0.966 (+/-0.049) for {'C': 8, 'gamma': 0.00048828125, 'kernel': 'rbf'}\n",
      "0.966 (+/-0.052) for {'C': 8, 'gamma': 0.001953125, 'kernel': 'rbf'}\n",
      "0.960 (+/-0.065) for {'C': 8, 'gamma': 0.0078125, 'kernel': 'rbf'}\n",
      "0.472 (+/-0.448) for {'C': 8, 'gamma': 32, 'kernel': 'rbf'}\n",
      "0.941 (+/-0.054) for {'C': 8, 'gamma': 0.125, 'kernel': 'rbf'}\n",
      "0.905 (+/-0.067) for {'C': 8, 'gamma': 0.5, 'kernel': 'rbf'}\n",
      "0.847 (+/-0.090) for {'C': 8, 'gamma': 2, 'kernel': 'rbf'}\n",
      "0.472 (+/-0.448) for {'C': 8, 'gamma': 8, 'kernel': 'rbf'}\n",
      "0.966 (+/-0.052) for {'C': 32, 'gamma': 0.00048828125, 'kernel': 'rbf'}\n",
      "0.962 (+/-0.060) for {'C': 32, 'gamma': 0.001953125, 'kernel': 'rbf'}\n",
      "0.955 (+/-0.068) for {'C': 32, 'gamma': 0.0078125, 'kernel': 'rbf'}\n",
      "0.472 (+/-0.448) for {'C': 32, 'gamma': 32, 'kernel': 'rbf'}\n",
      "0.941 (+/-0.054) for {'C': 32, 'gamma': 0.125, 'kernel': 'rbf'}\n",
      "0.905 (+/-0.067) for {'C': 32, 'gamma': 0.5, 'kernel': 'rbf'}\n",
      "0.847 (+/-0.090) for {'C': 32, 'gamma': 2, 'kernel': 'rbf'}\n",
      "0.472 (+/-0.448) for {'C': 32, 'gamma': 8, 'kernel': 'rbf'}\n",
      "0.961 (+/-0.059) for {'C': 128, 'gamma': 0.00048828125, 'kernel': 'rbf'}\n",
      "0.949 (+/-0.073) for {'C': 128, 'gamma': 0.001953125, 'kernel': 'rbf'}\n",
      "0.950 (+/-0.058) for {'C': 128, 'gamma': 0.0078125, 'kernel': 'rbf'}\n",
      "0.472 (+/-0.448) for {'C': 128, 'gamma': 32, 'kernel': 'rbf'}\n",
      "0.941 (+/-0.054) for {'C': 128, 'gamma': 0.125, 'kernel': 'rbf'}\n",
      "0.905 (+/-0.067) for {'C': 128, 'gamma': 0.5, 'kernel': 'rbf'}\n",
      "0.847 (+/-0.090) for {'C': 128, 'gamma': 2, 'kernel': 'rbf'}\n",
      "0.472 (+/-0.448) for {'C': 128, 'gamma': 8, 'kernel': 'rbf'}\n",
      "0.953 (+/-0.079) for {'C': 512, 'gamma': 0.00048828125, 'kernel': 'rbf'}\n",
      "0.944 (+/-0.076) for {'C': 512, 'gamma': 0.001953125, 'kernel': 'rbf'}\n",
      "0.948 (+/-0.059) for {'C': 512, 'gamma': 0.0078125, 'kernel': 'rbf'}\n",
      "0.472 (+/-0.448) for {'C': 512, 'gamma': 32, 'kernel': 'rbf'}\n",
      "0.941 (+/-0.054) for {'C': 512, 'gamma': 0.125, 'kernel': 'rbf'}\n",
      "0.905 (+/-0.067) for {'C': 512, 'gamma': 0.5, 'kernel': 'rbf'}\n",
      "0.847 (+/-0.090) for {'C': 512, 'gamma': 2, 'kernel': 'rbf'}\n",
      "0.472 (+/-0.448) for {'C': 512, 'gamma': 8, 'kernel': 'rbf'}\n",
      "0.950 (+/-0.067) for {'C': 2048, 'gamma': 0.00048828125, 'kernel': 'rbf'}\n",
      "0.945 (+/-0.055) for {'C': 2048, 'gamma': 0.001953125, 'kernel': 'rbf'}\n",
      "0.948 (+/-0.059) for {'C': 2048, 'gamma': 0.0078125, 'kernel': 'rbf'}\n",
      "0.472 (+/-0.448) for {'C': 2048, 'gamma': 32, 'kernel': 'rbf'}\n",
      "0.941 (+/-0.054) for {'C': 2048, 'gamma': 0.125, 'kernel': 'rbf'}\n",
      "0.905 (+/-0.067) for {'C': 2048, 'gamma': 0.5, 'kernel': 'rbf'}\n",
      "0.847 (+/-0.090) for {'C': 2048, 'gamma': 2, 'kernel': 'rbf'}\n",
      "0.472 (+/-0.448) for {'C': 2048, 'gamma': 8, 'kernel': 'rbf'}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           2       0.96      0.98      0.97        91\n",
      "           4       0.96      0.92      0.94        49\n",
      "\n",
      "   micro avg       0.96      0.96      0.96       140\n",
      "   macro avg       0.96      0.95      0.95       140\n",
      "weighted avg       0.96      0.96      0.96       140\n",
      "\n",
      "\n",
      "# Tuning hyper-parameters for recall\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set found :\n",
      "\n",
      "{'C': 2, 'gamma': 0.001953125, 'kernel': 'rbf'}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.925 (+/-0.100) for {'C': 0.125, 'gamma': 0.00048828125, 'kernel': 'rbf'}\n",
      "0.963 (+/-0.058) for {'C': 0.125, 'gamma': 0.001953125, 'kernel': 'rbf'}\n",
      "0.970 (+/-0.039) for {'C': 0.125, 'gamma': 0.0078125, 'kernel': 'rbf'}\n",
      "0.500 (+/-0.000) for {'C': 0.125, 'gamma': 32, 'kernel': 'rbf'}\n",
      "0.938 (+/-0.050) for {'C': 0.125, 'gamma': 0.125, 'kernel': 'rbf'}\n",
      "0.510 (+/-0.045) for {'C': 0.125, 'gamma': 0.5, 'kernel': 'rbf'}\n",
      "0.500 (+/-0.000) for {'C': 0.125, 'gamma': 2, 'kernel': 'rbf'}\n",
      "0.500 (+/-0.000) for {'C': 0.125, 'gamma': 8, 'kernel': 'rbf'}\n",
      "0.963 (+/-0.058) for {'C': 0.5, 'gamma': 0.00048828125, 'kernel': 'rbf'}\n",
      "0.968 (+/-0.051) for {'C': 0.5, 'gamma': 0.001953125, 'kernel': 'rbf'}\n",
      "0.970 (+/-0.039) for {'C': 0.5, 'gamma': 0.0078125, 'kernel': 'rbf'}\n",
      "0.507 (+/-0.042) for {'C': 0.5, 'gamma': 32, 'kernel': 'rbf'}\n",
      "0.960 (+/-0.042) for {'C': 0.5, 'gamma': 0.125, 'kernel': 'rbf'}\n",
      "0.898 (+/-0.099) for {'C': 0.5, 'gamma': 0.5, 'kernel': 'rbf'}\n",
      "0.514 (+/-0.047) for {'C': 0.5, 'gamma': 2, 'kernel': 'rbf'}\n",
      "0.507 (+/-0.042) for {'C': 0.5, 'gamma': 8, 'kernel': 'rbf'}\n",
      "0.968 (+/-0.051) for {'C': 2, 'gamma': 0.00048828125, 'kernel': 'rbf'}\n",
      "0.977 (+/-0.039) for {'C': 2, 'gamma': 0.001953125, 'kernel': 'rbf'}\n",
      "0.977 (+/-0.039) for {'C': 2, 'gamma': 0.0078125, 'kernel': 'rbf'}\n",
      "0.536 (+/-0.174) for {'C': 2, 'gamma': 32, 'kernel': 'rbf'}\n",
      "0.962 (+/-0.045) for {'C': 2, 'gamma': 0.125, 'kernel': 'rbf'}\n",
      "0.936 (+/-0.054) for {'C': 2, 'gamma': 0.5, 'kernel': 'rbf'}\n",
      "0.878 (+/-0.103) for {'C': 2, 'gamma': 2, 'kernel': 'rbf'}\n",
      "0.536 (+/-0.174) for {'C': 2, 'gamma': 8, 'kernel': 'rbf'}\n",
      "0.973 (+/-0.043) for {'C': 8, 'gamma': 0.00048828125, 'kernel': 'rbf'}\n",
      "0.973 (+/-0.052) for {'C': 8, 'gamma': 0.001953125, 'kernel': 'rbf'}\n",
      "0.963 (+/-0.078) for {'C': 8, 'gamma': 0.0078125, 'kernel': 'rbf'}\n",
      "0.536 (+/-0.174) for {'C': 8, 'gamma': 32, 'kernel': 'rbf'}\n",
      "0.962 (+/-0.045) for {'C': 8, 'gamma': 0.125, 'kernel': 'rbf'}\n",
      "0.936 (+/-0.054) for {'C': 8, 'gamma': 0.5, 'kernel': 'rbf'}\n",
      "0.878 (+/-0.103) for {'C': 8, 'gamma': 2, 'kernel': 'rbf'}\n",
      "0.536 (+/-0.174) for {'C': 8, 'gamma': 8, 'kernel': 'rbf'}\n",
      "0.973 (+/-0.052) for {'C': 32, 'gamma': 0.00048828125, 'kernel': 'rbf'}\n",
      "0.967 (+/-0.075) for {'C': 32, 'gamma': 0.001953125, 'kernel': 'rbf'}\n",
      "0.953 (+/-0.072) for {'C': 32, 'gamma': 0.0078125, 'kernel': 'rbf'}\n",
      "0.536 (+/-0.174) for {'C': 32, 'gamma': 32, 'kernel': 'rbf'}\n",
      "0.962 (+/-0.045) for {'C': 32, 'gamma': 0.125, 'kernel': 'rbf'}\n",
      "0.936 (+/-0.054) for {'C': 32, 'gamma': 0.5, 'kernel': 'rbf'}\n",
      "0.878 (+/-0.103) for {'C': 32, 'gamma': 2, 'kernel': 'rbf'}\n",
      "0.536 (+/-0.174) for {'C': 32, 'gamma': 8, 'kernel': 'rbf'}\n",
      "0.968 (+/-0.055) for {'C': 128, 'gamma': 0.00048828125, 'kernel': 'rbf'}\n",
      "0.949 (+/-0.078) for {'C': 128, 'gamma': 0.001953125, 'kernel': 'rbf'}\n",
      "0.940 (+/-0.058) for {'C': 128, 'gamma': 0.0078125, 'kernel': 'rbf'}\n",
      "0.536 (+/-0.174) for {'C': 128, 'gamma': 32, 'kernel': 'rbf'}\n",
      "0.962 (+/-0.045) for {'C': 128, 'gamma': 0.125, 'kernel': 'rbf'}\n",
      "0.936 (+/-0.054) for {'C': 128, 'gamma': 0.5, 'kernel': 'rbf'}\n",
      "0.878 (+/-0.103) for {'C': 128, 'gamma': 2, 'kernel': 'rbf'}\n",
      "0.536 (+/-0.174) for {'C': 128, 'gamma': 8, 'kernel': 'rbf'}\n",
      "0.956 (+/-0.082) for {'C': 512, 'gamma': 0.00048828125, 'kernel': 'rbf'}\n",
      "0.937 (+/-0.082) for {'C': 512, 'gamma': 0.001953125, 'kernel': 'rbf'}\n",
      "0.937 (+/-0.060) for {'C': 512, 'gamma': 0.0078125, 'kernel': 'rbf'}\n",
      "0.536 (+/-0.174) for {'C': 512, 'gamma': 32, 'kernel': 'rbf'}\n",
      "0.962 (+/-0.045) for {'C': 512, 'gamma': 0.125, 'kernel': 'rbf'}\n",
      "0.936 (+/-0.054) for {'C': 512, 'gamma': 0.5, 'kernel': 'rbf'}\n",
      "0.878 (+/-0.103) for {'C': 512, 'gamma': 2, 'kernel': 'rbf'}\n",
      "0.536 (+/-0.174) for {'C': 512, 'gamma': 8, 'kernel': 'rbf'}\n",
      "0.947 (+/-0.083) for {'C': 2048, 'gamma': 0.00048828125, 'kernel': 'rbf'}\n",
      "0.935 (+/-0.045) for {'C': 2048, 'gamma': 0.001953125, 'kernel': 'rbf'}\n",
      "0.937 (+/-0.060) for {'C': 2048, 'gamma': 0.0078125, 'kernel': 'rbf'}\n",
      "0.536 (+/-0.174) for {'C': 2048, 'gamma': 32, 'kernel': 'rbf'}\n",
      "0.962 (+/-0.045) for {'C': 2048, 'gamma': 0.125, 'kernel': 'rbf'}\n",
      "0.936 (+/-0.054) for {'C': 2048, 'gamma': 0.5, 'kernel': 'rbf'}\n",
      "0.878 (+/-0.103) for {'C': 2048, 'gamma': 2, 'kernel': 'rbf'}\n",
      "0.536 (+/-0.174) for {'C': 2048, 'gamma': 8, 'kernel': 'rbf'}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           2       0.96      0.98      0.97        91\n",
      "           4       0.96      0.92      0.94        49\n",
      "\n",
      "   micro avg       0.96      0.96      0.96       140\n",
      "   macro avg       0.96      0.95      0.95       140\n",
      "weighted avg       0.96      0.96      0.96       140\n",
      "\n",
      "\n",
      "CV Accuracy: 97.14285714285714\n",
      "[[90  1]\n",
      " [ 3 46]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           2       0.97      0.99      0.98        91\n",
      "           4       0.98      0.94      0.96        49\n",
      "\n",
      "   micro avg       0.97      0.97      0.97       140\n",
      "   macro avg       0.97      0.96      0.97       140\n",
      "weighted avg       0.97      0.97      0.97       140\n",
      "\n",
      "Accuracy = 0.964286\n",
      "Overall Accuracy=95.0 \n",
      "[[97  4]\n",
      " [ 3 36]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           2       0.72      0.75      0.73        96\n",
      "           4       0.40      0.36      0.38        44\n",
      "\n",
      "   micro avg       0.63      0.63      0.63       140\n",
      "   macro avg       0.56      0.56      0.56       140\n",
      "weighted avg       0.62      0.63      0.62       140\n",
      "\n",
      "0.95\n",
      "Classification Error=5.0 \n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x648 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 6.13208855\n",
      "Iteration 2, loss = 4.88019294\n",
      "Iteration 3, loss = 1.50933206\n",
      "Iteration 4, loss = 0.76631137\n",
      "Iteration 5, loss = 0.55737930\n",
      "Iteration 6, loss = 0.43593107\n",
      "Iteration 7, loss = 0.24844992\n",
      "Iteration 8, loss = 0.20240253\n",
      "Iteration 9, loss = 0.13845249\n",
      "Iteration 10, loss = 0.35701580\n",
      "Iteration 11, loss = 0.26701037\n",
      "Iteration 12, loss = 0.20913371\n",
      "Iteration 13, loss = 0.25035927\n",
      "Iteration 14, loss = 0.17376432\n",
      "Iteration 15, loss = 0.15969167\n",
      "Iteration 16, loss = 0.11092896\n",
      "Iteration 17, loss = 0.11311044\n",
      "Iteration 18, loss = 0.12182376\n",
      "Iteration 19, loss = 0.12097775\n",
      "Iteration 20, loss = 0.10652572\n",
      "Iteration 21, loss = 0.10473226\n",
      "Iteration 22, loss = 0.10531454\n",
      "Iteration 23, loss = 0.13111867\n",
      "Iteration 24, loss = 0.12267739\n",
      "Iteration 25, loss = 0.11632516\n",
      "Iteration 26, loss = 0.12793138\n",
      "Iteration 27, loss = 0.11708228\n",
      "Iteration 28, loss = 0.14069551\n",
      "Iteration 29, loss = 0.13402736\n",
      "Iteration 30, loss = 0.11905922\n",
      "Iteration 31, loss = 0.11972198\n",
      "Iteration 32, loss = 0.11505645\n",
      "Iteration 33, loss = 0.11324159\n",
      "Iteration 34, loss = 0.10522301\n",
      "Iteration 35, loss = 0.10412455\n",
      "Iteration 36, loss = 0.10629492\n",
      "Iteration 37, loss = 0.11811878\n",
      "Iteration 38, loss = 0.10767149\n",
      "Iteration 39, loss = 0.11133899\n",
      "Iteration 40, loss = 0.11134998\n",
      "Iteration 41, loss = 0.11440760\n",
      "Iteration 42, loss = 0.10596615\n",
      "Iteration 43, loss = 0.10913229\n",
      "Iteration 44, loss = 0.12468806\n",
      "Iteration 45, loss = 0.11860519\n",
      "Iteration 46, loss = 0.11021894\n",
      "Iteration 47, loss = 0.10962017\n",
      "Iteration 48, loss = 0.11100457\n",
      "Iteration 49, loss = 0.10695426\n",
      "Iteration 50, loss = 0.12217768\n",
      "Iteration 51, loss = 0.11344039\n",
      "Iteration 52, loss = 0.12195086\n",
      "Iteration 53, loss = 0.11183281\n",
      "Iteration 54, loss = 0.10678053\n",
      "Iteration 55, loss = 0.11706860\n",
      "Iteration 56, loss = 0.10753685\n",
      "Iteration 57, loss = 0.11942141\n",
      "Iteration 58, loss = 0.12372124\n",
      "Iteration 59, loss = 0.11982884\n",
      "Iteration 60, loss = 0.11279593\n",
      "Iteration 61, loss = 0.11520509\n",
      "Iteration 62, loss = 0.13325114\n",
      "Iteration 63, loss = 0.10590683\n",
      "Iteration 64, loss = 0.11296465\n",
      "Iteration 65, loss = 0.11741353\n",
      "Iteration 66, loss = 0.12850241\n",
      "Iteration 67, loss = 0.11028787\n",
      "Iteration 68, loss = 0.10765686\n",
      "Iteration 69, loss = 0.12043528\n",
      "Iteration 70, loss = 0.11139107\n",
      "Iteration 71, loss = 0.10700895\n",
      "Iteration 72, loss = 0.16790355\n",
      "Iteration 73, loss = 0.16152653\n",
      "Iteration 74, loss = 0.11784510\n",
      "Iteration 75, loss = 0.11563555\n",
      "Iteration 76, loss = 0.11962606\n",
      "Iteration 77, loss = 0.13458158\n",
      "Iteration 78, loss = 0.10635981\n",
      "Iteration 79, loss = 0.10734325\n",
      "Iteration 80, loss = 0.11105645\n",
      "Iteration 81, loss = 0.12567943\n",
      "Iteration 82, loss = 0.10742507\n",
      "Iteration 83, loss = 0.11437259\n",
      "Iteration 84, loss = 0.10852356\n",
      "Iteration 85, loss = 0.11137066\n",
      "Iteration 86, loss = 0.10342822\n",
      "Iteration 87, loss = 0.10707488\n",
      "Iteration 88, loss = 0.10833176\n",
      "Iteration 89, loss = 0.10525739\n",
      "Iteration 90, loss = 0.10303448\n",
      "Iteration 91, loss = 0.10390058\n",
      "Iteration 92, loss = 0.10772693\n",
      "Iteration 93, loss = 0.10840893\n",
      "Iteration 94, loss = 0.11040483\n",
      "Iteration 95, loss = 0.10643864\n",
      "Iteration 96, loss = 0.11283543\n",
      "Iteration 97, loss = 0.10324779\n",
      "Iteration 98, loss = 0.10891061\n",
      "Iteration 99, loss = 0.11263649\n",
      "Iteration 100, loss = 0.12719579\n",
      "Iteration 101, loss = 0.12228848\n",
      "Iteration 102, loss = 0.10883146\n",
      "Iteration 103, loss = 0.11645161\n",
      "Iteration 104, loss = 0.10402692\n",
      "Iteration 105, loss = 0.11277658\n",
      "Iteration 106, loss = 0.10618513\n",
      "Iteration 107, loss = 0.10846204\n",
      "Iteration 108, loss = 0.10842635\n",
      "Iteration 109, loss = 0.10990841\n",
      "Iteration 110, loss = 0.11815080\n",
      "Iteration 111, loss = 0.11506038\n",
      "Iteration 112, loss = 0.12946937\n",
      "Iteration 113, loss = 0.12702034\n",
      "Iteration 114, loss = 0.12194272\n",
      "Iteration 115, loss = 0.21283666\n",
      "Iteration 116, loss = 0.19172896\n",
      "Iteration 117, loss = 0.20787034\n",
      "Iteration 118, loss = 0.13180040\n",
      "Iteration 119, loss = 0.13555022\n",
      "Iteration 120, loss = 0.11214805\n",
      "Iteration 121, loss = 0.10562027\n",
      "Iteration 122, loss = 0.10714314\n",
      "Iteration 123, loss = 0.10968612\n",
      "Iteration 124, loss = 0.10447779\n",
      "Iteration 125, loss = 0.10795331\n",
      "Iteration 126, loss = 0.10658390\n",
      "Iteration 127, loss = 0.10500435\n",
      "Iteration 128, loss = 0.10658167\n",
      "Iteration 129, loss = 0.11118924\n",
      "Iteration 130, loss = 0.11742077\n",
      "Iteration 131, loss = 0.10910154\n",
      "Iteration 132, loss = 0.10589629\n",
      "Iteration 133, loss = 0.12202597\n",
      "Iteration 134, loss = 0.11553949\n",
      "Iteration 135, loss = 0.11334464\n",
      "Iteration 136, loss = 0.11116373\n",
      "Iteration 137, loss = 0.11426034\n",
      "Iteration 138, loss = 0.10952084\n",
      "Iteration 139, loss = 0.10982979\n",
      "Iteration 140, loss = 0.10665131\n",
      "Iteration 141, loss = 0.11180265\n",
      "Iteration 142, loss = 0.10686114\n",
      "Iteration 143, loss = 0.10972510\n",
      "Iteration 144, loss = 0.10640742\n",
      "Iteration 145, loss = 0.10435512\n",
      "Iteration 146, loss = 0.11008606\n",
      "Iteration 147, loss = 0.10550912\n",
      "Iteration 148, loss = 0.10695331\n",
      "Iteration 149, loss = 0.11706198\n",
      "Iteration 150, loss = 0.12368572\n",
      "Iteration 151, loss = 0.14154334\n",
      "Iteration 152, loss = 0.11325241\n",
      "Iteration 153, loss = 0.14529499\n",
      "Iteration 154, loss = 0.13110892\n",
      "Iteration 155, loss = 0.13176055\n",
      "Iteration 156, loss = 0.11409147\n",
      "Iteration 157, loss = 0.11859058\n",
      "Iteration 158, loss = 0.14465040\n",
      "Iteration 159, loss = 0.17095188\n",
      "Iteration 160, loss = 0.11813473\n",
      "Iteration 161, loss = 0.11626007\n",
      "Iteration 162, loss = 0.11873563\n",
      "Iteration 163, loss = 0.11762192\n",
      "Iteration 164, loss = 0.10792643\n",
      "Iteration 165, loss = 0.12773872\n",
      "Iteration 166, loss = 0.14355646\n",
      "Iteration 167, loss = 0.16825466\n",
      "Iteration 168, loss = 0.12601582\n",
      "Iteration 169, loss = 0.11619688\n",
      "Iteration 170, loss = 0.12553255\n",
      "Iteration 171, loss = 0.12629391\n",
      "Iteration 172, loss = 0.11597828\n",
      "Iteration 173, loss = 0.13403130\n",
      "Iteration 174, loss = 0.10989945\n",
      "Iteration 175, loss = 0.11190677\n",
      "Iteration 176, loss = 0.11977290\n",
      "Iteration 177, loss = 0.10882953\n",
      "Iteration 178, loss = 0.19029697\n",
      "Iteration 179, loss = 0.20743988\n",
      "Iteration 180, loss = 0.41544745\n",
      "Iteration 181, loss = 0.39881871\n",
      "Iteration 182, loss = 1.78746032\n",
      "Iteration 183, loss = 2.78402942\n",
      "Iteration 184, loss = 2.29283860\n",
      "Iteration 185, loss = 1.01711844\n",
      "Iteration 186, loss = 1.52251895\n",
      "Iteration 187, loss = 1.22230094\n",
      "Iteration 188, loss = 1.06627864\n",
      "Iteration 189, loss = 0.78692500\n",
      "Iteration 190, loss = 0.47836794\n",
      "Iteration 191, loss = 0.50958995\n",
      "Iteration 192, loss = 0.46770947\n",
      "Iteration 193, loss = 0.36143871\n",
      "Iteration 194, loss = 0.39691106\n",
      "Iteration 195, loss = 0.33306084\n",
      "Iteration 196, loss = 0.20397799\n",
      "Iteration 197, loss = 0.19405529\n",
      "Iteration 198, loss = 0.14793046\n",
      "Iteration 199, loss = 0.13120704\n",
      "Iteration 200, loss = 0.12436323\n",
      "Iteration 201, loss = 0.11455958\n",
      "Iteration 202, loss = 0.13922455\n",
      "Iteration 203, loss = 0.11838638\n",
      "Iteration 204, loss = 0.11029393\n",
      "Iteration 205, loss = 0.10763515\n",
      "Iteration 206, loss = 0.10635658\n",
      "Iteration 207, loss = 0.11119707\n",
      "Iteration 208, loss = 0.11239594\n",
      "Iteration 209, loss = 0.10986505\n",
      "Iteration 210, loss = 0.10855772\n",
      "Iteration 211, loss = 0.11140051\n",
      "Iteration 212, loss = 0.11285198\n",
      "Iteration 213, loss = 0.10364374\n",
      "Iteration 214, loss = 0.10784751\n",
      "Iteration 215, loss = 0.11783723\n",
      "Iteration 216, loss = 0.11556118\n",
      "Iteration 217, loss = 0.11976258\n",
      "Iteration 218, loss = 0.11524193\n",
      "Iteration 219, loss = 0.11715487\n",
      "Iteration 220, loss = 0.11365994\n",
      "Iteration 221, loss = 0.11172245\n",
      "Iteration 222, loss = 0.11975694\n",
      "Iteration 223, loss = 0.11004554\n",
      "Iteration 224, loss = 0.10912752\n",
      "Iteration 225, loss = 0.10912865\n",
      "Iteration 226, loss = 0.11635036\n",
      "Iteration 227, loss = 0.10886698\n",
      "Iteration 228, loss = 0.11008438\n",
      "Iteration 229, loss = 0.10584552\n",
      "Iteration 230, loss = 0.11870111\n",
      "Iteration 231, loss = 0.10786234\n",
      "Iteration 232, loss = 0.11549743\n",
      "Iteration 233, loss = 0.10848245\n",
      "Iteration 234, loss = 0.11312983\n",
      "Iteration 235, loss = 0.12320264\n",
      "Iteration 236, loss = 0.11556514\n",
      "Iteration 237, loss = 0.10863105\n",
      "Iteration 238, loss = 0.12466307\n",
      "Iteration 239, loss = 0.12581359\n",
      "Iteration 240, loss = 0.11246676\n",
      "Iteration 241, loss = 0.10812423\n",
      "Iteration 242, loss = 0.11682425\n",
      "Iteration 243, loss = 0.10674003\n",
      "Iteration 244, loss = 0.11687682\n",
      "Iteration 245, loss = 0.12026887\n",
      "Iteration 246, loss = 0.11186038\n",
      "Iteration 247, loss = 0.10327995\n",
      "Iteration 248, loss = 0.10861057\n",
      "Iteration 249, loss = 0.10635164\n",
      "Iteration 250, loss = 0.10824051\n",
      "Iteration 251, loss = 0.10749440\n",
      "Iteration 252, loss = 0.11475569\n",
      "Iteration 253, loss = 0.11175368\n",
      "Iteration 254, loss = 0.10738420\n",
      "Iteration 255, loss = 0.11164422\n",
      "Iteration 256, loss = 0.11387812\n",
      "Iteration 257, loss = 0.10696921\n",
      "Iteration 258, loss = 0.13898993\n",
      "Iteration 259, loss = 0.10977887\n",
      "Iteration 260, loss = 0.10373081\n",
      "Iteration 261, loss = 0.10581846\n",
      "Iteration 262, loss = 0.10743947\n",
      "Iteration 263, loss = 0.10849239\n",
      "Iteration 264, loss = 0.10610009\n",
      "Iteration 265, loss = 0.12383827\n",
      "Iteration 266, loss = 0.12993318\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 267, loss = 0.10979107\n",
      "Iteration 268, loss = 0.11385676\n",
      "Iteration 269, loss = 0.11225493\n",
      "Iteration 270, loss = 0.10420034\n",
      "Iteration 271, loss = 0.11479179\n",
      "Iteration 272, loss = 0.11461770\n",
      "Iteration 273, loss = 0.13682883\n",
      "Iteration 274, loss = 0.10937806\n",
      "Iteration 275, loss = 0.10372772\n",
      "Iteration 276, loss = 0.12029713\n",
      "Iteration 277, loss = 0.11941212\n",
      "Iteration 278, loss = 0.12900713\n",
      "Iteration 279, loss = 0.11344346\n",
      "Iteration 280, loss = 0.12944198\n",
      "Iteration 281, loss = 0.12636087\n",
      "Iteration 282, loss = 0.12694971\n",
      "Iteration 283, loss = 0.12116383\n",
      "Iteration 284, loss = 0.11315619\n",
      "Iteration 285, loss = 0.12210800\n",
      "Iteration 286, loss = 0.12215285\n",
      "Iteration 287, loss = 0.11156104\n",
      "Iteration 288, loss = 0.12732814\n",
      "Iteration 289, loss = 0.10503560\n",
      "Iteration 290, loss = 0.11556355\n",
      "Iteration 291, loss = 0.11835018\n",
      "Iteration 292, loss = 0.10974824\n",
      "Iteration 293, loss = 0.10387972\n",
      "Iteration 294, loss = 0.10854962\n",
      "Iteration 295, loss = 0.12084181\n",
      "Iteration 296, loss = 0.11952421\n",
      "Iteration 297, loss = 0.11327242\n",
      "Iteration 298, loss = 0.10796364\n",
      "Iteration 299, loss = 0.10493169\n",
      "Iteration 300, loss = 0.10635816\n",
      "Iteration 301, loss = 0.10352677\n",
      "Iteration 302, loss = 0.11654901\n",
      "Iteration 303, loss = 0.10456991\n",
      "Iteration 304, loss = 0.11166843\n",
      "Iteration 305, loss = 0.10813932\n",
      "Iteration 306, loss = 0.10475040\n",
      "Iteration 307, loss = 0.13718327\n",
      "Iteration 308, loss = 0.10997792\n",
      "Iteration 309, loss = 0.10901258\n",
      "Iteration 310, loss = 0.10820277\n",
      "Iteration 311, loss = 0.11067402\n",
      "Iteration 312, loss = 0.12079836\n",
      "Iteration 313, loss = 0.10942523\n",
      "Iteration 314, loss = 0.11506138\n",
      "Iteration 315, loss = 0.11889408\n",
      "Iteration 316, loss = 0.13000737\n",
      "Iteration 317, loss = 0.11471189\n",
      "Iteration 318, loss = 0.12182780\n",
      "Iteration 319, loss = 0.10854504\n",
      "Iteration 320, loss = 0.11761394\n",
      "Iteration 321, loss = 0.10729172\n",
      "Iteration 322, loss = 0.10369128\n",
      "Iteration 323, loss = 0.12028498\n",
      "Iteration 324, loss = 0.11501766\n",
      "Iteration 325, loss = 0.11705998\n",
      "Iteration 326, loss = 0.10551438\n",
      "Iteration 327, loss = 0.11306881\n",
      "Iteration 328, loss = 0.10479934\n",
      "Iteration 329, loss = 0.11072348\n",
      "Iteration 330, loss = 0.11450064\n",
      "Iteration 331, loss = 0.10734082\n",
      "Iteration 332, loss = 0.11031651\n",
      "Iteration 333, loss = 0.11550445\n",
      "Iteration 334, loss = 0.12194486\n",
      "Iteration 335, loss = 0.11848497\n",
      "Iteration 336, loss = 0.10629804\n",
      "Iteration 337, loss = 0.10449389\n",
      "Iteration 338, loss = 0.11174431\n",
      "Iteration 339, loss = 0.10665541\n",
      "Iteration 340, loss = 0.10615306\n",
      "Iteration 341, loss = 0.10407045\n",
      "Iteration 342, loss = 0.11318347\n",
      "Iteration 343, loss = 0.11454933\n",
      "Iteration 344, loss = 0.11226145\n",
      "Iteration 345, loss = 0.11764499\n",
      "Iteration 346, loss = 0.11846560\n",
      "Iteration 347, loss = 0.10884486\n",
      "Iteration 348, loss = 0.11125456\n",
      "Iteration 349, loss = 0.10146193\n",
      "Iteration 350, loss = 0.10509943\n",
      "Iteration 351, loss = 0.11629733\n",
      "Iteration 352, loss = 0.10921387\n",
      "Iteration 353, loss = 0.10186387\n",
      "Iteration 354, loss = 0.15641315\n",
      "Iteration 355, loss = 0.10908712\n",
      "Iteration 356, loss = 0.11986926\n",
      "Iteration 357, loss = 0.11390253\n",
      "Iteration 358, loss = 0.10435677\n",
      "Iteration 359, loss = 0.10537637\n",
      "Iteration 360, loss = 0.11360766\n",
      "Iteration 361, loss = 0.11898368\n",
      "Iteration 362, loss = 0.11604774\n",
      "Iteration 363, loss = 0.12978330\n",
      "Iteration 364, loss = 0.16523131\n",
      "Iteration 365, loss = 0.43548845\n",
      "Iteration 366, loss = 0.32018441\n",
      "Iteration 367, loss = 0.27678071\n",
      "Iteration 368, loss = 0.39439230\n",
      "Iteration 369, loss = 0.63163175\n",
      "Iteration 370, loss = 1.81099885\n",
      "Iteration 371, loss = 3.24857297\n",
      "Iteration 372, loss = 2.53028752\n",
      "Iteration 373, loss = 4.76401017\n",
      "Iteration 374, loss = 2.11186136\n",
      "Iteration 375, loss = 1.50824844\n",
      "Iteration 376, loss = 1.10523361\n",
      "Iteration 377, loss = 0.87815056\n",
      "Iteration 378, loss = 0.82580034\n",
      "Iteration 379, loss = 0.96747018\n",
      "Iteration 380, loss = 0.97095445\n",
      "Iteration 381, loss = 0.54535861\n",
      "Iteration 382, loss = 0.60491490\n",
      "Iteration 383, loss = 0.55937270\n",
      "Iteration 384, loss = 0.55676851\n",
      "Iteration 385, loss = 0.48651864\n",
      "Iteration 386, loss = 0.44515832\n",
      "Iteration 387, loss = 0.50119904\n",
      "Iteration 388, loss = 0.28755337\n",
      "Iteration 389, loss = 0.44363148\n",
      "Iteration 390, loss = 0.26851558\n",
      "Iteration 391, loss = 0.48759974\n",
      "Iteration 392, loss = 0.42722504\n",
      "Iteration 393, loss = 0.48255304\n",
      "Iteration 394, loss = 0.38630996\n",
      "Iteration 395, loss = 0.35054356\n",
      "Iteration 396, loss = 0.41415565\n",
      "Iteration 397, loss = 0.37742396\n",
      "Iteration 398, loss = 0.26343152\n",
      "Iteration 399, loss = 0.52584927\n",
      "Iteration 400, loss = 0.66425361\n",
      "Iteration 401, loss = 0.63233236\n",
      "Iteration 402, loss = 0.36669180\n",
      "Iteration 403, loss = 0.53380975\n",
      "Iteration 404, loss = 0.43397023\n",
      "Iteration 405, loss = 0.52732671\n",
      "Iteration 406, loss = 0.20980074\n",
      "Iteration 407, loss = 0.17968568\n",
      "Iteration 408, loss = 0.36020158\n",
      "Iteration 409, loss = 0.87359231\n",
      "Iteration 410, loss = 0.53199469\n",
      "Iteration 411, loss = 0.54332858\n",
      "Iteration 412, loss = 0.46889997\n",
      "Iteration 413, loss = 0.30632712\n",
      "Iteration 414, loss = 0.21638613\n",
      "Iteration 415, loss = 0.20140317\n",
      "Iteration 416, loss = 0.53640319\n",
      "Iteration 417, loss = 0.51110073\n",
      "Iteration 418, loss = 0.22289485\n",
      "Iteration 419, loss = 0.27115392\n",
      "Iteration 420, loss = 0.17286045\n",
      "Iteration 421, loss = 0.27350144\n",
      "Iteration 422, loss = 0.17244573\n",
      "Iteration 423, loss = 0.18965417\n",
      "Iteration 424, loss = 0.14753389\n",
      "Iteration 425, loss = 0.14269969\n",
      "Iteration 426, loss = 0.12987951\n",
      "Iteration 427, loss = 0.13070509\n",
      "Iteration 428, loss = 0.12735317\n",
      "Iteration 429, loss = 0.11925304\n",
      "Iteration 430, loss = 0.12756323\n",
      "Iteration 431, loss = 0.10843351\n",
      "Iteration 432, loss = 0.11150488\n",
      "Iteration 433, loss = 0.11573230\n",
      "Iteration 434, loss = 0.11566498\n",
      "Iteration 435, loss = 0.12495517\n",
      "Iteration 436, loss = 0.11459054\n",
      "Iteration 437, loss = 0.10918541\n",
      "Iteration 438, loss = 0.12085869\n",
      "Iteration 439, loss = 0.13008098\n",
      "Iteration 440, loss = 0.11580717\n",
      "Iteration 441, loss = 0.11500985\n",
      "Iteration 442, loss = 0.11442691\n",
      "Iteration 443, loss = 0.10657367\n",
      "Iteration 444, loss = 0.12980380\n",
      "Iteration 445, loss = 0.30566934\n",
      "Iteration 446, loss = 0.19304601\n",
      "Iteration 447, loss = 0.13842176\n",
      "Iteration 448, loss = 0.12088390\n",
      "Iteration 449, loss = 0.13532214\n",
      "Iteration 450, loss = 0.14148937\n",
      "Iteration 451, loss = 0.24265054\n",
      "Iteration 452, loss = 0.12700294\n",
      "Iteration 453, loss = 0.18428004\n",
      "Iteration 454, loss = 0.21711221\n",
      "Iteration 455, loss = 0.27076068\n",
      "Iteration 456, loss = 0.14116310\n",
      "Iteration 457, loss = 0.15371160\n",
      "Iteration 458, loss = 0.20320398\n",
      "Iteration 459, loss = 0.11294175\n",
      "Iteration 460, loss = 0.13999675\n",
      "Iteration 461, loss = 0.20873946\n",
      "Iteration 462, loss = 0.13868390\n",
      "Iteration 463, loss = 0.12795182\n",
      "Iteration 464, loss = 0.12598942\n",
      "Iteration 465, loss = 0.13780074\n",
      "Iteration 466, loss = 0.11931476\n",
      "Iteration 467, loss = 0.10837451\n",
      "Iteration 468, loss = 0.13668830\n",
      "Iteration 469, loss = 0.12525761\n",
      "Iteration 470, loss = 0.13223321\n",
      "Iteration 471, loss = 0.19870137\n",
      "Iteration 472, loss = 0.25523159\n",
      "Iteration 473, loss = 0.21871568\n",
      "Iteration 474, loss = 0.21094734\n",
      "Iteration 475, loss = 0.17036153\n",
      "Iteration 476, loss = 0.17635832\n",
      "Iteration 477, loss = 0.13284247\n",
      "Iteration 478, loss = 0.10709877\n",
      "Iteration 479, loss = 0.12515399\n",
      "Iteration 480, loss = 0.11422136\n",
      "Iteration 481, loss = 0.14509892\n",
      "Iteration 482, loss = 0.12303185\n",
      "Iteration 483, loss = 0.12070725\n",
      "Iteration 484, loss = 0.12666363\n",
      "Iteration 485, loss = 0.11028901\n",
      "Iteration 486, loss = 0.13207288\n",
      "Iteration 487, loss = 0.12968526\n",
      "Iteration 488, loss = 0.12009235\n",
      "Iteration 489, loss = 0.12057673\n",
      "Iteration 490, loss = 0.11406486\n",
      "Iteration 491, loss = 0.10816447\n",
      "Iteration 492, loss = 0.10818842\n",
      "Iteration 493, loss = 0.10628263\n",
      "Iteration 494, loss = 0.11900717\n",
      "Iteration 495, loss = 0.10654367\n",
      "Iteration 496, loss = 0.12003118\n",
      "Iteration 497, loss = 0.27703952\n",
      "Iteration 498, loss = 0.21606375\n",
      "Iteration 499, loss = 0.37143944\n",
      "Iteration 500, loss = 0.42182898\n",
      "Iteration 501, loss = 0.22576975\n",
      "Iteration 502, loss = 0.33837704\n",
      "Iteration 503, loss = 0.30512488\n",
      "Iteration 504, loss = 0.16623508\n",
      "Iteration 505, loss = 0.14453432\n",
      "Iteration 506, loss = 0.17403731\n",
      "Iteration 507, loss = 0.15551613\n",
      "Iteration 508, loss = 0.11992436\n",
      "Iteration 509, loss = 0.13319044\n",
      "Iteration 510, loss = 0.11225991\n",
      "Iteration 511, loss = 0.12360130\n",
      "Iteration 512, loss = 0.12130045\n",
      "Iteration 513, loss = 0.12518492\n",
      "Iteration 514, loss = 0.13863985\n",
      "Iteration 515, loss = 0.12105160\n",
      "Iteration 516, loss = 0.12300514\n",
      "Iteration 517, loss = 0.12879216\n",
      "Iteration 518, loss = 0.15419827\n",
      "Iteration 519, loss = 0.11272391\n",
      "Iteration 520, loss = 0.14870502\n",
      "Iteration 521, loss = 0.11816330\n",
      "Iteration 522, loss = 0.10998773\n",
      "Iteration 523, loss = 0.11646146\n",
      "Iteration 524, loss = 0.11285198\n",
      "Iteration 525, loss = 0.11258417\n",
      "Iteration 526, loss = 0.11122721\n",
      "Iteration 527, loss = 0.11769861\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 528, loss = 0.12972734\n",
      "Iteration 529, loss = 0.12170878\n",
      "Iteration 530, loss = 0.10260144\n",
      "Iteration 531, loss = 0.12018518\n",
      "Iteration 532, loss = 0.12033901\n",
      "Iteration 533, loss = 0.13393399\n",
      "Iteration 534, loss = 0.11656746\n",
      "Iteration 535, loss = 0.12789339\n",
      "Iteration 536, loss = 0.13322298\n",
      "Iteration 537, loss = 0.11445585\n",
      "Iteration 538, loss = 0.12196835\n",
      "Iteration 539, loss = 0.11032517\n",
      "Iteration 540, loss = 0.11479492\n",
      "Iteration 541, loss = 0.15361886\n",
      "Iteration 542, loss = 0.11678336\n",
      "Iteration 543, loss = 0.11099959\n",
      "Iteration 544, loss = 0.11791449\n",
      "Iteration 545, loss = 0.11554442\n",
      "Iteration 546, loss = 0.11702673\n",
      "Iteration 547, loss = 0.12250367\n",
      "Iteration 548, loss = 0.14120787\n",
      "Iteration 549, loss = 0.12369855\n",
      "Iteration 550, loss = 0.14642403\n",
      "Iteration 551, loss = 0.20611412\n",
      "Iteration 552, loss = 0.29877934\n",
      "Iteration 553, loss = 0.17259951\n",
      "Iteration 554, loss = 0.27749827\n",
      "Iteration 555, loss = 0.20489266\n",
      "Iteration 556, loss = 0.16246346\n",
      "Iteration 557, loss = 0.15166525\n",
      "Iteration 558, loss = 0.13524148\n",
      "Iteration 559, loss = 0.11721506\n",
      "Iteration 560, loss = 0.10785250\n",
      "Iteration 561, loss = 0.11541782\n",
      "Iteration 562, loss = 0.11726405\n",
      "Iteration 563, loss = 0.11568490\n",
      "Iteration 564, loss = 0.11154715\n",
      "Iteration 565, loss = 0.11875035\n",
      "Iteration 566, loss = 0.10832199\n",
      "Iteration 567, loss = 0.11188887\n",
      "Iteration 568, loss = 0.10625491\n",
      "Iteration 569, loss = 0.10638275\n",
      "Iteration 570, loss = 0.10717457\n",
      "Iteration 571, loss = 0.10852548\n",
      "Iteration 572, loss = 0.10806728\n",
      "Iteration 573, loss = 0.10175737\n",
      "Iteration 574, loss = 0.10952620\n",
      "Iteration 575, loss = 0.10524715\n",
      "Iteration 576, loss = 0.10475535\n",
      "Iteration 577, loss = 0.10517057\n",
      "Iteration 578, loss = 0.11188853\n",
      "Iteration 579, loss = 0.10580423\n",
      "Iteration 580, loss = 0.10287657\n",
      "Iteration 581, loss = 0.12974176\n",
      "Iteration 582, loss = 0.13236595\n",
      "Iteration 583, loss = 0.11504614\n",
      "Iteration 584, loss = 0.11712999\n",
      "Iteration 585, loss = 0.12130567\n",
      "Iteration 586, loss = 0.11942807\n",
      "Iteration 587, loss = 0.12447925\n",
      "Iteration 588, loss = 0.12609068\n",
      "Iteration 589, loss = 0.11596955\n",
      "Iteration 590, loss = 0.12867421\n",
      "Iteration 591, loss = 0.10647243\n",
      "Iteration 592, loss = 0.12875451\n",
      "Iteration 593, loss = 0.11164484\n",
      "Iteration 594, loss = 0.13377065\n",
      "Iteration 595, loss = 0.12679561\n",
      "Iteration 596, loss = 0.13730977\n",
      "Iteration 597, loss = 0.13489506\n",
      "Iteration 598, loss = 0.11845259\n",
      "Iteration 599, loss = 0.11441868\n",
      "Iteration 600, loss = 0.11242989\n",
      "Iteration 601, loss = 0.12245866\n",
      "Iteration 602, loss = 0.11067780\n",
      "Iteration 603, loss = 0.10619394\n",
      "Iteration 604, loss = 0.11008510\n",
      "Iteration 605, loss = 0.11219033\n",
      "Iteration 606, loss = 0.12532590\n",
      "Iteration 607, loss = 0.11166148\n",
      "Iteration 608, loss = 0.12197864\n",
      "Iteration 609, loss = 0.10930166\n",
      "Iteration 610, loss = 0.11490460\n",
      "Iteration 611, loss = 0.11116396\n",
      "Iteration 612, loss = 0.11107663\n",
      "Iteration 613, loss = 0.11221315\n",
      "Iteration 614, loss = 0.10563937\n",
      "Iteration 615, loss = 0.10727167\n",
      "Iteration 616, loss = 0.10658985\n",
      "Iteration 617, loss = 0.11230178\n",
      "Iteration 618, loss = 0.12886089\n",
      "Iteration 619, loss = 0.11290828\n",
      "Iteration 620, loss = 0.13432666\n",
      "Iteration 621, loss = 0.11462587\n",
      "Iteration 622, loss = 0.11939611\n",
      "Iteration 623, loss = 0.11346108\n",
      "Iteration 624, loss = 0.12797813\n",
      "Iteration 625, loss = 0.10634043\n",
      "Iteration 626, loss = 0.10913784\n",
      "Iteration 627, loss = 0.12909040\n",
      "Iteration 628, loss = 0.12314783\n",
      "Iteration 629, loss = 0.11473897\n",
      "Iteration 630, loss = 0.11305171\n",
      "Iteration 631, loss = 0.12364526\n",
      "Iteration 632, loss = 0.13670739\n",
      "Iteration 633, loss = 0.12632064\n",
      "Iteration 634, loss = 0.14838543\n",
      "Iteration 635, loss = 0.40619164\n",
      "Iteration 636, loss = 0.32558416\n",
      "Iteration 637, loss = 0.27673535\n",
      "Iteration 638, loss = 0.55689948\n",
      "Iteration 639, loss = 0.47550195\n",
      "Iteration 640, loss = 0.31106205\n",
      "Iteration 641, loss = 0.24813211\n",
      "Iteration 642, loss = 0.19361338\n",
      "Iteration 643, loss = 0.21289880\n",
      "Iteration 644, loss = 0.16066281\n",
      "Iteration 645, loss = 0.12217071\n",
      "Iteration 646, loss = 0.12010876\n",
      "Iteration 647, loss = 0.11243024\n",
      "Iteration 648, loss = 0.13672014\n",
      "Iteration 649, loss = 0.13069198\n",
      "Iteration 650, loss = 0.13342352\n",
      "Iteration 651, loss = 0.14471127\n",
      "Iteration 652, loss = 0.16174983\n",
      "Iteration 653, loss = 0.17338435\n",
      "Iteration 654, loss = 0.13921159\n",
      "Iteration 655, loss = 0.12440642\n",
      "Iteration 656, loss = 0.11030707\n",
      "Iteration 657, loss = 0.13845322\n",
      "Iteration 658, loss = 0.11727283\n",
      "Iteration 659, loss = 0.14751040\n",
      "Iteration 660, loss = 0.11427565\n",
      "Iteration 661, loss = 0.10597797\n",
      "Iteration 662, loss = 0.10435906\n",
      "Iteration 663, loss = 0.10722311\n",
      "Iteration 664, loss = 0.12466244\n",
      "Iteration 665, loss = 0.10502668\n",
      "Iteration 666, loss = 0.11659692\n",
      "Iteration 667, loss = 0.13312879\n",
      "Iteration 668, loss = 0.12058313\n",
      "Iteration 669, loss = 0.11553653\n",
      "Iteration 670, loss = 0.10551579\n",
      "Iteration 671, loss = 0.11675069\n",
      "Iteration 672, loss = 0.15392583\n",
      "Iteration 673, loss = 0.12488146\n",
      "Iteration 674, loss = 0.11913950\n",
      "Iteration 675, loss = 0.13966039\n",
      "Iteration 676, loss = 0.11617629\n",
      "Iteration 677, loss = 0.13083556\n",
      "Iteration 678, loss = 0.13687986\n",
      "Iteration 679, loss = 0.11838068\n",
      "Iteration 680, loss = 0.13524430\n",
      "Iteration 681, loss = 0.10970772\n",
      "Iteration 682, loss = 0.11142278\n",
      "Iteration 683, loss = 0.10485610\n",
      "Iteration 684, loss = 0.10721613\n",
      "Iteration 685, loss = 0.12791461\n",
      "Iteration 686, loss = 0.11663048\n",
      "Iteration 687, loss = 0.11282916\n",
      "Iteration 688, loss = 0.11139417\n",
      "Iteration 689, loss = 0.13821766\n",
      "Iteration 690, loss = 0.16985883\n",
      "Iteration 691, loss = 0.24887502\n",
      "Iteration 692, loss = 0.22388633\n",
      "Iteration 693, loss = 0.18100157\n",
      "Iteration 694, loss = 0.22090860\n",
      "Iteration 695, loss = 0.12492337\n",
      "Iteration 696, loss = 0.12728021\n",
      "Iteration 697, loss = 0.11872486\n",
      "Iteration 698, loss = 0.11149751\n",
      "Iteration 699, loss = 0.12236984\n",
      "Iteration 700, loss = 0.11823834\n",
      "Iteration 701, loss = 0.10973680\n",
      "Iteration 702, loss = 0.10976443\n",
      "Iteration 703, loss = 0.11797867\n",
      "Iteration 704, loss = 0.11393583\n",
      "Iteration 705, loss = 0.10712990\n",
      "Iteration 706, loss = 0.11293368\n",
      "Iteration 707, loss = 0.10726860\n",
      "Iteration 708, loss = 0.13317860\n",
      "Iteration 709, loss = 0.11132060\n",
      "Iteration 710, loss = 0.12732690\n",
      "Iteration 711, loss = 0.10586436\n",
      "Iteration 712, loss = 0.13585364\n",
      "Iteration 713, loss = 0.12129359\n",
      "Iteration 714, loss = 0.10541459\n",
      "Iteration 715, loss = 0.10880903\n",
      "Iteration 716, loss = 0.12676902\n",
      "Iteration 717, loss = 0.11562713\n",
      "Iteration 718, loss = 0.12418564\n",
      "Iteration 719, loss = 0.13005982\n",
      "Iteration 720, loss = 0.12118834\n",
      "Iteration 721, loss = 0.16784958\n",
      "Iteration 722, loss = 0.10319284\n",
      "Iteration 723, loss = 0.10878305\n",
      "Iteration 724, loss = 0.11216441\n",
      "Iteration 725, loss = 0.12005797\n",
      "Iteration 726, loss = 0.12699473\n",
      "Iteration 727, loss = 0.12730222\n",
      "Iteration 728, loss = 0.11645433\n",
      "Iteration 729, loss = 0.12509731\n",
      "Iteration 730, loss = 0.11174104\n",
      "Iteration 731, loss = 0.12900519\n",
      "Iteration 732, loss = 0.20618105\n",
      "Iteration 733, loss = 0.34495498\n",
      "Iteration 734, loss = 0.22508856\n",
      "Iteration 735, loss = 0.24163988\n",
      "Iteration 736, loss = 0.14758997\n",
      "Iteration 737, loss = 0.13952067\n",
      "Iteration 738, loss = 0.26592814\n",
      "Iteration 739, loss = 0.25454247\n",
      "Iteration 740, loss = 0.19186904\n",
      "Iteration 741, loss = 0.16285161\n",
      "Iteration 742, loss = 0.15095895\n",
      "Iteration 743, loss = 0.14214009\n",
      "Iteration 744, loss = 0.15358629\n",
      "Iteration 745, loss = 0.17700663\n",
      "Iteration 746, loss = 0.17852668\n",
      "Iteration 747, loss = 0.18937237\n",
      "Iteration 748, loss = 0.19377890\n",
      "Iteration 749, loss = 0.15027658\n",
      "Iteration 750, loss = 0.19665161\n",
      "Iteration 751, loss = 0.86958674\n",
      "Iteration 752, loss = 0.99390183\n",
      "Iteration 753, loss = 0.55479826\n",
      "Iteration 754, loss = 0.40146320\n",
      "Iteration 755, loss = 0.39270437\n",
      "Iteration 756, loss = 0.16695882\n",
      "Iteration 757, loss = 0.14296836\n",
      "Iteration 758, loss = 0.13747073\n",
      "Iteration 759, loss = 0.17244165\n",
      "Iteration 760, loss = 0.16307496\n",
      "Iteration 761, loss = 0.17703108\n",
      "Iteration 762, loss = 0.20928082\n",
      "Iteration 763, loss = 0.13607367\n",
      "Iteration 764, loss = 0.14211528\n",
      "Iteration 765, loss = 0.15069818\n",
      "Iteration 766, loss = 0.17829335\n",
      "Iteration 767, loss = 0.12089448\n",
      "Iteration 768, loss = 0.10506325\n",
      "Iteration 769, loss = 0.12876074\n",
      "Iteration 770, loss = 0.11475353\n",
      "Iteration 771, loss = 0.12369386\n",
      "Iteration 772, loss = 0.14711719\n",
      "Iteration 773, loss = 0.12767018\n",
      "Iteration 774, loss = 0.12043956\n",
      "Iteration 775, loss = 0.14861785\n",
      "Iteration 776, loss = 0.11998887\n",
      "Iteration 777, loss = 0.10675739\n",
      "Iteration 778, loss = 0.13088167\n",
      "Iteration 779, loss = 0.12325087\n",
      "Iteration 780, loss = 0.16733867\n",
      "Iteration 781, loss = 0.32648294\n",
      "Iteration 782, loss = 0.94981338\n",
      "Iteration 783, loss = 0.73752687\n",
      "Iteration 784, loss = 1.02146744\n",
      "Iteration 785, loss = 0.52916778\n",
      "Iteration 786, loss = 4.15364504\n",
      "Iteration 787, loss = 4.05535940\n",
      "Iteration 788, loss = 1.51929639\n",
      "Iteration 789, loss = 1.17151022\n",
      "Iteration 790, loss = 1.04857832\n",
      "Iteration 791, loss = 1.14604804\n",
      "Iteration 792, loss = 1.03486369\n",
      "Iteration 793, loss = 0.74736455\n",
      "Iteration 794, loss = 0.82777842\n",
      "Iteration 795, loss = 0.75350874\n",
      "Iteration 796, loss = 0.73757170\n",
      "Iteration 797, loss = 0.83008645\n",
      "Iteration 798, loss = 0.60859094\n",
      "Iteration 799, loss = 0.64755286\n",
      "Iteration 800, loss = 0.57924964\n",
      "Iteration 801, loss = 0.46026122\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 802, loss = 0.31708588\n",
      "Iteration 803, loss = 0.30603652\n",
      "Iteration 804, loss = 0.35134078\n",
      "Iteration 805, loss = 0.49276521\n",
      "Iteration 806, loss = 0.27663007\n",
      "Iteration 807, loss = 0.22475939\n",
      "Iteration 808, loss = 0.23475888\n",
      "Iteration 809, loss = 0.21386884\n",
      "Iteration 810, loss = 0.26420009\n",
      "Iteration 811, loss = 0.42355018\n",
      "Iteration 812, loss = 0.70366017\n",
      "Iteration 813, loss = 0.46913827\n",
      "Iteration 814, loss = 0.48166218\n",
      "Iteration 815, loss = 0.36223777\n",
      "Iteration 816, loss = 0.33214777\n",
      "Iteration 817, loss = 0.31189698\n",
      "Iteration 818, loss = 0.40199044\n",
      "Iteration 819, loss = 0.35317782\n",
      "Iteration 820, loss = 0.26476721\n",
      "Iteration 821, loss = 0.18238570\n",
      "Iteration 822, loss = 0.23511176\n",
      "Iteration 823, loss = 0.22207159\n",
      "Iteration 824, loss = 0.19307960\n",
      "Iteration 825, loss = 0.15016135\n",
      "Iteration 826, loss = 0.15198801\n",
      "Iteration 827, loss = 0.15625017\n",
      "Iteration 828, loss = 0.18776415\n",
      "Iteration 829, loss = 0.15426525\n",
      "Iteration 830, loss = 0.12722209\n",
      "Iteration 831, loss = 0.13617868\n",
      "Iteration 832, loss = 0.13556725\n",
      "Iteration 833, loss = 0.11982666\n",
      "Iteration 834, loss = 0.12193195\n",
      "Iteration 835, loss = 0.11434130\n",
      "Iteration 836, loss = 0.14917487\n",
      "Iteration 837, loss = 0.14025076\n",
      "Iteration 838, loss = 0.12139508\n",
      "Iteration 839, loss = 0.11291235\n",
      "Iteration 840, loss = 0.11392773\n",
      "Iteration 841, loss = 0.12534156\n",
      "Iteration 842, loss = 0.10961632\n",
      "Iteration 843, loss = 0.10977710\n",
      "Iteration 844, loss = 0.13513309\n",
      "Iteration 845, loss = 0.13543335\n",
      "Iteration 846, loss = 0.15105162\n",
      "Iteration 847, loss = 0.13764934\n",
      "Iteration 848, loss = 0.11947771\n",
      "Iteration 849, loss = 0.11799731\n",
      "Iteration 850, loss = 0.11242505\n",
      "Iteration 851, loss = 0.11247589\n",
      "Iteration 852, loss = 0.11660034\n",
      "Iteration 853, loss = 0.13223241\n",
      "Iteration 854, loss = 0.19707212\n",
      "Iteration 855, loss = 0.25749887\n",
      "Iteration 856, loss = 0.15139335\n",
      "Iteration 857, loss = 0.15764857\n",
      "Iteration 858, loss = 0.13370640\n",
      "Iteration 859, loss = 0.25731532\n",
      "Iteration 860, loss = 0.50355178\n",
      "Iteration 861, loss = 0.31490536\n",
      "Iteration 862, loss = 0.21165571\n",
      "Iteration 863, loss = 0.20656488\n",
      "Iteration 864, loss = 0.28096691\n",
      "Iteration 865, loss = 0.23093690\n",
      "Iteration 866, loss = 0.14215541\n",
      "Iteration 867, loss = 0.13139640\n",
      "Iteration 868, loss = 0.12686757\n",
      "Iteration 869, loss = 0.11231052\n",
      "Iteration 870, loss = 0.11553725\n",
      "Iteration 871, loss = 0.13786709\n",
      "Iteration 872, loss = 0.15375135\n",
      "Iteration 873, loss = 0.12296876\n",
      "Iteration 874, loss = 0.16640003\n",
      "Iteration 875, loss = 0.12235572\n",
      "Iteration 876, loss = 0.11986561\n",
      "Iteration 877, loss = 0.12375792\n",
      "Iteration 878, loss = 0.12364636\n",
      "Iteration 879, loss = 0.11979322\n",
      "Iteration 880, loss = 0.11007691\n",
      "Iteration 881, loss = 0.12348463\n",
      "Iteration 882, loss = 0.11663348\n",
      "Iteration 883, loss = 0.11302021\n",
      "Iteration 884, loss = 0.11384631\n",
      "Iteration 885, loss = 0.11674557\n",
      "Iteration 886, loss = 0.12011378\n",
      "Iteration 887, loss = 0.12193209\n",
      "Iteration 888, loss = 0.12453117\n",
      "Iteration 889, loss = 0.11887332\n",
      "Iteration 890, loss = 0.12097676\n",
      "Iteration 891, loss = 0.10799901\n",
      "Iteration 892, loss = 0.13493126\n",
      "Iteration 893, loss = 0.12583974\n",
      "Iteration 894, loss = 0.12843609\n",
      "Iteration 895, loss = 0.12334069\n",
      "Iteration 896, loss = 0.13023216\n",
      "Iteration 897, loss = 0.14310243\n",
      "Iteration 898, loss = 0.17537589\n",
      "Iteration 899, loss = 0.19278199\n",
      "Iteration 900, loss = 0.14622878\n",
      "Iteration 901, loss = 0.11080096\n",
      "Iteration 902, loss = 0.11156121\n",
      "Iteration 903, loss = 0.11350157\n",
      "Iteration 904, loss = 0.15809336\n",
      "Iteration 905, loss = 0.11470601\n",
      "Iteration 906, loss = 0.10775921\n",
      "Iteration 907, loss = 0.10708879\n",
      "Iteration 908, loss = 0.12546275\n",
      "Iteration 909, loss = 0.12169226\n",
      "Iteration 910, loss = 0.12911592\n",
      "Iteration 911, loss = 0.13934561\n",
      "Iteration 912, loss = 0.33429899\n",
      "Iteration 913, loss = 0.21273972\n",
      "Iteration 914, loss = 0.19871669\n",
      "Iteration 915, loss = 0.18422575\n",
      "Iteration 916, loss = 0.17417730\n",
      "Iteration 917, loss = 0.15960569\n",
      "Iteration 918, loss = 0.13579653\n",
      "Iteration 919, loss = 0.12159078\n",
      "Iteration 920, loss = 0.11755715\n",
      "Iteration 921, loss = 0.11272130\n",
      "Iteration 922, loss = 0.11014683\n",
      "Iteration 923, loss = 0.12188855\n",
      "Iteration 924, loss = 0.10315958\n",
      "Iteration 925, loss = 0.11353267\n",
      "Iteration 926, loss = 0.10557930\n",
      "Iteration 927, loss = 0.11094921\n",
      "Iteration 928, loss = 0.13547670\n",
      "Iteration 929, loss = 0.12544539\n",
      "Iteration 930, loss = 0.11522871\n",
      "Iteration 931, loss = 0.10821026\n",
      "Iteration 932, loss = 0.10882185\n",
      "Iteration 933, loss = 0.11879972\n",
      "Iteration 934, loss = 0.12630936\n",
      "Iteration 935, loss = 0.12437792\n",
      "Iteration 936, loss = 0.11217374\n",
      "Iteration 937, loss = 0.11869451\n",
      "Iteration 938, loss = 0.10955639\n",
      "Iteration 939, loss = 0.11193356\n",
      "Iteration 940, loss = 0.12803921\n",
      "Iteration 941, loss = 0.15564533\n",
      "Iteration 942, loss = 0.13118523\n",
      "Iteration 943, loss = 0.22275793\n",
      "Iteration 944, loss = 0.13750737\n",
      "Iteration 945, loss = 0.16075804\n",
      "Iteration 946, loss = 0.12288557\n",
      "Iteration 947, loss = 0.11319644\n",
      "Iteration 948, loss = 0.12892959\n",
      "Iteration 949, loss = 0.12434483\n",
      "Iteration 950, loss = 0.14015548\n",
      "Iteration 951, loss = 0.11573843\n",
      "Iteration 952, loss = 0.10889409\n",
      "Iteration 953, loss = 0.11465615\n",
      "Iteration 954, loss = 0.10620440\n",
      "Iteration 955, loss = 0.12136324\n",
      "Iteration 956, loss = 0.11106469\n",
      "Iteration 957, loss = 0.10853536\n",
      "Iteration 958, loss = 0.10728389\n",
      "Iteration 959, loss = 0.10900258\n",
      "Iteration 960, loss = 0.11829908\n",
      "Iteration 961, loss = 0.11241815\n",
      "Iteration 962, loss = 0.10512279\n",
      "Iteration 963, loss = 0.11000136\n",
      "Iteration 964, loss = 0.10390941\n",
      "Iteration 965, loss = 0.10930035\n",
      "Iteration 966, loss = 0.11269604\n",
      "Iteration 967, loss = 0.10637999\n",
      "Iteration 968, loss = 0.12625102\n",
      "Iteration 969, loss = 0.13242383\n",
      "Iteration 970, loss = 0.12596502\n",
      "Iteration 971, loss = 0.15990250\n",
      "Iteration 972, loss = 0.12151671\n",
      "Iteration 973, loss = 0.11096672\n",
      "Iteration 974, loss = 0.11155895\n",
      "Iteration 975, loss = 0.11153144\n",
      "Iteration 976, loss = 0.10514353\n",
      "Iteration 977, loss = 0.10596649\n",
      "Iteration 978, loss = 0.10626940\n",
      "Iteration 979, loss = 0.11873570\n",
      "Iteration 980, loss = 0.11757249\n",
      "Iteration 981, loss = 0.16439339\n",
      "Iteration 982, loss = 0.11959196\n",
      "Iteration 983, loss = 0.10908272\n",
      "Iteration 984, loss = 0.13083195\n",
      "Iteration 985, loss = 0.14512065\n",
      "Iteration 986, loss = 0.16206557\n",
      "Iteration 987, loss = 0.12242712\n",
      "Iteration 988, loss = 0.10525401\n",
      "Iteration 989, loss = 0.10944324\n",
      "Iteration 990, loss = 0.11483109\n",
      "Iteration 991, loss = 0.11045116\n",
      "Iteration 992, loss = 0.11374296\n",
      "Iteration 993, loss = 0.11415230\n",
      "Iteration 994, loss = 0.10523641\n",
      "Iteration 995, loss = 0.13465545\n",
      "Iteration 996, loss = 0.14704653\n",
      "Iteration 997, loss = 0.19080955\n",
      "Iteration 998, loss = 0.19343576\n",
      "Iteration 999, loss = 0.29700246\n",
      "Iteration 1000, loss = 0.17470203\n",
      "Iteration 1001, loss = 0.31413677\n",
      "Iteration 1002, loss = 0.28602498\n",
      "Iteration 1003, loss = 0.49696269\n",
      "Iteration 1004, loss = 0.57164175\n",
      "Iteration 1005, loss = 0.50516720\n",
      "Iteration 1006, loss = 0.37335938\n",
      "Iteration 1007, loss = 0.27255133\n",
      "Iteration 1008, loss = 0.51979183\n",
      "Iteration 1009, loss = 0.48775827\n",
      "Iteration 1010, loss = 0.47201897\n",
      "Iteration 1011, loss = 0.36297890\n",
      "Iteration 1012, loss = 0.20314984\n",
      "Iteration 1013, loss = 0.20079595\n",
      "Iteration 1014, loss = 0.13976136\n",
      "Iteration 1015, loss = 0.11824993\n",
      "Iteration 1016, loss = 0.14522219\n",
      "Iteration 1017, loss = 0.17935711\n",
      "Iteration 1018, loss = 0.15839515\n",
      "Iteration 1019, loss = 0.15948458\n",
      "Iteration 1020, loss = 0.11684477\n",
      "Iteration 1021, loss = 0.12665394\n",
      "Iteration 1022, loss = 0.11874819\n",
      "Iteration 1023, loss = 0.11321116\n",
      "Iteration 1024, loss = 0.10688855\n",
      "Iteration 1025, loss = 0.11153995\n",
      "Iteration 1026, loss = 0.10620199\n",
      "Iteration 1027, loss = 0.10685407\n",
      "Iteration 1028, loss = 0.11101093\n",
      "Iteration 1029, loss = 0.10217777\n",
      "Iteration 1030, loss = 0.11020140\n",
      "Iteration 1031, loss = 0.11401632\n",
      "Iteration 1032, loss = 0.11706785\n",
      "Iteration 1033, loss = 0.11920383\n",
      "Iteration 1034, loss = 0.12626243\n",
      "Iteration 1035, loss = 0.12313486\n",
      "Iteration 1036, loss = 0.12586378\n",
      "Iteration 1037, loss = 0.10442314\n",
      "Iteration 1038, loss = 0.11741321\n",
      "Iteration 1039, loss = 0.12072868\n",
      "Iteration 1040, loss = 0.12968311\n",
      "Iteration 1041, loss = 0.13192997\n",
      "Iteration 1042, loss = 0.11682471\n",
      "Iteration 1043, loss = 0.12575386\n",
      "Iteration 1044, loss = 0.10972610\n",
      "Iteration 1045, loss = 0.10893769\n",
      "Iteration 1046, loss = 0.10673155\n",
      "Iteration 1047, loss = 0.11911976\n",
      "Iteration 1048, loss = 0.10789603\n",
      "Iteration 1049, loss = 0.11078826\n",
      "Iteration 1050, loss = 0.10941830\n",
      "Iteration 1051, loss = 0.11006908\n",
      "Iteration 1052, loss = 0.11844602\n",
      "Iteration 1053, loss = 0.11057424\n",
      "Iteration 1054, loss = 0.12986871\n",
      "Iteration 1055, loss = 0.11212218\n",
      "Iteration 1056, loss = 0.13742019\n",
      "Iteration 1057, loss = 0.12538075\n",
      "Iteration 1058, loss = 0.11898236\n",
      "Iteration 1059, loss = 0.12720660\n",
      "Iteration 1060, loss = 0.12202914\n",
      "Iteration 1061, loss = 0.12367183\n",
      "Iteration 1062, loss = 0.13013828\n",
      "Iteration 1063, loss = 0.11471601\n",
      "Iteration 1064, loss = 0.11317486\n",
      "Iteration 1065, loss = 0.13885198\n",
      "Iteration 1066, loss = 0.21049876\n",
      "Iteration 1067, loss = 0.12876744\n",
      "Iteration 1068, loss = 0.14791875\n",
      "Iteration 1069, loss = 0.11220068\n",
      "Iteration 1070, loss = 0.11784233\n",
      "Iteration 1071, loss = 0.11409303\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1072, loss = 0.12365789\n",
      "Iteration 1073, loss = 0.10552417\n",
      "Iteration 1074, loss = 0.11403644\n",
      "Iteration 1075, loss = 0.10829532\n",
      "Iteration 1076, loss = 0.13174736\n",
      "Iteration 1077, loss = 0.12898050\n",
      "Iteration 1078, loss = 0.11844369\n",
      "Iteration 1079, loss = 0.11005382\n",
      "Iteration 1080, loss = 0.12285651\n",
      "Iteration 1081, loss = 0.10932746\n",
      "Iteration 1082, loss = 0.10703898\n",
      "Iteration 1083, loss = 0.11027031\n",
      "Iteration 1084, loss = 0.12070389\n",
      "Iteration 1085, loss = 0.13143581\n",
      "Iteration 1086, loss = 0.14733676\n",
      "Iteration 1087, loss = 0.11117453\n",
      "Iteration 1088, loss = 0.10546008\n",
      "Iteration 1089, loss = 0.10534885\n",
      "Iteration 1090, loss = 0.10606847\n",
      "Iteration 1091, loss = 0.11019879\n",
      "Iteration 1092, loss = 0.10708986\n",
      "Iteration 1093, loss = 0.12141562\n",
      "Iteration 1094, loss = 0.12159016\n",
      "Iteration 1095, loss = 0.11472774\n",
      "Iteration 1096, loss = 0.10456490\n",
      "Iteration 1097, loss = 0.12492044\n",
      "Iteration 1098, loss = 0.10934932\n",
      "Iteration 1099, loss = 0.11092032\n",
      "Iteration 1100, loss = 0.14583498\n",
      "Iteration 1101, loss = 0.10641001\n",
      "Iteration 1102, loss = 0.14262399\n",
      "Iteration 1103, loss = 0.12867062\n",
      "Iteration 1104, loss = 0.15305336\n",
      "Iteration 1105, loss = 0.12278883\n",
      "Iteration 1106, loss = 0.15727904\n",
      "Iteration 1107, loss = 0.13472523\n",
      "Iteration 1108, loss = 0.11470695\n",
      "Iteration 1109, loss = 0.11263711\n",
      "Iteration 1110, loss = 0.10233642\n",
      "Iteration 1111, loss = 0.10874812\n",
      "Iteration 1112, loss = 0.11137467\n",
      "Iteration 1113, loss = 0.10620420\n",
      "Iteration 1114, loss = 0.13076661\n",
      "Iteration 1115, loss = 0.11518040\n",
      "Iteration 1116, loss = 0.10634049\n",
      "Iteration 1117, loss = 0.11267838\n",
      "Iteration 1118, loss = 0.12231859\n",
      "Iteration 1119, loss = 0.12005803\n",
      "Iteration 1120, loss = 0.13051473\n",
      "Iteration 1121, loss = 0.19461788\n",
      "Iteration 1122, loss = 0.17410939\n",
      "Iteration 1123, loss = 0.14479184\n",
      "Iteration 1124, loss = 0.13023859\n",
      "Iteration 1125, loss = 0.15912760\n",
      "Iteration 1126, loss = 0.11665503\n",
      "Iteration 1127, loss = 0.11855522\n",
      "Iteration 1128, loss = 0.10288864\n",
      "Iteration 1129, loss = 0.11398011\n",
      "Iteration 1130, loss = 0.12282661\n",
      "Iteration 1131, loss = 0.11097717\n",
      "Iteration 1132, loss = 0.11984747\n",
      "Iteration 1133, loss = 0.11346739\n",
      "Iteration 1134, loss = 0.11804756\n",
      "Iteration 1135, loss = 0.10957682\n",
      "Iteration 1136, loss = 0.11039279\n",
      "Iteration 1137, loss = 0.10739106\n",
      "Iteration 1138, loss = 0.10582219\n",
      "Iteration 1139, loss = 0.11021269\n",
      "Iteration 1140, loss = 0.11323962\n",
      "Iteration 1141, loss = 0.11166695\n",
      "Iteration 1142, loss = 0.10564534\n",
      "Iteration 1143, loss = 0.13354298\n",
      "Iteration 1144, loss = 0.11533388\n",
      "Iteration 1145, loss = 0.11238146\n",
      "Iteration 1146, loss = 0.10729846\n",
      "Iteration 1147, loss = 0.14951422\n",
      "Iteration 1148, loss = 0.14158085\n",
      "Iteration 1149, loss = 0.14181679\n",
      "Iteration 1150, loss = 0.15772111\n",
      "Iteration 1151, loss = 0.12104895\n",
      "Iteration 1152, loss = 0.18311171\n",
      "Iteration 1153, loss = 0.14749468\n",
      "Iteration 1154, loss = 0.12114230\n",
      "Iteration 1155, loss = 0.12463727\n",
      "Iteration 1156, loss = 0.13941845\n",
      "Iteration 1157, loss = 0.19333509\n",
      "Iteration 1158, loss = 0.19059256\n",
      "Iteration 1159, loss = 0.21251150\n",
      "Iteration 1160, loss = 0.21798351\n",
      "Iteration 1161, loss = 0.32369671\n",
      "Iteration 1162, loss = 0.20156591\n",
      "Iteration 1163, loss = 0.13124271\n",
      "Iteration 1164, loss = 0.12804629\n",
      "Iteration 1165, loss = 0.14268873\n",
      "Iteration 1166, loss = 0.11325165\n",
      "Iteration 1167, loss = 0.11442426\n",
      "Iteration 1168, loss = 0.11235184\n",
      "Iteration 1169, loss = 0.13218127\n",
      "Iteration 1170, loss = 0.12317669\n",
      "Iteration 1171, loss = 0.16985692\n",
      "Iteration 1172, loss = 0.10931518\n",
      "Iteration 1173, loss = 0.10830935\n",
      "Iteration 1174, loss = 0.10921751\n",
      "Iteration 1175, loss = 0.12277450\n",
      "Iteration 1176, loss = 0.10612915\n",
      "Iteration 1177, loss = 0.10705718\n",
      "Iteration 1178, loss = 0.11441715\n",
      "Iteration 1179, loss = 0.10721444\n",
      "Iteration 1180, loss = 0.11619913\n",
      "Iteration 1181, loss = 0.12994036\n",
      "Iteration 1182, loss = 0.11267099\n",
      "Iteration 1183, loss = 0.10698048\n",
      "Iteration 1184, loss = 0.11802744\n",
      "Iteration 1185, loss = 0.11592849\n",
      "Iteration 1186, loss = 0.11242565\n",
      "Iteration 1187, loss = 0.10314138\n",
      "Iteration 1188, loss = 0.10980477\n",
      "Iteration 1189, loss = 0.11100890\n",
      "Iteration 1190, loss = 0.10691523\n",
      "Iteration 1191, loss = 0.10878413\n",
      "Iteration 1192, loss = 0.13822258\n",
      "Iteration 1193, loss = 0.11240550\n",
      "Iteration 1194, loss = 0.13658045\n",
      "Iteration 1195, loss = 0.13341774\n",
      "Iteration 1196, loss = 0.12598653\n",
      "Iteration 1197, loss = 0.15816232\n",
      "Iteration 1198, loss = 0.13837851\n",
      "Iteration 1199, loss = 0.14662647\n",
      "Iteration 1200, loss = 0.12451295\n",
      "Iteration 1201, loss = 0.11545289\n",
      "Iteration 1202, loss = 0.10365346\n",
      "Iteration 1203, loss = 0.11429520\n",
      "Iteration 1204, loss = 0.10415517\n",
      "Iteration 1205, loss = 0.10920172\n",
      "Iteration 1206, loss = 0.10982930\n",
      "Iteration 1207, loss = 0.10261652\n",
      "Iteration 1208, loss = 0.10735124\n",
      "Iteration 1209, loss = 0.10564810\n",
      "Iteration 1210, loss = 0.11198408\n",
      "Iteration 1211, loss = 0.10977725\n",
      "Iteration 1212, loss = 0.10671805\n",
      "Iteration 1213, loss = 0.11236651\n",
      "Iteration 1214, loss = 0.11404218\n",
      "Iteration 1215, loss = 0.11501293\n",
      "Iteration 1216, loss = 0.12623515\n",
      "Iteration 1217, loss = 0.10325912\n",
      "Iteration 1218, loss = 0.10754951\n",
      "Iteration 1219, loss = 0.10607312\n",
      "Iteration 1220, loss = 0.10416738\n",
      "Iteration 1221, loss = 0.10581149\n",
      "Iteration 1222, loss = 0.10595480\n",
      "Iteration 1223, loss = 0.10351188\n",
      "Iteration 1224, loss = 0.10501581\n",
      "Iteration 1225, loss = 0.10943092\n",
      "Iteration 1226, loss = 0.11929179\n",
      "Iteration 1227, loss = 0.10592653\n",
      "Iteration 1228, loss = 0.11971029\n",
      "Iteration 1229, loss = 0.12273033\n",
      "Iteration 1230, loss = 0.12028544\n",
      "Iteration 1231, loss = 0.10938401\n",
      "Iteration 1232, loss = 0.10778874\n",
      "Iteration 1233, loss = 0.11427597\n",
      "Iteration 1234, loss = 0.11698605\n",
      "Iteration 1235, loss = 0.13085938\n",
      "Iteration 1236, loss = 0.26676358\n",
      "Iteration 1237, loss = 0.88563577\n",
      "Iteration 1238, loss = 0.96921468\n",
      "Iteration 1239, loss = 2.19830984\n",
      "Iteration 1240, loss = 4.88480853\n",
      "Iteration 1241, loss = 2.60479621\n",
      "Iteration 1242, loss = 2.00748172\n",
      "Iteration 1243, loss = 2.01715560\n",
      "Iteration 1244, loss = 1.96629104\n",
      "Iteration 1245, loss = 1.06985612\n",
      "Iteration 1246, loss = 1.15867472\n",
      "Iteration 1247, loss = 0.71455655\n",
      "Iteration 1248, loss = 0.94532609\n",
      "Iteration 1249, loss = 0.69599888\n",
      "Iteration 1250, loss = 0.39479997\n",
      "Iteration 1251, loss = 0.34032843\n",
      "Iteration 1252, loss = 0.48684710\n",
      "Iteration 1253, loss = 0.59897853\n",
      "Iteration 1254, loss = 0.63169709\n",
      "Iteration 1255, loss = 0.68158849\n",
      "Iteration 1256, loss = 0.55959390\n",
      "Iteration 1257, loss = 0.47551709\n",
      "Iteration 1258, loss = 0.31926835\n",
      "Iteration 1259, loss = 0.27957574\n",
      "Iteration 1260, loss = 0.23291766\n",
      "Iteration 1261, loss = 0.35655329\n",
      "Iteration 1262, loss = 0.23984111\n",
      "Iteration 1263, loss = 0.29276280\n",
      "Iteration 1264, loss = 0.28847132\n",
      "Iteration 1265, loss = 0.31021033\n",
      "Iteration 1266, loss = 0.22943401\n",
      "Iteration 1267, loss = 0.24893766\n",
      "Iteration 1268, loss = 0.21078037\n",
      "Iteration 1269, loss = 0.42712579\n",
      "Iteration 1270, loss = 0.35741651\n",
      "Iteration 1271, loss = 0.39748357\n",
      "Iteration 1272, loss = 0.39503994\n",
      "Iteration 1273, loss = 0.25636213\n",
      "Iteration 1274, loss = 0.15434316\n",
      "Iteration 1275, loss = 0.16244049\n",
      "Iteration 1276, loss = 0.17868357\n",
      "Iteration 1277, loss = 0.16952628\n",
      "Iteration 1278, loss = 0.69570427\n",
      "Iteration 1279, loss = 0.62476818\n",
      "Iteration 1280, loss = 0.42479266\n",
      "Iteration 1281, loss = 0.31649086\n",
      "Iteration 1282, loss = 0.22088679\n",
      "Iteration 1283, loss = 0.20803979\n",
      "Iteration 1284, loss = 0.15233980\n",
      "Iteration 1285, loss = 0.14106321\n",
      "Iteration 1286, loss = 0.24383666\n",
      "Iteration 1287, loss = 0.14144651\n",
      "Iteration 1288, loss = 0.14342296\n",
      "Iteration 1289, loss = 0.20721229\n",
      "Iteration 1290, loss = 0.21197503\n",
      "Iteration 1291, loss = 0.14112714\n",
      "Iteration 1292, loss = 0.14924294\n",
      "Iteration 1293, loss = 0.12632044\n",
      "Iteration 1294, loss = 0.11880052\n",
      "Iteration 1295, loss = 0.13395449\n",
      "Iteration 1296, loss = 0.13695078\n",
      "Iteration 1297, loss = 0.11672858\n",
      "Iteration 1298, loss = 0.14133732\n",
      "Iteration 1299, loss = 0.13618980\n",
      "Iteration 1300, loss = 0.18814980\n",
      "Iteration 1301, loss = 0.14488780\n",
      "Iteration 1302, loss = 0.23243231\n",
      "Iteration 1303, loss = 0.19700376\n",
      "Iteration 1304, loss = 0.47363984\n",
      "Iteration 1305, loss = 0.37571639\n",
      "Iteration 1306, loss = 0.31598817\n",
      "Iteration 1307, loss = 0.62972757\n",
      "Iteration 1308, loss = 0.92267110\n",
      "Iteration 1309, loss = 0.81828880\n",
      "Iteration 1310, loss = 0.75250012\n",
      "Iteration 1311, loss = 0.63964766\n",
      "Iteration 1312, loss = 0.58638316\n",
      "Iteration 1313, loss = 0.21221367\n",
      "Iteration 1314, loss = 0.30527446\n",
      "Iteration 1315, loss = 0.19178337\n",
      "Iteration 1316, loss = 0.23658705\n",
      "Iteration 1317, loss = 0.26879319\n",
      "Iteration 1318, loss = 0.25180197\n",
      "Iteration 1319, loss = 0.13234811\n",
      "Iteration 1320, loss = 0.31021253\n",
      "Iteration 1321, loss = 0.19139899\n",
      "Iteration 1322, loss = 0.36295344\n",
      "Iteration 1323, loss = 0.32247089\n",
      "Iteration 1324, loss = 0.22574609\n",
      "Iteration 1325, loss = 0.24904553\n",
      "Iteration 1326, loss = 0.14348290\n",
      "Iteration 1327, loss = 0.14982519\n",
      "Iteration 1328, loss = 0.15989136\n",
      "Iteration 1329, loss = 0.12111475\n",
      "Iteration 1330, loss = 0.11370954\n",
      "Iteration 1331, loss = 0.12759003\n",
      "Iteration 1332, loss = 0.10788308\n",
      "Iteration 1333, loss = 0.11305925\n",
      "Iteration 1334, loss = 0.10293240\n",
      "Iteration 1335, loss = 0.10429635\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1336, loss = 0.10816572\n",
      "Iteration 1337, loss = 0.11529101\n",
      "Iteration 1338, loss = 0.11746003\n",
      "Iteration 1339, loss = 0.11349917\n",
      "Iteration 1340, loss = 0.11221894\n",
      "Iteration 1341, loss = 0.11143892\n",
      "Iteration 1342, loss = 0.14466117\n",
      "Iteration 1343, loss = 0.13508421\n",
      "Iteration 1344, loss = 0.13186482\n",
      "Iteration 1345, loss = 0.10909536\n",
      "Iteration 1346, loss = 0.11221020\n",
      "Iteration 1347, loss = 0.12456294\n",
      "Iteration 1348, loss = 0.11562988\n",
      "Iteration 1349, loss = 0.13394862\n",
      "Iteration 1350, loss = 0.13536536\n",
      "Iteration 1351, loss = 0.11246174\n",
      "Iteration 1352, loss = 0.10767297\n",
      "Iteration 1353, loss = 0.11824901\n",
      "Iteration 1354, loss = 0.11131991\n",
      "Iteration 1355, loss = 0.10665508\n",
      "Iteration 1356, loss = 0.11248559\n",
      "Iteration 1357, loss = 0.12811062\n",
      "Iteration 1358, loss = 0.11287747\n",
      "Iteration 1359, loss = 0.10793115\n",
      "Iteration 1360, loss = 0.12693384\n",
      "Iteration 1361, loss = 0.12571880\n",
      "Iteration 1362, loss = 0.10801928\n",
      "Iteration 1363, loss = 0.11051150\n",
      "Iteration 1364, loss = 0.11867016\n",
      "Iteration 1365, loss = 0.10330761\n",
      "Iteration 1366, loss = 0.10822149\n",
      "Iteration 1367, loss = 0.10964048\n",
      "Iteration 1368, loss = 0.12357330\n",
      "Iteration 1369, loss = 0.11947789\n",
      "Iteration 1370, loss = 0.19806229\n",
      "Iteration 1371, loss = 0.20218064\n",
      "Iteration 1372, loss = 0.13329860\n",
      "Iteration 1373, loss = 0.17905337\n",
      "Iteration 1374, loss = 0.21205696\n",
      "Iteration 1375, loss = 0.16155867\n",
      "Iteration 1376, loss = 0.12037706\n",
      "Iteration 1377, loss = 0.14104714\n",
      "Iteration 1378, loss = 0.17635709\n",
      "Iteration 1379, loss = 0.12295496\n",
      "Iteration 1380, loss = 0.10589806\n",
      "Iteration 1381, loss = 0.12275756\n",
      "Iteration 1382, loss = 0.14468832\n",
      "Iteration 1383, loss = 0.12985355\n",
      "Iteration 1384, loss = 0.14290970\n",
      "Iteration 1385, loss = 0.12653415\n",
      "Iteration 1386, loss = 0.11046422\n",
      "Iteration 1387, loss = 0.10807839\n",
      "Iteration 1388, loss = 0.10730031\n",
      "Iteration 1389, loss = 0.10973402\n",
      "Iteration 1390, loss = 0.10982927\n",
      "Iteration 1391, loss = 0.11615038\n",
      "Iteration 1392, loss = 0.11463034\n",
      "Iteration 1393, loss = 0.13397010\n",
      "Iteration 1394, loss = 0.11989471\n",
      "Iteration 1395, loss = 0.11437508\n",
      "Iteration 1396, loss = 0.12576483\n",
      "Iteration 1397, loss = 0.12553051\n",
      "Iteration 1398, loss = 0.11742456\n",
      "Iteration 1399, loss = 0.11133510\n",
      "Iteration 1400, loss = 0.10603949\n",
      "Iteration 1401, loss = 0.10946758\n",
      "Iteration 1402, loss = 0.11381593\n",
      "Iteration 1403, loss = 0.11067359\n",
      "Iteration 1404, loss = 0.11410392\n",
      "Iteration 1405, loss = 0.11336369\n",
      "Iteration 1406, loss = 0.11891477\n",
      "Iteration 1407, loss = 0.17272331\n",
      "Iteration 1408, loss = 0.16116723\n",
      "Iteration 1409, loss = 0.23581960\n",
      "Iteration 1410, loss = 0.21501583\n",
      "Iteration 1411, loss = 0.30572115\n",
      "Iteration 1412, loss = 0.18531743\n",
      "Iteration 1413, loss = 0.20938901\n",
      "Iteration 1414, loss = 0.13945559\n",
      "Iteration 1415, loss = 0.15584319\n",
      "Iteration 1416, loss = 0.14080145\n",
      "Iteration 1417, loss = 0.11127592\n",
      "Iteration 1418, loss = 0.12324123\n",
      "Iteration 1419, loss = 0.11965673\n",
      "Iteration 1420, loss = 0.14212069\n",
      "Iteration 1421, loss = 0.17301659\n",
      "Iteration 1422, loss = 0.11937170\n",
      "Iteration 1423, loss = 0.11483981\n",
      "Iteration 1424, loss = 0.10945114\n",
      "Iteration 1425, loss = 0.10379400\n",
      "Iteration 1426, loss = 0.10387146\n",
      "Iteration 1427, loss = 0.10599915\n",
      "Iteration 1428, loss = 0.11224987\n",
      "Iteration 1429, loss = 0.11451413\n",
      "Iteration 1430, loss = 0.11244838\n",
      "Iteration 1431, loss = 0.11519844\n",
      "Iteration 1432, loss = 0.12050162\n",
      "Iteration 1433, loss = 0.10578511\n",
      "Iteration 1434, loss = 0.10860470\n",
      "Iteration 1435, loss = 0.16457286\n",
      "Iteration 1436, loss = 0.14077199\n",
      "Iteration 1437, loss = 0.34642540\n",
      "Iteration 1438, loss = 0.34361674\n",
      "Iteration 1439, loss = 0.22356426\n",
      "Iteration 1440, loss = 0.32876454\n",
      "Iteration 1441, loss = 0.21573578\n",
      "Iteration 1442, loss = 0.13501564\n",
      "Iteration 1443, loss = 0.11169679\n",
      "Iteration 1444, loss = 0.13044666\n",
      "Iteration 1445, loss = 0.11767397\n",
      "Iteration 1446, loss = 0.11934078\n",
      "Iteration 1447, loss = 0.12223052\n",
      "Iteration 1448, loss = 0.11430462\n",
      "Iteration 1449, loss = 0.11264385\n",
      "Iteration 1450, loss = 0.10486552\n",
      "Iteration 1451, loss = 0.11821739\n",
      "Iteration 1452, loss = 0.13539054\n",
      "Iteration 1453, loss = 0.25035157\n",
      "Iteration 1454, loss = 0.15449575\n",
      "Iteration 1455, loss = 0.24863877\n",
      "Iteration 1456, loss = 0.20585850\n",
      "Iteration 1457, loss = 0.46967175\n",
      "Iteration 1458, loss = 0.57815755\n",
      "Iteration 1459, loss = 0.26611313\n",
      "Iteration 1460, loss = 0.20204140\n",
      "Iteration 1461, loss = 0.15887188\n",
      "Iteration 1462, loss = 0.11517426\n",
      "Iteration 1463, loss = 0.11483055\n",
      "Iteration 1464, loss = 0.11227849\n",
      "Iteration 1465, loss = 0.15573208\n",
      "Iteration 1466, loss = 0.15370782\n",
      "Iteration 1467, loss = 0.13542390\n",
      "Iteration 1468, loss = 0.12155283\n",
      "Iteration 1469, loss = 0.10494864\n",
      "Iteration 1470, loss = 0.10636731\n",
      "Iteration 1471, loss = 0.10866636\n",
      "Iteration 1472, loss = 0.11068392\n",
      "Iteration 1473, loss = 0.10855092\n",
      "Iteration 1474, loss = 0.10803373\n",
      "Iteration 1475, loss = 0.10694773\n",
      "Iteration 1476, loss = 0.11319558\n",
      "Iteration 1477, loss = 0.11655759\n",
      "Iteration 1478, loss = 0.11074198\n",
      "Iteration 1479, loss = 0.13242858\n",
      "Iteration 1480, loss = 0.10990476\n",
      "Iteration 1481, loss = 0.10324092\n",
      "Iteration 1482, loss = 0.10972767\n",
      "Iteration 1483, loss = 0.10420751\n",
      "Iteration 1484, loss = 0.10571472\n",
      "Iteration 1485, loss = 0.10771524\n",
      "Iteration 1486, loss = 0.12240751\n",
      "Iteration 1487, loss = 0.11173114\n",
      "Iteration 1488, loss = 0.11074275\n",
      "Iteration 1489, loss = 0.12385475\n",
      "Iteration 1490, loss = 0.15197898\n",
      "Iteration 1491, loss = 0.17084740\n",
      "Iteration 1492, loss = 0.28235591\n",
      "Iteration 1493, loss = 0.46047183\n",
      "Iteration 1494, loss = 0.40986687\n",
      "Iteration 1495, loss = 0.24170178\n",
      "Iteration 1496, loss = 0.50906405\n",
      "Iteration 1497, loss = 0.98563638\n",
      "Iteration 1498, loss = 0.55458345\n",
      "Iteration 1499, loss = 0.87219473\n",
      "Iteration 1500, loss = 0.42715299\n",
      "Iteration 1501, loss = 0.18479256\n",
      "Iteration 1502, loss = 0.16102939\n",
      "Iteration 1503, loss = 0.13002917\n",
      "Iteration 1504, loss = 0.17591305\n",
      "Iteration 1505, loss = 0.12102321\n",
      "Iteration 1506, loss = 0.12532188\n",
      "Iteration 1507, loss = 0.12926129\n",
      "Iteration 1508, loss = 0.12285529\n",
      "Iteration 1509, loss = 0.11521631\n",
      "Iteration 1510, loss = 0.10652936\n",
      "Iteration 1511, loss = 0.10221023\n",
      "Iteration 1512, loss = 0.11637656\n",
      "Iteration 1513, loss = 0.10369115\n",
      "Iteration 1514, loss = 0.11331469\n",
      "Iteration 1515, loss = 0.10944411\n",
      "Iteration 1516, loss = 0.12669751\n",
      "Iteration 1517, loss = 0.12357494\n",
      "Iteration 1518, loss = 0.11399568\n",
      "Iteration 1519, loss = 0.12587207\n",
      "Iteration 1520, loss = 0.11962850\n",
      "Iteration 1521, loss = 0.10459278\n",
      "Iteration 1522, loss = 0.10494042\n",
      "Iteration 1523, loss = 0.11006423\n",
      "Iteration 1524, loss = 0.10294088\n",
      "Iteration 1525, loss = 0.11005858\n",
      "Iteration 1526, loss = 0.11089867\n",
      "Iteration 1527, loss = 0.11393147\n",
      "Iteration 1528, loss = 0.10746481\n",
      "Iteration 1529, loss = 0.10737029\n",
      "Iteration 1530, loss = 0.11043153\n",
      "Iteration 1531, loss = 0.11230891\n",
      "Iteration 1532, loss = 0.12352356\n",
      "Iteration 1533, loss = 0.13538173\n",
      "Iteration 1534, loss = 0.11954353\n",
      "Iteration 1535, loss = 0.13380073\n",
      "Iteration 1536, loss = 0.10625274\n",
      "Iteration 1537, loss = 0.11872087\n",
      "Iteration 1538, loss = 0.13587085\n",
      "Iteration 1539, loss = 0.11065446\n",
      "Iteration 1540, loss = 0.11574556\n",
      "Iteration 1541, loss = 0.11206355\n",
      "Iteration 1542, loss = 0.10663048\n",
      "Iteration 1543, loss = 0.10612979\n",
      "Iteration 1544, loss = 0.11122821\n",
      "Iteration 1545, loss = 0.11459652\n",
      "Iteration 1546, loss = 0.12765068\n",
      "Iteration 1547, loss = 0.16725859\n",
      "Iteration 1548, loss = 0.11052099\n",
      "Iteration 1549, loss = 0.10987135\n",
      "Iteration 1550, loss = 0.11177883\n",
      "Iteration 1551, loss = 0.11092416\n",
      "Iteration 1552, loss = 0.10774959\n",
      "Iteration 1553, loss = 0.10510633\n",
      "Iteration 1554, loss = 0.10520401\n",
      "Iteration 1555, loss = 0.11945152\n",
      "Iteration 1556, loss = 0.13513151\n",
      "Iteration 1557, loss = 0.12205894\n",
      "Iteration 1558, loss = 0.12036568\n",
      "Iteration 1559, loss = 0.10876083\n",
      "Iteration 1560, loss = 0.11714580\n",
      "Iteration 1561, loss = 0.11892629\n",
      "Iteration 1562, loss = 0.12607371\n",
      "Iteration 1563, loss = 0.11560672\n",
      "Iteration 1564, loss = 0.11069062\n",
      "Iteration 1565, loss = 0.11523609\n",
      "Iteration 1566, loss = 0.10610542\n",
      "Iteration 1567, loss = 0.10401510\n",
      "Iteration 1568, loss = 0.12189927\n",
      "Iteration 1569, loss = 0.12100097\n",
      "Iteration 1570, loss = 0.11049423\n",
      "Iteration 1571, loss = 0.10302252\n",
      "Iteration 1572, loss = 0.11264321\n",
      "Iteration 1573, loss = 0.10625023\n",
      "Iteration 1574, loss = 0.10393822\n",
      "Iteration 1575, loss = 0.10363846\n",
      "Iteration 1576, loss = 0.11853937\n",
      "Iteration 1577, loss = 0.12057879\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1578, loss = 0.10894176\n",
      "Iteration 1579, loss = 0.23264390\n",
      "Iteration 1580, loss = 0.17838613\n",
      "Iteration 1581, loss = 0.36429762\n",
      "Iteration 1582, loss = 0.31273089\n",
      "Iteration 1583, loss = 0.33359385\n",
      "Iteration 1584, loss = 0.43795972\n",
      "Iteration 1585, loss = 0.38985077\n",
      "Iteration 1586, loss = 0.15902793\n",
      "Iteration 1587, loss = 0.12912717\n",
      "Iteration 1588, loss = 0.12619521\n",
      "Iteration 1589, loss = 0.12245661\n",
      "Iteration 1590, loss = 0.11795682\n",
      "Iteration 1591, loss = 0.13140461\n",
      "Iteration 1592, loss = 0.14195246\n",
      "Iteration 1593, loss = 0.12543035\n",
      "Iteration 1594, loss = 0.11034464\n",
      "Iteration 1595, loss = 0.12118392\n",
      "Iteration 1596, loss = 0.12208238\n",
      "Iteration 1597, loss = 0.11110180\n",
      "Iteration 1598, loss = 0.10547350\n",
      "Iteration 1599, loss = 0.10819032\n",
      "Iteration 1600, loss = 0.11074133\n",
      "Iteration 1601, loss = 0.11214120\n",
      "Iteration 1602, loss = 0.10826927\n",
      "Iteration 1603, loss = 0.10580239\n",
      "Iteration 1604, loss = 0.10652695\n",
      "Iteration 1605, loss = 0.12190522\n",
      "Iteration 1606, loss = 0.10676872\n",
      "Iteration 1607, loss = 0.10752812\n",
      "Iteration 1608, loss = 0.11774195\n",
      "Iteration 1609, loss = 0.13345285\n",
      "Iteration 1610, loss = 0.10736010\n",
      "Iteration 1611, loss = 0.10496011\n",
      "Iteration 1612, loss = 0.10527701\n",
      "Iteration 1613, loss = 0.11439376\n",
      "Iteration 1614, loss = 0.10925413\n",
      "Iteration 1615, loss = 0.10570610\n",
      "Iteration 1616, loss = 0.10566154\n",
      "Iteration 1617, loss = 0.10755083\n",
      "Iteration 1618, loss = 0.11274865\n",
      "Iteration 1619, loss = 0.11882180\n",
      "Iteration 1620, loss = 0.10208618\n",
      "Iteration 1621, loss = 0.10703681\n",
      "Iteration 1622, loss = 0.10435832\n",
      "Iteration 1623, loss = 0.10465596\n",
      "Iteration 1624, loss = 0.10619647\n",
      "Iteration 1625, loss = 0.10671680\n",
      "Iteration 1626, loss = 0.10836103\n",
      "Iteration 1627, loss = 0.10299842\n",
      "Iteration 1628, loss = 0.12318426\n",
      "Iteration 1629, loss = 0.10723064\n",
      "Iteration 1630, loss = 0.10397435\n",
      "Iteration 1631, loss = 0.11540576\n",
      "Iteration 1632, loss = 0.10901209\n",
      "Iteration 1633, loss = 0.11429441\n",
      "Iteration 1634, loss = 0.10791816\n",
      "Iteration 1635, loss = 0.10680151\n",
      "Iteration 1636, loss = 0.11421492\n",
      "Iteration 1637, loss = 0.12304665\n",
      "Iteration 1638, loss = 0.11948276\n",
      "Iteration 1639, loss = 0.10476425\n",
      "Iteration 1640, loss = 0.10596126\n",
      "Iteration 1641, loss = 0.10867179\n",
      "Iteration 1642, loss = 0.11048208\n",
      "Iteration 1643, loss = 0.12325660\n",
      "Iteration 1644, loss = 0.10612749\n",
      "Iteration 1645, loss = 0.10544088\n",
      "Iteration 1646, loss = 0.10776869\n",
      "Iteration 1647, loss = 0.10996616\n",
      "Iteration 1648, loss = 0.10385953\n",
      "Iteration 1649, loss = 0.10860434\n",
      "Iteration 1650, loss = 0.10772741\n",
      "Iteration 1651, loss = 0.10493089\n",
      "Iteration 1652, loss = 0.11944836\n",
      "Iteration 1653, loss = 0.11763344\n",
      "Iteration 1654, loss = 0.11721512\n",
      "Iteration 1655, loss = 0.11785003\n",
      "Iteration 1656, loss = 0.11217109\n",
      "Iteration 1657, loss = 0.10589042\n",
      "Iteration 1658, loss = 0.10700135\n",
      "Iteration 1659, loss = 0.12064014\n",
      "Iteration 1660, loss = 0.13114498\n",
      "Iteration 1661, loss = 0.12301718\n",
      "Iteration 1662, loss = 0.11061478\n",
      "Iteration 1663, loss = 0.21024904\n",
      "Iteration 1664, loss = 0.24190675\n",
      "Iteration 1665, loss = 0.66630822\n",
      "Iteration 1666, loss = 0.59413999\n",
      "Iteration 1667, loss = 0.56740595\n",
      "Iteration 1668, loss = 0.41875504\n",
      "Iteration 1669, loss = 0.33072205\n",
      "Iteration 1670, loss = 0.52873805\n",
      "Iteration 1671, loss = 0.78721442\n",
      "Iteration 1672, loss = 0.66621553\n",
      "Iteration 1673, loss = 0.36629965\n",
      "Iteration 1674, loss = 0.18579936\n",
      "Iteration 1675, loss = 0.25409234\n",
      "Iteration 1676, loss = 0.12517973\n",
      "Iteration 1677, loss = 0.12950861\n",
      "Iteration 1678, loss = 0.10927699\n",
      "Iteration 1679, loss = 0.12226450\n",
      "Iteration 1680, loss = 0.11265387\n",
      "Iteration 1681, loss = 0.11318465\n",
      "Iteration 1682, loss = 0.10240728\n",
      "Iteration 1683, loss = 0.10811059\n",
      "Iteration 1684, loss = 0.10875215\n",
      "Iteration 1685, loss = 0.16665164\n",
      "Iteration 1686, loss = 0.12166870\n",
      "Iteration 1687, loss = 0.11074789\n",
      "Iteration 1688, loss = 0.11328212\n",
      "Iteration 1689, loss = 0.11710210\n",
      "Iteration 1690, loss = 0.10599633\n",
      "Iteration 1691, loss = 0.10725392\n",
      "Iteration 1692, loss = 0.11630858\n",
      "Iteration 1693, loss = 0.12596057\n",
      "Iteration 1694, loss = 0.12392939\n",
      "Iteration 1695, loss = 0.11028778\n",
      "Iteration 1696, loss = 0.10923086\n",
      "Iteration 1697, loss = 0.10595341\n",
      "Iteration 1698, loss = 0.10667904\n",
      "Iteration 1699, loss = 0.10436907\n",
      "Iteration 1700, loss = 0.10500519\n",
      "Iteration 1701, loss = 0.11493353\n",
      "Iteration 1702, loss = 0.10577010\n",
      "Iteration 1703, loss = 0.10560563\n",
      "Iteration 1704, loss = 0.10529381\n",
      "Iteration 1705, loss = 0.10453975\n",
      "Iteration 1706, loss = 0.10683303\n",
      "Iteration 1707, loss = 0.10874785\n",
      "Iteration 1708, loss = 0.11228527\n",
      "Iteration 1709, loss = 0.11097029\n",
      "Iteration 1710, loss = 0.11110100\n",
      "Iteration 1711, loss = 0.12804172\n",
      "Iteration 1712, loss = 0.11400639\n",
      "Iteration 1713, loss = 0.13046899\n",
      "Iteration 1714, loss = 0.11932612\n",
      "Iteration 1715, loss = 0.11928981\n",
      "Iteration 1716, loss = 0.11231455\n",
      "Iteration 1717, loss = 0.11412428\n",
      "Iteration 1718, loss = 0.10716418\n",
      "Iteration 1719, loss = 0.11310283\n",
      "Iteration 1720, loss = 0.12694701\n",
      "Iteration 1721, loss = 0.11072479\n",
      "Iteration 1722, loss = 0.10532770\n",
      "Iteration 1723, loss = 0.11000873\n",
      "Iteration 1724, loss = 0.10692899\n",
      "Iteration 1725, loss = 0.10617162\n",
      "Iteration 1726, loss = 0.10750202\n",
      "Iteration 1727, loss = 0.10415247\n",
      "Iteration 1728, loss = 0.10229157\n",
      "Iteration 1729, loss = 0.10541531\n",
      "Iteration 1730, loss = 0.10732848\n",
      "Iteration 1731, loss = 0.11492964\n",
      "Iteration 1732, loss = 0.11297274\n",
      "Iteration 1733, loss = 0.10646746\n",
      "Iteration 1734, loss = 0.10750987\n",
      "Iteration 1735, loss = 0.10709921\n",
      "Iteration 1736, loss = 0.10358205\n",
      "Iteration 1737, loss = 0.10873368\n",
      "Iteration 1738, loss = 0.10868410\n",
      "Iteration 1739, loss = 0.12569060\n",
      "Iteration 1740, loss = 0.12619736\n",
      "Iteration 1741, loss = 0.12573747\n",
      "Iteration 1742, loss = 0.13732156\n",
      "Iteration 1743, loss = 0.10814263\n",
      "Iteration 1744, loss = 0.11290462\n",
      "Iteration 1745, loss = 0.11675793\n",
      "Iteration 1746, loss = 0.11916731\n",
      "Iteration 1747, loss = 0.11076503\n",
      "Iteration 1748, loss = 0.10324454\n",
      "Iteration 1749, loss = 0.11617491\n",
      "Iteration 1750, loss = 0.11029118\n",
      "Iteration 1751, loss = 0.10721042\n",
      "Iteration 1752, loss = 0.11819596\n",
      "Iteration 1753, loss = 0.11585244\n",
      "Iteration 1754, loss = 0.10573412\n",
      "Iteration 1755, loss = 0.12387064\n",
      "Iteration 1756, loss = 0.10545293\n",
      "Iteration 1757, loss = 0.10352945\n",
      "Iteration 1758, loss = 0.10860544\n",
      "Iteration 1759, loss = 0.10382132\n",
      "Iteration 1760, loss = 0.10368409\n",
      "Iteration 1761, loss = 0.10636782\n",
      "Iteration 1762, loss = 0.12445534\n",
      "Iteration 1763, loss = 0.10722785\n",
      "Iteration 1764, loss = 0.10795454\n",
      "Iteration 1765, loss = 0.11906370\n",
      "Iteration 1766, loss = 0.10287122\n",
      "Iteration 1767, loss = 0.10712372\n",
      "Iteration 1768, loss = 0.10697237\n",
      "Iteration 1769, loss = 0.12042041\n",
      "Iteration 1770, loss = 0.11303003\n",
      "Iteration 1771, loss = 0.15221138\n",
      "Iteration 1772, loss = 0.12506003\n",
      "Iteration 1773, loss = 0.12940091\n",
      "Iteration 1774, loss = 0.14851894\n",
      "Iteration 1775, loss = 0.13836225\n",
      "Iteration 1776, loss = 0.10593348\n",
      "Iteration 1777, loss = 0.11665905\n",
      "Iteration 1778, loss = 0.11439491\n",
      "Iteration 1779, loss = 0.12474423\n",
      "Iteration 1780, loss = 0.11696776\n",
      "Iteration 1781, loss = 0.11396365\n",
      "Iteration 1782, loss = 0.15271665\n",
      "Iteration 1783, loss = 0.13697514\n",
      "Iteration 1784, loss = 0.11708155\n",
      "Iteration 1785, loss = 0.11607873\n",
      "Iteration 1786, loss = 0.11073752\n",
      "Iteration 1787, loss = 0.10650151\n",
      "Iteration 1788, loss = 0.10559509\n",
      "Iteration 1789, loss = 0.11963808\n",
      "Iteration 1790, loss = 0.12598491\n",
      "Iteration 1791, loss = 0.11657102\n",
      "Iteration 1792, loss = 0.13793283\n",
      "Iteration 1793, loss = 0.17340648\n",
      "Iteration 1794, loss = 0.21848945\n",
      "Iteration 1795, loss = 0.15677297\n",
      "Iteration 1796, loss = 0.20786933\n",
      "Iteration 1797, loss = 0.14611653\n",
      "Iteration 1798, loss = 0.13214976\n",
      "Iteration 1799, loss = 0.10937069\n",
      "Iteration 1800, loss = 0.10773494\n",
      "Iteration 1801, loss = 0.10100112\n",
      "Iteration 1802, loss = 0.10642475\n",
      "Iteration 1803, loss = 0.10685473\n",
      "Iteration 1804, loss = 0.11486689\n",
      "Iteration 1805, loss = 0.12037391\n",
      "Iteration 1806, loss = 0.11731673\n",
      "Iteration 1807, loss = 0.10310788\n",
      "Iteration 1808, loss = 0.10690307\n",
      "Iteration 1809, loss = 0.10419880\n",
      "Iteration 1810, loss = 0.11346399\n",
      "Iteration 1811, loss = 0.11182928\n",
      "Iteration 1812, loss = 0.12596307\n",
      "Iteration 1813, loss = 0.10848134\n",
      "Iteration 1814, loss = 0.10313618\n",
      "Iteration 1815, loss = 0.10571707\n",
      "Iteration 1816, loss = 0.10766278\n",
      "Iteration 1817, loss = 0.10693312\n",
      "Iteration 1818, loss = 0.10555699\n",
      "Iteration 1819, loss = 0.11866864\n",
      "Iteration 1820, loss = 0.10690597\n",
      "Iteration 1821, loss = 0.10525807\n",
      "Iteration 1822, loss = 0.16991685\n",
      "Iteration 1823, loss = 0.35434814\n",
      "Iteration 1824, loss = 0.31411063\n",
      "Iteration 1825, loss = 0.54340785\n",
      "Iteration 1826, loss = 0.89969020\n",
      "Iteration 1827, loss = 0.80475153\n",
      "Iteration 1828, loss = 0.76684243\n",
      "Iteration 1829, loss = 0.77204072\n",
      "Iteration 1830, loss = 0.89825808\n",
      "Iteration 1831, loss = 1.91216340\n",
      "Iteration 1832, loss = 1.41043782\n",
      "Iteration 1833, loss = 3.52569791\n",
      "Iteration 1834, loss = 3.40266176\n",
      "Iteration 1835, loss = 1.81221503\n",
      "Iteration 1836, loss = 1.28531697\n",
      "Iteration 1837, loss = 1.27264502\n",
      "Iteration 1838, loss = 1.28006055\n",
      "Iteration 1839, loss = 1.16265755\n",
      "Iteration 1840, loss = 0.75932148\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1841, loss = 0.94125422\n",
      "Iteration 1842, loss = 0.93668821\n",
      "Iteration 1843, loss = 0.78337924\n",
      "Iteration 1844, loss = 0.86041851\n",
      "Iteration 1845, loss = 0.67917164\n",
      "Iteration 1846, loss = 0.79980160\n",
      "Iteration 1847, loss = 0.58259651\n",
      "Iteration 1848, loss = 0.55552763\n",
      "Iteration 1849, loss = 0.44746043\n",
      "Iteration 1850, loss = 0.41683334\n",
      "Iteration 1851, loss = 1.32110823\n",
      "Iteration 1852, loss = 1.27539432\n",
      "Iteration 1853, loss = 0.92882191\n",
      "Iteration 1854, loss = 0.74908894\n",
      "Iteration 1855, loss = 1.02106297\n",
      "Iteration 1856, loss = 0.75572983\n",
      "Iteration 1857, loss = 0.68591336\n",
      "Iteration 1858, loss = 0.66171128\n",
      "Iteration 1859, loss = 0.49381988\n",
      "Iteration 1860, loss = 0.74537606\n",
      "Iteration 1861, loss = 0.56887400\n",
      "Iteration 1862, loss = 0.58590050\n",
      "Iteration 1863, loss = 0.43276313\n",
      "Iteration 1864, loss = 0.32598271\n",
      "Iteration 1865, loss = 0.21175046\n",
      "Iteration 1866, loss = 0.27834848\n",
      "Iteration 1867, loss = 0.25679193\n",
      "Iteration 1868, loss = 0.20115424\n",
      "Iteration 1869, loss = 0.19715921\n",
      "Iteration 1870, loss = 0.13624136\n",
      "Iteration 1871, loss = 0.13563679\n",
      "Iteration 1872, loss = 0.12236625\n",
      "Iteration 1873, loss = 0.11924091\n",
      "Iteration 1874, loss = 0.11228834\n",
      "Iteration 1875, loss = 0.11309589\n",
      "Iteration 1876, loss = 0.13877036\n",
      "Iteration 1877, loss = 0.13123790\n",
      "Iteration 1878, loss = 0.11730135\n",
      "Iteration 1879, loss = 0.13796756\n",
      "Iteration 1880, loss = 0.15311777\n",
      "Iteration 1881, loss = 0.12333471\n",
      "Iteration 1882, loss = 0.12891948\n",
      "Iteration 1883, loss = 0.12014664\n",
      "Iteration 1884, loss = 0.11369968\n",
      "Iteration 1885, loss = 0.11165740\n",
      "Iteration 1886, loss = 0.11795975\n",
      "Iteration 1887, loss = 0.12646434\n",
      "Iteration 1888, loss = 0.12495578\n",
      "Iteration 1889, loss = 0.12966883\n",
      "Iteration 1890, loss = 0.15210992\n",
      "Iteration 1891, loss = 0.11705248\n",
      "Iteration 1892, loss = 0.14208895\n",
      "Iteration 1893, loss = 0.12842581\n",
      "Iteration 1894, loss = 0.14459358\n",
      "Iteration 1895, loss = 0.16542948\n",
      "Iteration 1896, loss = 0.19655095\n",
      "Iteration 1897, loss = 0.15244675\n",
      "Iteration 1898, loss = 0.13460623\n",
      "Iteration 1899, loss = 0.13934535\n",
      "Iteration 1900, loss = 0.13653804\n",
      "Iteration 1901, loss = 0.13182752\n",
      "Iteration 1902, loss = 0.12215777\n",
      "Iteration 1903, loss = 0.12364289\n",
      "Iteration 1904, loss = 0.11948890\n",
      "Iteration 1905, loss = 0.12457646\n",
      "Iteration 1906, loss = 0.11729280\n",
      "Iteration 1907, loss = 0.12420913\n",
      "Iteration 1908, loss = 0.11008063\n",
      "Iteration 1909, loss = 0.11674945\n",
      "Iteration 1910, loss = 0.10979995\n",
      "Iteration 1911, loss = 0.10683409\n",
      "Iteration 1912, loss = 0.11836977\n",
      "Iteration 1913, loss = 0.11617111\n",
      "Iteration 1914, loss = 0.12286775\n",
      "Iteration 1915, loss = 0.12420430\n",
      "Iteration 1916, loss = 0.11364672\n",
      "Iteration 1917, loss = 0.10906830\n",
      "Iteration 1918, loss = 0.10697503\n",
      "Iteration 1919, loss = 0.11802789\n",
      "Iteration 1920, loss = 0.12045735\n",
      "Iteration 1921, loss = 0.14050052\n",
      "Iteration 1922, loss = 0.18186056\n",
      "Iteration 1923, loss = 0.17126767\n",
      "Iteration 1924, loss = 0.16704832\n",
      "Iteration 1925, loss = 0.14726481\n",
      "Iteration 1926, loss = 0.11814976\n",
      "Iteration 1927, loss = 0.12201816\n",
      "Iteration 1928, loss = 0.11913271\n",
      "Iteration 1929, loss = 0.11864671\n",
      "Iteration 1930, loss = 0.12549786\n",
      "Iteration 1931, loss = 0.11167437\n",
      "Iteration 1932, loss = 0.11575416\n",
      "Iteration 1933, loss = 0.10735510\n",
      "Iteration 1934, loss = 0.11911050\n",
      "Iteration 1935, loss = 0.12826640\n",
      "Iteration 1936, loss = 0.17455284\n",
      "Iteration 1937, loss = 0.15674986\n",
      "Iteration 1938, loss = 0.14751855\n",
      "Iteration 1939, loss = 0.13342113\n",
      "Iteration 1940, loss = 0.16032138\n",
      "Iteration 1941, loss = 0.13657467\n",
      "Iteration 1942, loss = 0.12493596\n",
      "Iteration 1943, loss = 0.13425293\n",
      "Iteration 1944, loss = 0.13204541\n",
      "Iteration 1945, loss = 0.10782688\n",
      "Iteration 1946, loss = 0.11302932\n",
      "Iteration 1947, loss = 0.10829017\n",
      "Iteration 1948, loss = 0.11484077\n",
      "Iteration 1949, loss = 0.11413672\n",
      "Iteration 1950, loss = 0.12004394\n",
      "Iteration 1951, loss = 0.11526232\n",
      "Iteration 1952, loss = 0.12024062\n",
      "Iteration 1953, loss = 0.11279986\n",
      "Iteration 1954, loss = 0.11728353\n",
      "Iteration 1955, loss = 0.13450543\n",
      "Iteration 1956, loss = 0.11555637\n",
      "Iteration 1957, loss = 0.10918022\n",
      "Iteration 1958, loss = 0.12180695\n",
      "Iteration 1959, loss = 0.14671796\n",
      "Iteration 1960, loss = 0.14624000\n",
      "Iteration 1961, loss = 0.11012118\n",
      "Iteration 1962, loss = 0.12665146\n",
      "Iteration 1963, loss = 0.11497791\n",
      "Iteration 1964, loss = 0.10498014\n",
      "Iteration 1965, loss = 0.11703015\n",
      "Iteration 1966, loss = 0.11191679\n",
      "Iteration 1967, loss = 0.11379660\n",
      "Iteration 1968, loss = 0.11796444\n",
      "Iteration 1969, loss = 0.12148090\n",
      "Iteration 1970, loss = 0.14492914\n",
      "Iteration 1971, loss = 0.12012938\n",
      "Iteration 1972, loss = 0.12845204\n",
      "Iteration 1973, loss = 0.12439234\n",
      "Iteration 1974, loss = 0.15312285\n",
      "Iteration 1975, loss = 0.19103384\n",
      "Iteration 1976, loss = 0.15303068\n",
      "Iteration 1977, loss = 0.10957049\n",
      "Iteration 1978, loss = 0.11892393\n",
      "Iteration 1979, loss = 0.12310443\n",
      "Iteration 1980, loss = 0.11106690\n",
      "Iteration 1981, loss = 0.11774356\n",
      "Iteration 1982, loss = 0.11126645\n",
      "Iteration 1983, loss = 0.13885897\n",
      "Iteration 1984, loss = 0.11131989\n",
      "Iteration 1985, loss = 0.11856316\n",
      "Iteration 1986, loss = 0.13351717\n",
      "Iteration 1987, loss = 0.11442658\n",
      "Iteration 1988, loss = 0.10891728\n",
      "Iteration 1989, loss = 0.10942357\n",
      "Iteration 1990, loss = 0.11008659\n",
      "Iteration 1991, loss = 0.11890493\n",
      "Iteration 1992, loss = 0.11869747\n",
      "Iteration 1993, loss = 0.16837996\n",
      "Iteration 1994, loss = 0.11626398\n",
      "Iteration 1995, loss = 0.11350722\n",
      "Iteration 1996, loss = 0.11226969\n",
      "Iteration 1997, loss = 0.12774642\n",
      "Iteration 1998, loss = 0.10509852\n",
      "Iteration 1999, loss = 0.11096480\n",
      "Iteration 2000, loss = 0.10549035\n",
      "Iteration 2001, loss = 0.12599119\n",
      "Iteration 2002, loss = 0.14872215\n",
      "Iteration 2003, loss = 0.14667041\n",
      "Iteration 2004, loss = 0.13252928\n",
      "Iteration 2005, loss = 0.11633193\n",
      "Iteration 2006, loss = 0.12527218\n",
      "Iteration 2007, loss = 0.11312117\n",
      "Iteration 2008, loss = 0.10607801\n",
      "Iteration 2009, loss = 0.11619782\n",
      "Iteration 2010, loss = 0.12228797\n",
      "Iteration 2011, loss = 0.11134253\n",
      "Iteration 2012, loss = 0.10830110\n",
      "Iteration 2013, loss = 0.11161471\n",
      "Iteration 2014, loss = 0.12157163\n",
      "Iteration 2015, loss = 0.11620696\n",
      "Iteration 2016, loss = 0.10429717\n",
      "Iteration 2017, loss = 0.11895991\n",
      "Iteration 2018, loss = 0.15200524\n",
      "Iteration 2019, loss = 0.10908590\n",
      "Iteration 2020, loss = 0.13245258\n",
      "Iteration 2021, loss = 0.22671327\n",
      "Iteration 2022, loss = 0.12789150\n",
      "Iteration 2023, loss = 0.11552775\n",
      "Iteration 2024, loss = 0.10876110\n",
      "Iteration 2025, loss = 0.11675238\n",
      "Iteration 2026, loss = 0.10760612\n",
      "Iteration 2027, loss = 0.11058959\n",
      "Iteration 2028, loss = 0.11369759\n",
      "Iteration 2029, loss = 0.10636214\n",
      "Iteration 2030, loss = 0.10838101\n",
      "Iteration 2031, loss = 0.12136960\n",
      "Iteration 2032, loss = 0.17165744\n",
      "Iteration 2033, loss = 0.21805432\n",
      "Iteration 2034, loss = 0.36337946\n",
      "Iteration 2035, loss = 0.15213058\n",
      "Iteration 2036, loss = 0.14118413\n",
      "Iteration 2037, loss = 0.13067933\n",
      "Iteration 2038, loss = 0.16694634\n",
      "Iteration 2039, loss = 0.16236527\n",
      "Iteration 2040, loss = 0.14383836\n",
      "Iteration 2041, loss = 0.12822715\n",
      "Iteration 2042, loss = 0.16253176\n",
      "Iteration 2043, loss = 0.10652455\n",
      "Iteration 2044, loss = 0.11683862\n",
      "Iteration 2045, loss = 0.11749985\n",
      "Iteration 2046, loss = 0.11084016\n",
      "Iteration 2047, loss = 0.10961871\n",
      "Iteration 2048, loss = 0.11701377\n",
      "Iteration 2049, loss = 0.11305707\n",
      "Iteration 2050, loss = 0.11055519\n",
      "Iteration 2051, loss = 0.10749102\n",
      "Iteration 2052, loss = 0.10442256\n",
      "Iteration 2053, loss = 0.11387130\n",
      "Iteration 2054, loss = 0.10640569\n",
      "Iteration 2055, loss = 0.11222578\n",
      "Iteration 2056, loss = 0.11015720\n",
      "Iteration 2057, loss = 0.11613008\n",
      "Iteration 2058, loss = 0.12477919\n",
      "Iteration 2059, loss = 0.11830683\n",
      "Iteration 2060, loss = 0.11337906\n",
      "Iteration 2061, loss = 0.10716517\n",
      "Iteration 2062, loss = 0.11826749\n",
      "Iteration 2063, loss = 0.11693352\n",
      "Iteration 2064, loss = 0.11666679\n",
      "Iteration 2065, loss = 0.12061889\n",
      "Iteration 2066, loss = 0.11103444\n",
      "Iteration 2067, loss = 0.10919283\n",
      "Iteration 2068, loss = 0.10144972\n",
      "Iteration 2069, loss = 0.11738464\n",
      "Iteration 2070, loss = 0.11709326\n",
      "Iteration 2071, loss = 0.11468192\n",
      "Iteration 2072, loss = 0.10687265\n",
      "Iteration 2073, loss = 0.12245318\n",
      "Iteration 2074, loss = 0.10490094\n",
      "Iteration 2075, loss = 0.15794489\n",
      "Iteration 2076, loss = 0.18515909\n",
      "Iteration 2077, loss = 0.13864421\n",
      "Iteration 2078, loss = 0.13197132\n",
      "Iteration 2079, loss = 0.16180851\n",
      "Iteration 2080, loss = 0.12218309\n",
      "Iteration 2081, loss = 0.12526939\n",
      "Iteration 2082, loss = 0.12274243\n",
      "Iteration 2083, loss = 0.12076616\n",
      "Iteration 2084, loss = 0.11893468\n",
      "Iteration 2085, loss = 0.11802108\n",
      "Iteration 2086, loss = 0.11066394\n",
      "Iteration 2087, loss = 0.12027049\n",
      "Iteration 2088, loss = 0.15071154\n",
      "Iteration 2089, loss = 0.13348441\n",
      "Iteration 2090, loss = 0.15782426\n",
      "Iteration 2091, loss = 0.16625627\n",
      "Iteration 2092, loss = 0.24384083\n",
      "Iteration 2093, loss = 0.61069523\n",
      "Iteration 2094, loss = 0.66432366\n",
      "Iteration 2095, loss = 0.56907753\n",
      "Iteration 2096, loss = 0.37299411\n",
      "Iteration 2097, loss = 0.27248137\n",
      "Iteration 2098, loss = 0.37038153\n",
      "Iteration 2099, loss = 0.26965722\n",
      "Iteration 2100, loss = 0.16472814\n",
      "Iteration 2101, loss = 0.23208555\n",
      "Iteration 2102, loss = 0.16716045\n",
      "Iteration 2103, loss = 0.14002652\n",
      "Iteration 2104, loss = 0.14851150\n",
      "Iteration 2105, loss = 0.12091929\n",
      "Iteration 2106, loss = 0.15423144\n",
      "Iteration 2107, loss = 0.10975412\n",
      "Iteration 2108, loss = 0.10495448\n",
      "Iteration 2109, loss = 0.10969695\n",
      "Iteration 2110, loss = 0.10312904\n",
      "Iteration 2111, loss = 0.10444792\n",
      "Iteration 2112, loss = 0.11903888\n",
      "Iteration 2113, loss = 0.10812118\n",
      "Iteration 2114, loss = 0.10960395\n",
      "Iteration 2115, loss = 0.10633711\n",
      "Iteration 2116, loss = 0.10578155\n",
      "Iteration 2117, loss = 0.11122040\n",
      "Iteration 2118, loss = 0.10815628\n",
      "Iteration 2119, loss = 0.13596112\n",
      "Iteration 2120, loss = 0.10866370\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 2121, loss = 0.10491441\n",
      "Iteration 2122, loss = 0.10870499\n",
      "Iteration 2123, loss = 0.11321083\n",
      "Iteration 2124, loss = 0.11359187\n",
      "Iteration 2125, loss = 0.12314099\n",
      "Iteration 2126, loss = 0.10789147\n",
      "Iteration 2127, loss = 0.10395463\n",
      "Iteration 2128, loss = 0.10629629\n",
      "Iteration 2129, loss = 0.14252246\n",
      "Iteration 2130, loss = 0.11490752\n",
      "Iteration 2131, loss = 0.13548542\n",
      "Iteration 2132, loss = 0.10804963\n",
      "Iteration 2133, loss = 0.10505730\n",
      "Iteration 2134, loss = 0.10613763\n",
      "Iteration 2135, loss = 0.11910916\n",
      "Iteration 2136, loss = 0.11883286\n",
      "Iteration 2137, loss = 0.11144194\n",
      "Iteration 2138, loss = 0.11093760\n",
      "Iteration 2139, loss = 0.11602135\n",
      "Iteration 2140, loss = 0.10287506\n",
      "Iteration 2141, loss = 0.10593619\n",
      "Iteration 2142, loss = 0.10336143\n",
      "Iteration 2143, loss = 0.10762922\n",
      "Iteration 2144, loss = 0.11374684\n",
      "Iteration 2145, loss = 0.10912745\n",
      "Iteration 2146, loss = 0.10878355\n",
      "Iteration 2147, loss = 0.11235418\n",
      "Iteration 2148, loss = 0.12640032\n",
      "Iteration 2149, loss = 0.11101298\n",
      "Iteration 2150, loss = 0.11833499\n",
      "Iteration 2151, loss = 0.11956254\n",
      "Iteration 2152, loss = 0.10816269\n",
      "Iteration 2153, loss = 0.10748666\n",
      "Iteration 2154, loss = 0.11185558\n",
      "Iteration 2155, loss = 0.11808507\n",
      "Iteration 2156, loss = 0.10904969\n",
      "Iteration 2157, loss = 0.10430480\n",
      "Iteration 2158, loss = 0.10550400\n",
      "Iteration 2159, loss = 0.11564067\n",
      "Iteration 2160, loss = 0.11945236\n",
      "Iteration 2161, loss = 0.10864408\n",
      "Iteration 2162, loss = 0.12346531\n",
      "Iteration 2163, loss = 0.11808839\n",
      "Iteration 2164, loss = 0.11483895\n",
      "Iteration 2165, loss = 0.13544624\n",
      "Iteration 2166, loss = 0.10321523\n",
      "Iteration 2167, loss = 0.11214196\n",
      "Iteration 2168, loss = 0.11120035\n",
      "Iteration 2169, loss = 0.10974947\n",
      "Iteration 2170, loss = 0.11030791\n",
      "Iteration 2171, loss = 0.10760136\n",
      "Iteration 2172, loss = 0.12401332\n",
      "Iteration 2173, loss = 0.10984563\n",
      "Iteration 2174, loss = 0.11545792\n",
      "Iteration 2175, loss = 0.10366985\n",
      "Iteration 2176, loss = 0.11434861\n",
      "Iteration 2177, loss = 0.10759144\n",
      "Iteration 2178, loss = 0.11033350\n",
      "Iteration 2179, loss = 0.10527062\n",
      "Iteration 2180, loss = 0.10500683\n",
      "Iteration 2181, loss = 0.10495957\n",
      "Iteration 2182, loss = 0.11022047\n",
      "Iteration 2183, loss = 0.11303405\n",
      "Iteration 2184, loss = 0.11252849\n",
      "Iteration 2185, loss = 0.16088057\n",
      "Iteration 2186, loss = 0.11299348\n",
      "Iteration 2187, loss = 0.11465397\n",
      "Iteration 2188, loss = 0.11781253\n",
      "Iteration 2189, loss = 0.11533020\n",
      "Iteration 2190, loss = 0.11531933\n",
      "Iteration 2191, loss = 0.11855128\n",
      "Iteration 2192, loss = 0.10599426\n",
      "Iteration 2193, loss = 0.11627521\n",
      "Iteration 2194, loss = 0.12003073\n",
      "Iteration 2195, loss = 0.11841649\n",
      "Iteration 2196, loss = 0.11688124\n",
      "Iteration 2197, loss = 0.11371382\n",
      "Iteration 2198, loss = 0.14311262\n",
      "Iteration 2199, loss = 0.25175385\n",
      "Iteration 2200, loss = 0.54163791\n",
      "Iteration 2201, loss = 0.57862224\n",
      "Iteration 2202, loss = 0.44703214\n",
      "Iteration 2203, loss = 0.29616697\n",
      "Iteration 2204, loss = 0.27534571\n",
      "Iteration 2205, loss = 0.36893030\n",
      "Iteration 2206, loss = 0.20904789\n",
      "Iteration 2207, loss = 0.29209643\n",
      "Iteration 2208, loss = 0.18124075\n",
      "Iteration 2209, loss = 0.14721205\n",
      "Iteration 2210, loss = 0.12513433\n",
      "Iteration 2211, loss = 0.11434353\n",
      "Iteration 2212, loss = 0.12320849\n",
      "Iteration 2213, loss = 0.10397229\n",
      "Iteration 2214, loss = 0.10894624\n",
      "Iteration 2215, loss = 0.11670838\n",
      "Iteration 2216, loss = 0.11457352\n",
      "Iteration 2217, loss = 0.11127934\n",
      "Iteration 2218, loss = 0.10491673\n",
      "Iteration 2219, loss = 0.12012581\n",
      "Iteration 2220, loss = 0.10656013\n",
      "Iteration 2221, loss = 0.11055822\n",
      "Iteration 2222, loss = 0.11171467\n",
      "Iteration 2223, loss = 0.11207319\n",
      "Iteration 2224, loss = 0.10806932\n",
      "Iteration 2225, loss = 0.11271830\n",
      "Iteration 2226, loss = 0.11568580\n",
      "Iteration 2227, loss = 0.11043453\n",
      "Iteration 2228, loss = 0.13365812\n",
      "Iteration 2229, loss = 0.11753166\n",
      "Iteration 2230, loss = 0.17110264\n",
      "Iteration 2231, loss = 0.14239137\n",
      "Iteration 2232, loss = 0.16377209\n",
      "Iteration 2233, loss = 0.13228117\n",
      "Iteration 2234, loss = 0.13528734\n",
      "Iteration 2235, loss = 0.11343515\n",
      "Iteration 2236, loss = 0.12948098\n",
      "Iteration 2237, loss = 0.10144270\n",
      "Iteration 2238, loss = 0.14694871\n",
      "Iteration 2239, loss = 0.12225254\n",
      "Iteration 2240, loss = 0.11681607\n",
      "Iteration 2241, loss = 0.12080545\n",
      "Iteration 2242, loss = 0.11453850\n",
      "Iteration 2243, loss = 0.11046408\n",
      "Iteration 2244, loss = 0.12288496\n",
      "Iteration 2245, loss = 0.11202650\n",
      "Iteration 2246, loss = 0.11388962\n",
      "Iteration 2247, loss = 0.11942409\n",
      "Iteration 2248, loss = 0.12752280\n",
      "Iteration 2249, loss = 0.11374335\n",
      "Iteration 2250, loss = 0.10614298\n",
      "Iteration 2251, loss = 0.10609749\n",
      "Iteration 2252, loss = 0.10769398\n",
      "Iteration 2253, loss = 0.10510463\n",
      "Iteration 2254, loss = 0.10541624\n",
      "Iteration 2255, loss = 0.11188967\n",
      "Iteration 2256, loss = 0.10876320\n",
      "Iteration 2257, loss = 0.10600448\n",
      "Iteration 2258, loss = 0.10682770\n",
      "Iteration 2259, loss = 0.10584870\n",
      "Iteration 2260, loss = 0.10935725\n",
      "Iteration 2261, loss = 0.10991723\n",
      "Iteration 2262, loss = 0.10471943\n",
      "Iteration 2263, loss = 0.10671706\n",
      "Iteration 2264, loss = 0.10759324\n",
      "Iteration 2265, loss = 0.10898620\n",
      "Iteration 2266, loss = 0.11270441\n",
      "Iteration 2267, loss = 0.10782840\n",
      "Iteration 2268, loss = 0.10693369\n",
      "Iteration 2269, loss = 0.10712812\n",
      "Iteration 2270, loss = 0.11777904\n",
      "Iteration 2271, loss = 0.11033952\n",
      "Iteration 2272, loss = 0.11125724\n",
      "Iteration 2273, loss = 0.11021348\n",
      "Iteration 2274, loss = 0.13636325\n",
      "Iteration 2275, loss = 0.11372601\n",
      "Iteration 2276, loss = 0.11929262\n",
      "Iteration 2277, loss = 0.10296986\n",
      "Iteration 2278, loss = 0.10430823\n",
      "Iteration 2279, loss = 0.10699166\n",
      "Iteration 2280, loss = 0.10613988\n",
      "Iteration 2281, loss = 0.10220210\n",
      "Iteration 2282, loss = 0.10350177\n",
      "Iteration 2283, loss = 0.10941616\n",
      "Iteration 2284, loss = 0.10791862\n",
      "Iteration 2285, loss = 0.10746345\n",
      "Iteration 2286, loss = 0.10349983\n",
      "Iteration 2287, loss = 0.12634739\n",
      "Iteration 2288, loss = 0.11920468\n",
      "Iteration 2289, loss = 0.12155740\n",
      "Iteration 2290, loss = 0.19423261\n",
      "Iteration 2291, loss = 0.15582975\n",
      "Iteration 2292, loss = 0.30229354\n",
      "Iteration 2293, loss = 0.18633865\n",
      "Iteration 2294, loss = 0.12653634\n",
      "Iteration 2295, loss = 0.10511331\n",
      "Iteration 2296, loss = 0.11241070\n",
      "Iteration 2297, loss = 0.11871499\n",
      "Iteration 2298, loss = 0.11019734\n",
      "Iteration 2299, loss = 0.10611978\n",
      "Iteration 2300, loss = 0.10930619\n",
      "Iteration 2301, loss = 0.10509681\n",
      "Iteration 2302, loss = 0.11670181\n",
      "Iteration 2303, loss = 0.11719140\n",
      "Iteration 2304, loss = 0.10670876\n",
      "Iteration 2305, loss = 0.10939790\n",
      "Iteration 2306, loss = 0.10526887\n",
      "Iteration 2307, loss = 0.11939170\n",
      "Iteration 2308, loss = 0.10711513\n",
      "Iteration 2309, loss = 0.10925756\n",
      "Iteration 2310, loss = 0.10708187\n",
      "Iteration 2311, loss = 0.10778068\n",
      "Iteration 2312, loss = 0.12060010\n",
      "Iteration 2313, loss = 0.10940480\n",
      "Iteration 2314, loss = 0.10190086\n",
      "Iteration 2315, loss = 0.11043495\n",
      "Iteration 2316, loss = 0.10430462\n",
      "Iteration 2317, loss = 0.10413096\n",
      "Iteration 2318, loss = 0.10361406\n",
      "Iteration 2319, loss = 0.10754787\n",
      "Iteration 2320, loss = 0.10585798\n",
      "Iteration 2321, loss = 0.10554179\n",
      "Iteration 2322, loss = 0.10315663\n",
      "Iteration 2323, loss = 0.10359636\n",
      "Iteration 2324, loss = 0.10346131\n",
      "Iteration 2325, loss = 0.10610740\n",
      "Iteration 2326, loss = 0.10183944\n",
      "Iteration 2327, loss = 0.10919707\n",
      "Iteration 2328, loss = 0.10164538\n",
      "Iteration 2329, loss = 0.10258998\n",
      "Iteration 2330, loss = 0.10643852\n",
      "Iteration 2331, loss = 0.11256256\n",
      "Iteration 2332, loss = 0.11947062\n",
      "Iteration 2333, loss = 0.11496518\n",
      "Iteration 2334, loss = 0.12235328\n",
      "Iteration 2335, loss = 0.11078401\n",
      "Iteration 2336, loss = 0.15394344\n",
      "Iteration 2337, loss = 0.10666291\n",
      "Iteration 2338, loss = 0.12474539\n",
      "Iteration 2339, loss = 0.14024132\n",
      "Iteration 2340, loss = 0.21407362\n",
      "Iteration 2341, loss = 0.20500453\n",
      "Iteration 2342, loss = 0.20523246\n",
      "Iteration 2343, loss = 0.15289091\n",
      "Iteration 2344, loss = 0.17251244\n",
      "Iteration 2345, loss = 0.15795934\n",
      "Iteration 2346, loss = 0.17991115\n",
      "Iteration 2347, loss = 2.68265928\n",
      "Iteration 2348, loss = 1.35527615\n",
      "Iteration 2349, loss = 0.87929131\n",
      "Iteration 2350, loss = 0.82172569\n",
      "Iteration 2351, loss = 1.11035917\n",
      "Iteration 2352, loss = 1.02821615\n",
      "Iteration 2353, loss = 1.23273856\n",
      "Iteration 2354, loss = 1.70387072\n",
      "Iteration 2355, loss = 1.60719182\n",
      "Iteration 2356, loss = 1.32428524\n",
      "Iteration 2357, loss = 0.99857691\n",
      "Iteration 2358, loss = 1.07674512\n",
      "Iteration 2359, loss = 0.95809006\n",
      "Iteration 2360, loss = 1.04855950\n",
      "Iteration 2361, loss = 1.02668399\n",
      "Iteration 2362, loss = 0.83299958\n",
      "Iteration 2363, loss = 0.64869621\n",
      "Iteration 2364, loss = 0.47539414\n",
      "Iteration 2365, loss = 0.36090324\n",
      "Iteration 2366, loss = 0.31557967\n",
      "Iteration 2367, loss = 0.28434366\n",
      "Iteration 2368, loss = 0.21143379\n",
      "Iteration 2369, loss = 0.21331816\n",
      "Iteration 2370, loss = 0.34142145\n",
      "Iteration 2371, loss = 0.61688459\n",
      "Iteration 2372, loss = 0.78850331\n",
      "Iteration 2373, loss = 0.64164200\n",
      "Iteration 2374, loss = 0.49705828\n",
      "Iteration 2375, loss = 0.42816732\n",
      "Iteration 2376, loss = 0.30986857\n",
      "Iteration 2377, loss = 0.52768379\n",
      "Iteration 2378, loss = 0.54806779\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 2379, loss = 0.33160930\n",
      "Iteration 2380, loss = 0.34516768\n",
      "Iteration 2381, loss = 0.36109009\n",
      "Iteration 2382, loss = 0.22513054\n",
      "Iteration 2383, loss = 0.14913716\n",
      "Iteration 2384, loss = 0.17633983\n",
      "Iteration 2385, loss = 0.17271955\n",
      "Iteration 2386, loss = 0.13971286\n",
      "Iteration 2387, loss = 0.12840985\n",
      "Iteration 2388, loss = 0.12414465\n",
      "Iteration 2389, loss = 0.12767231\n",
      "Iteration 2390, loss = 0.16042949\n",
      "Iteration 2391, loss = 0.14471344\n",
      "Iteration 2392, loss = 0.13855029\n",
      "Iteration 2393, loss = 0.12465716\n",
      "Iteration 2394, loss = 0.11062332\n",
      "Iteration 2395, loss = 0.13631266\n",
      "Iteration 2396, loss = 0.14171457\n",
      "Iteration 2397, loss = 0.14033067\n",
      "Iteration 2398, loss = 0.16157141\n",
      "Iteration 2399, loss = 0.12785935\n",
      "Iteration 2400, loss = 0.11610583\n",
      "Iteration 2401, loss = 0.12500437\n",
      "Iteration 2402, loss = 0.11018384\n",
      "Iteration 2403, loss = 0.12112854\n",
      "Iteration 2404, loss = 0.12159438\n",
      "Iteration 2405, loss = 0.12448402\n",
      "Iteration 2406, loss = 0.13033801\n",
      "Iteration 2407, loss = 0.14155858\n",
      "Iteration 2408, loss = 0.19312896\n",
      "Iteration 2409, loss = 0.12625312\n",
      "Iteration 2410, loss = 0.13974761\n",
      "Iteration 2411, loss = 0.14801842\n",
      "Iteration 2412, loss = 0.12038762\n",
      "Iteration 2413, loss = 0.11610210\n",
      "Iteration 2414, loss = 0.11117811\n",
      "Iteration 2415, loss = 0.11387905\n",
      "Iteration 2416, loss = 0.11841504\n",
      "Iteration 2417, loss = 0.11244878\n",
      "Iteration 2418, loss = 0.12248566\n",
      "Iteration 2419, loss = 0.11054686\n",
      "Iteration 2420, loss = 0.12189954\n",
      "Iteration 2421, loss = 0.12829927\n",
      "Iteration 2422, loss = 0.10857577\n",
      "Iteration 2423, loss = 0.11736803\n",
      "Iteration 2424, loss = 0.11143107\n",
      "Iteration 2425, loss = 0.11064923\n",
      "Iteration 2426, loss = 0.10810953\n",
      "Iteration 2427, loss = 0.10877423\n",
      "Iteration 2428, loss = 0.11625333\n",
      "Iteration 2429, loss = 0.12158551\n",
      "Iteration 2430, loss = 0.12748634\n",
      "Iteration 2431, loss = 0.11507029\n",
      "Iteration 2432, loss = 0.12084268\n",
      "Iteration 2433, loss = 0.11234783\n",
      "Iteration 2434, loss = 0.11171903\n",
      "Iteration 2435, loss = 0.11529859\n",
      "Iteration 2436, loss = 0.10700927\n",
      "Iteration 2437, loss = 0.11178196\n",
      "Iteration 2438, loss = 0.11626404\n",
      "Iteration 2439, loss = 0.11283470\n",
      "Iteration 2440, loss = 0.11330180\n",
      "Iteration 2441, loss = 0.11586128\n",
      "Iteration 2442, loss = 0.10571705\n",
      "Iteration 2443, loss = 0.10893285\n",
      "Iteration 2444, loss = 0.10651774\n",
      "Iteration 2445, loss = 0.10856514\n",
      "Iteration 2446, loss = 0.10518861\n",
      "Iteration 2447, loss = 0.11131946\n",
      "Iteration 2448, loss = 0.10901288\n",
      "Iteration 2449, loss = 0.12442266\n",
      "Iteration 2450, loss = 0.10891569\n",
      "Iteration 2451, loss = 0.11214583\n",
      "Iteration 2452, loss = 0.11700361\n",
      "Iteration 2453, loss = 0.11421013\n",
      "Iteration 2454, loss = 0.11393831\n",
      "Iteration 2455, loss = 0.11367159\n",
      "Iteration 2456, loss = 0.13237540\n",
      "Iteration 2457, loss = 0.10974688\n",
      "Iteration 2458, loss = 0.11353974\n",
      "Iteration 2459, loss = 0.11405635\n",
      "Iteration 2460, loss = 0.10741560\n",
      "Iteration 2461, loss = 0.11089007\n",
      "Iteration 2462, loss = 0.11326757\n",
      "Iteration 2463, loss = 0.11104919\n",
      "Iteration 2464, loss = 0.12362293\n",
      "Iteration 2465, loss = 0.12054756\n",
      "Iteration 2466, loss = 0.11909306\n",
      "Iteration 2467, loss = 0.13048658\n",
      "Iteration 2468, loss = 0.11731802\n",
      "Iteration 2469, loss = 0.12757960\n",
      "Iteration 2470, loss = 0.11510448\n",
      "Iteration 2471, loss = 0.11401980\n",
      "Iteration 2472, loss = 0.11198928\n",
      "Iteration 2473, loss = 0.10708484\n",
      "Iteration 2474, loss = 0.10528001\n",
      "Iteration 2475, loss = 0.10554788\n",
      "Iteration 2476, loss = 0.11110665\n",
      "Iteration 2477, loss = 0.11632980\n",
      "Iteration 2478, loss = 0.10888452\n",
      "Iteration 2479, loss = 0.11779423\n",
      "Iteration 2480, loss = 0.10389940\n",
      "Iteration 2481, loss = 0.10689904\n",
      "Iteration 2482, loss = 0.10909977\n",
      "Iteration 2483, loss = 0.14410938\n",
      "Iteration 2484, loss = 0.12278163\n",
      "Iteration 2485, loss = 0.12946514\n",
      "Iteration 2486, loss = 0.12854514\n",
      "Iteration 2487, loss = 0.11901173\n",
      "Iteration 2488, loss = 0.11186917\n",
      "Iteration 2489, loss = 0.11526367\n",
      "Iteration 2490, loss = 0.11819983\n",
      "Iteration 2491, loss = 0.11135398\n",
      "Iteration 2492, loss = 0.11027587\n",
      "Iteration 2493, loss = 0.11006781\n",
      "Iteration 2494, loss = 0.11405581\n",
      "Iteration 2495, loss = 0.10514380\n",
      "Iteration 2496, loss = 0.10928505\n",
      "Iteration 2497, loss = 0.11230715\n",
      "Iteration 2498, loss = 0.11525551\n",
      "Iteration 2499, loss = 0.12914127\n",
      "Iteration 2500, loss = 0.19687688\n",
      "Iteration 2501, loss = 0.13113872\n",
      "Iteration 2502, loss = 0.14575548\n",
      "Iteration 2503, loss = 0.11039494\n",
      "Iteration 2504, loss = 0.11937462\n",
      "Iteration 2505, loss = 0.11238340\n",
      "Iteration 2506, loss = 0.12417063\n",
      "Iteration 2507, loss = 0.11897533\n",
      "Iteration 2508, loss = 0.11211163\n",
      "Iteration 2509, loss = 0.10808954\n",
      "Iteration 2510, loss = 0.10984482\n",
      "Iteration 2511, loss = 0.10867448\n",
      "Iteration 2512, loss = 0.10986434\n",
      "Iteration 2513, loss = 0.11022754\n",
      "Iteration 2514, loss = 0.11447549\n",
      "Iteration 2515, loss = 0.10994218\n",
      "Iteration 2516, loss = 0.10538202\n",
      "Iteration 2517, loss = 0.10901377\n",
      "Iteration 2518, loss = 0.10322342\n",
      "Iteration 2519, loss = 0.10498467\n",
      "Iteration 2520, loss = 0.11007531\n",
      "Iteration 2521, loss = 0.10846880\n",
      "Iteration 2522, loss = 0.11053127\n",
      "Iteration 2523, loss = 0.12411714\n",
      "Iteration 2524, loss = 0.12912806\n",
      "Iteration 2525, loss = 0.12029765\n",
      "Iteration 2526, loss = 0.10957974\n",
      "Iteration 2527, loss = 0.10731220\n",
      "Iteration 2528, loss = 0.10506845\n",
      "Iteration 2529, loss = 0.11035959\n",
      "Iteration 2530, loss = 0.10069092\n",
      "Iteration 2531, loss = 0.12016715\n",
      "Iteration 2532, loss = 0.11278392\n",
      "Iteration 2533, loss = 0.10603664\n",
      "Iteration 2534, loss = 0.11001720\n",
      "Iteration 2535, loss = 0.10349528\n",
      "Iteration 2536, loss = 0.13462049\n",
      "Iteration 2537, loss = 0.12714765\n",
      "Iteration 2538, loss = 0.11764644\n",
      "Iteration 2539, loss = 0.10772718\n",
      "Iteration 2540, loss = 0.11653841\n",
      "Iteration 2541, loss = 0.12823128\n",
      "Iteration 2542, loss = 0.10612085\n",
      "Iteration 2543, loss = 0.10442940\n",
      "Iteration 2544, loss = 0.10651318\n",
      "Iteration 2545, loss = 0.10794561\n",
      "Iteration 2546, loss = 0.11951653\n",
      "Iteration 2547, loss = 0.13419382\n",
      "Iteration 2548, loss = 0.11689124\n",
      "Iteration 2549, loss = 0.11810397\n",
      "Iteration 2550, loss = 0.11741967\n",
      "Iteration 2551, loss = 0.11798906\n",
      "Iteration 2552, loss = 0.11518348\n",
      "Iteration 2553, loss = 0.11544345\n",
      "Iteration 2554, loss = 0.11190135\n",
      "Iteration 2555, loss = 0.10641184\n",
      "Iteration 2556, loss = 0.10403401\n",
      "Iteration 2557, loss = 0.11265162\n",
      "Iteration 2558, loss = 0.12701557\n",
      "Iteration 2559, loss = 0.13804674\n",
      "Iteration 2560, loss = 0.15666660\n",
      "Iteration 2561, loss = 0.18845720\n",
      "Iteration 2562, loss = 0.24046988\n",
      "Iteration 2563, loss = 0.15159476\n",
      "Iteration 2564, loss = 0.32425490\n",
      "Iteration 2565, loss = 0.22352610\n",
      "Iteration 2566, loss = 0.23282231\n",
      "Iteration 2567, loss = 0.22773203\n",
      "Iteration 2568, loss = 0.21172522\n",
      "Iteration 2569, loss = 0.36853471\n",
      "Iteration 2570, loss = 0.16940922\n",
      "Iteration 2571, loss = 0.13846175\n",
      "Iteration 2572, loss = 0.14484311\n",
      "Iteration 2573, loss = 0.18798878\n",
      "Iteration 2574, loss = 0.13902035\n",
      "Iteration 2575, loss = 0.15156952\n",
      "Iteration 2576, loss = 0.16523296\n",
      "Iteration 2577, loss = 0.17221823\n",
      "Iteration 2578, loss = 0.20106544\n",
      "Iteration 2579, loss = 0.15519922\n",
      "Iteration 2580, loss = 0.15319459\n",
      "Iteration 2581, loss = 0.14333609\n",
      "Iteration 2582, loss = 0.15638746\n",
      "Iteration 2583, loss = 0.13857060\n",
      "Iteration 2584, loss = 0.18300202\n",
      "Iteration 2585, loss = 0.14070330\n",
      "Iteration 2586, loss = 0.11047850\n",
      "Iteration 2587, loss = 0.14391850\n",
      "Iteration 2588, loss = 0.11541337\n",
      "Iteration 2589, loss = 0.12058569\n",
      "Iteration 2590, loss = 0.10974816\n",
      "Iteration 2591, loss = 0.11738728\n",
      "Iteration 2592, loss = 0.10677204\n",
      "Iteration 2593, loss = 0.12639813\n",
      "Iteration 2594, loss = 0.11496783\n",
      "Iteration 2595, loss = 0.11345786\n",
      "Iteration 2596, loss = 0.12685659\n",
      "Iteration 2597, loss = 0.10803745\n",
      "Iteration 2598, loss = 0.12406241\n",
      "Iteration 2599, loss = 0.12822719\n",
      "Iteration 2600, loss = 0.12050575\n",
      "Iteration 2601, loss = 0.14909298\n",
      "Iteration 2602, loss = 0.12950893\n",
      "Iteration 2603, loss = 0.12000149\n",
      "Iteration 2604, loss = 0.11264773\n",
      "Iteration 2605, loss = 0.14985933\n",
      "Iteration 2606, loss = 0.11237572\n",
      "Iteration 2607, loss = 0.20729636\n",
      "Iteration 2608, loss = 0.15415417\n",
      "Iteration 2609, loss = 0.27233109\n",
      "Iteration 2610, loss = 0.26873841\n",
      "Iteration 2611, loss = 0.21691748\n",
      "Iteration 2612, loss = 0.33911355\n",
      "Iteration 2613, loss = 0.51028621\n",
      "Iteration 2614, loss = 0.59503559\n",
      "Iteration 2615, loss = 0.81747107\n",
      "Iteration 2616, loss = 1.01103175\n",
      "Iteration 2617, loss = 0.61485550\n",
      "Iteration 2618, loss = 0.76386565\n",
      "Iteration 2619, loss = 0.59482808\n",
      "Iteration 2620, loss = 0.44998025\n",
      "Iteration 2621, loss = 0.46792857\n",
      "Iteration 2622, loss = 0.47146564\n",
      "Iteration 2623, loss = 0.35719461\n",
      "Iteration 2624, loss = 0.20218549\n",
      "Iteration 2625, loss = 0.19398875\n",
      "Iteration 2626, loss = 0.19463925\n",
      "Iteration 2627, loss = 0.13432349\n",
      "Iteration 2628, loss = 0.13301402\n",
      "Iteration 2629, loss = 0.13098856\n",
      "Iteration 2630, loss = 0.13127900\n",
      "Iteration 2631, loss = 0.13883397\n",
      "Iteration 2632, loss = 0.10945717\n",
      "Iteration 2633, loss = 0.10971602\n",
      "Iteration 2634, loss = 0.10532831\n",
      "Iteration 2635, loss = 0.11061515\n",
      "Iteration 2636, loss = 0.11188355\n",
      "Iteration 2637, loss = 0.10806277\n",
      "Iteration 2638, loss = 0.12877780\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 2639, loss = 0.10620311\n",
      "Iteration 2640, loss = 0.11297858\n",
      "Iteration 2641, loss = 0.10943877\n",
      "Iteration 2642, loss = 0.10859498\n",
      "Iteration 2643, loss = 0.11337528\n",
      "Iteration 2644, loss = 0.10375689\n",
      "Iteration 2645, loss = 0.10823764\n",
      "Iteration 2646, loss = 0.11404632\n",
      "Iteration 2647, loss = 0.10851082\n",
      "Iteration 2648, loss = 0.11571376\n",
      "Iteration 2649, loss = 0.10657500\n",
      "Iteration 2650, loss = 0.11119171\n",
      "Iteration 2651, loss = 0.10569506\n",
      "Iteration 2652, loss = 0.10330718\n",
      "Iteration 2653, loss = 0.11180043\n",
      "Iteration 2654, loss = 0.11289512\n",
      "Iteration 2655, loss = 0.10380916\n",
      "Iteration 2656, loss = 0.10804783\n",
      "Iteration 2657, loss = 0.10735265\n",
      "Iteration 2658, loss = 0.10511361\n",
      "Iteration 2659, loss = 0.10329498\n",
      "Iteration 2660, loss = 0.10473158\n",
      "Iteration 2661, loss = 0.10367344\n",
      "Iteration 2662, loss = 0.10798330\n",
      "Iteration 2663, loss = 0.10813268\n",
      "Iteration 2664, loss = 0.10466586\n",
      "Iteration 2665, loss = 0.10464019\n",
      "Iteration 2666, loss = 0.10340063\n",
      "Iteration 2667, loss = 0.11245311\n",
      "Iteration 2668, loss = 0.11299674\n",
      "Iteration 2669, loss = 0.12595060\n",
      "Iteration 2670, loss = 0.10540828\n",
      "Iteration 2671, loss = 0.10697836\n",
      "Iteration 2672, loss = 0.10881550\n",
      "Iteration 2673, loss = 0.10397652\n",
      "Iteration 2674, loss = 0.10738449\n",
      "Iteration 2675, loss = 0.11123491\n",
      "Iteration 2676, loss = 0.11618923\n",
      "Iteration 2677, loss = 0.11958605\n",
      "Iteration 2678, loss = 0.11676269\n",
      "Iteration 2679, loss = 0.10268802\n",
      "Iteration 2680, loss = 0.10267948\n",
      "Iteration 2681, loss = 0.10568015\n",
      "Iteration 2682, loss = 0.11044325\n",
      "Iteration 2683, loss = 0.10488322\n",
      "Iteration 2684, loss = 0.10521794\n",
      "Iteration 2685, loss = 0.10339415\n",
      "Iteration 2686, loss = 0.10649029\n",
      "Iteration 2687, loss = 0.10324725\n",
      "Iteration 2688, loss = 0.10546235\n",
      "Iteration 2689, loss = 0.11607060\n",
      "Iteration 2690, loss = 0.11051429\n",
      "Iteration 2691, loss = 0.10485661\n",
      "Iteration 2692, loss = 0.10662358\n",
      "Iteration 2693, loss = 0.10648054\n",
      "Iteration 2694, loss = 0.10802511\n",
      "Iteration 2695, loss = 0.13278413\n",
      "Iteration 2696, loss = 0.10817362\n",
      "Iteration 2697, loss = 0.10755256\n",
      "Iteration 2698, loss = 0.10476998\n",
      "Iteration 2699, loss = 0.10259393\n",
      "Iteration 2700, loss = 0.10695819\n",
      "Iteration 2701, loss = 0.10698006\n",
      "Iteration 2702, loss = 0.10963271\n",
      "Iteration 2703, loss = 0.11217686\n",
      "Iteration 2704, loss = 0.11455224\n",
      "Iteration 2705, loss = 0.10665043\n",
      "Iteration 2706, loss = 0.13322450\n",
      "Iteration 2707, loss = 0.12125097\n",
      "Iteration 2708, loss = 0.10641255\n",
      "Iteration 2709, loss = 0.11102808\n",
      "Iteration 2710, loss = 0.10411008\n",
      "Iteration 2711, loss = 0.11517363\n",
      "Iteration 2712, loss = 0.10976793\n",
      "Iteration 2713, loss = 0.11374501\n",
      "Iteration 2714, loss = 0.10907255\n",
      "Iteration 2715, loss = 0.10723721\n",
      "Iteration 2716, loss = 0.12712360\n",
      "Iteration 2717, loss = 0.11622966\n",
      "Iteration 2718, loss = 0.11100474\n",
      "Iteration 2719, loss = 0.11615028\n",
      "Iteration 2720, loss = 0.10283677\n",
      "Iteration 2721, loss = 0.10460422\n",
      "Iteration 2722, loss = 0.10368171\n",
      "Iteration 2723, loss = 0.10550353\n",
      "Iteration 2724, loss = 0.11091497\n",
      "Iteration 2725, loss = 0.11260374\n",
      "Iteration 2726, loss = 0.11425240\n",
      "Iteration 2727, loss = 0.10719730\n",
      "Iteration 2728, loss = 0.10667585\n",
      "Iteration 2729, loss = 0.10364896\n",
      "Iteration 2730, loss = 0.10799536\n",
      "Iteration 2731, loss = 0.10604583\n",
      "Iteration 2732, loss = 0.10460396\n",
      "Iteration 2733, loss = 0.10854134\n",
      "Iteration 2734, loss = 0.11346235\n",
      "Iteration 2735, loss = 0.11018736\n",
      "Iteration 2736, loss = 0.10194493\n",
      "Iteration 2737, loss = 0.10613095\n",
      "Iteration 2738, loss = 0.10141098\n",
      "Iteration 2739, loss = 0.10433867\n",
      "Iteration 2740, loss = 0.10169199\n",
      "Iteration 2741, loss = 0.10617270\n",
      "Iteration 2742, loss = 0.10635126\n",
      "Iteration 2743, loss = 0.10794504\n",
      "Iteration 2744, loss = 0.10598450\n",
      "Iteration 2745, loss = 0.11875058\n",
      "Iteration 2746, loss = 0.12355823\n",
      "Iteration 2747, loss = 0.11412756\n",
      "Iteration 2748, loss = 0.10696334\n",
      "Iteration 2749, loss = 0.13061642\n",
      "Iteration 2750, loss = 0.12898240\n",
      "Iteration 2751, loss = 0.11196803\n",
      "Iteration 2752, loss = 0.13644744\n",
      "Iteration 2753, loss = 0.11729437\n",
      "Iteration 2754, loss = 0.11069938\n",
      "Iteration 2755, loss = 0.11779849\n",
      "Iteration 2756, loss = 0.11809656\n",
      "Iteration 2757, loss = 0.14330261\n",
      "Iteration 2758, loss = 0.11160378\n",
      "Iteration 2759, loss = 0.11828187\n",
      "Iteration 2760, loss = 0.11350983\n",
      "Iteration 2761, loss = 0.11157331\n",
      "Iteration 2762, loss = 0.10238331\n",
      "Iteration 2763, loss = 0.12051184\n",
      "Iteration 2764, loss = 0.11728896\n",
      "Iteration 2765, loss = 0.13163771\n",
      "Iteration 2766, loss = 0.12708277\n",
      "Iteration 2767, loss = 0.14122729\n",
      "Iteration 2768, loss = 0.11751069\n",
      "Iteration 2769, loss = 0.12911710\n",
      "Iteration 2770, loss = 0.19663670\n",
      "Iteration 2771, loss = 0.15612508\n",
      "Iteration 2772, loss = 0.14376311\n",
      "Iteration 2773, loss = 0.17207931\n",
      "Iteration 2774, loss = 0.23859061\n",
      "Iteration 2775, loss = 0.15826752\n",
      "Iteration 2776, loss = 0.15483640\n",
      "Iteration 2777, loss = 0.17192506\n",
      "Iteration 2778, loss = 0.14002687\n",
      "Iteration 2779, loss = 0.16118530\n",
      "Iteration 2780, loss = 0.14259076\n",
      "Iteration 2781, loss = 0.14589974\n",
      "Iteration 2782, loss = 0.14253775\n",
      "Iteration 2783, loss = 0.14470474\n",
      "Iteration 2784, loss = 0.17958251\n",
      "Iteration 2785, loss = 0.26819780\n",
      "Iteration 2786, loss = 0.31197370\n",
      "Iteration 2787, loss = 1.41401139\n",
      "Iteration 2788, loss = 2.15876535\n",
      "Iteration 2789, loss = 1.41916442\n",
      "Iteration 2790, loss = 1.73870653\n",
      "Iteration 2791, loss = 1.36788084\n",
      "Iteration 2792, loss = 1.36562279\n",
      "Iteration 2793, loss = 1.01808982\n",
      "Iteration 2794, loss = 1.14192460\n",
      "Iteration 2795, loss = 1.09968214\n",
      "Iteration 2796, loss = 0.89090186\n",
      "Iteration 2797, loss = 1.25640355\n",
      "Iteration 2798, loss = 0.96070016\n",
      "Iteration 2799, loss = 0.74804631\n",
      "Iteration 2800, loss = 0.93440040\n",
      "Iteration 2801, loss = 0.77801391\n",
      "Iteration 2802, loss = 0.56335803\n",
      "Iteration 2803, loss = 1.35938697\n",
      "Iteration 2804, loss = 1.52468176\n",
      "Iteration 2805, loss = 1.24005451\n",
      "Iteration 2806, loss = 1.04588746\n",
      "Iteration 2807, loss = 0.73172842\n",
      "Iteration 2808, loss = 0.81274472\n",
      "Iteration 2809, loss = 0.80045120\n",
      "Iteration 2810, loss = 0.71463561\n",
      "Iteration 2811, loss = 0.79012570\n",
      "Iteration 2812, loss = 0.43362817\n",
      "Iteration 2813, loss = 0.65349256\n",
      "Iteration 2814, loss = 0.51602335\n",
      "Iteration 2815, loss = 0.42815965\n",
      "Iteration 2816, loss = 0.32657694\n",
      "Iteration 2817, loss = 0.31331562\n",
      "Iteration 2818, loss = 0.30795512\n",
      "Iteration 2819, loss = 0.19757682\n",
      "Iteration 2820, loss = 0.20350393\n",
      "Iteration 2821, loss = 0.21167021\n",
      "Iteration 2822, loss = 0.23242114\n",
      "Iteration 2823, loss = 0.23837493\n",
      "Iteration 2824, loss = 0.17364770\n",
      "Iteration 2825, loss = 0.15079664\n",
      "Iteration 2826, loss = 0.16905923\n",
      "Iteration 2827, loss = 0.17466592\n",
      "Iteration 2828, loss = 0.14681865\n",
      "Iteration 2829, loss = 0.18480090\n",
      "Iteration 2830, loss = 0.15358064\n",
      "Iteration 2831, loss = 0.17404332\n",
      "Iteration 2832, loss = 0.11135449\n",
      "Iteration 2833, loss = 0.11318973\n",
      "Iteration 2834, loss = 0.11305931\n",
      "Iteration 2835, loss = 0.12203110\n",
      "Iteration 2836, loss = 0.11236732\n",
      "Iteration 2837, loss = 0.12388963\n",
      "Iteration 2838, loss = 0.13526259\n",
      "Iteration 2839, loss = 0.11909368\n",
      "Iteration 2840, loss = 0.11319674\n",
      "Iteration 2841, loss = 0.12076174\n",
      "Iteration 2842, loss = 0.11529203\n",
      "Iteration 2843, loss = 0.12288099\n",
      "Iteration 2844, loss = 0.11354425\n",
      "Iteration 2845, loss = 0.10863290\n",
      "Iteration 2846, loss = 0.10951893\n",
      "Iteration 2847, loss = 0.13010167\n",
      "Iteration 2848, loss = 0.10637323\n",
      "Iteration 2849, loss = 0.11042974\n",
      "Iteration 2850, loss = 0.11658690\n",
      "Iteration 2851, loss = 0.10846916\n",
      "Iteration 2852, loss = 0.11282412\n",
      "Iteration 2853, loss = 0.11094124\n",
      "Iteration 2854, loss = 0.10554613\n",
      "Iteration 2855, loss = 0.11251860\n",
      "Iteration 2856, loss = 0.11483238\n",
      "Iteration 2857, loss = 0.10655217\n",
      "Iteration 2858, loss = 0.11664532\n",
      "Iteration 2859, loss = 0.11198894\n",
      "Iteration 2860, loss = 0.11855903\n",
      "Iteration 2861, loss = 0.10340833\n",
      "Iteration 2862, loss = 0.10987665\n",
      "Iteration 2863, loss = 0.11706262\n",
      "Iteration 2864, loss = 0.11349039\n",
      "Iteration 2865, loss = 0.11164993\n",
      "Iteration 2866, loss = 0.11925084\n",
      "Iteration 2867, loss = 0.13670645\n",
      "Iteration 2868, loss = 0.11475255\n",
      "Iteration 2869, loss = 0.11343259\n",
      "Iteration 2870, loss = 0.11407583\n",
      "Iteration 2871, loss = 0.11417496\n",
      "Iteration 2872, loss = 0.11744681\n",
      "Iteration 2873, loss = 0.12101631\n",
      "Iteration 2874, loss = 0.11209332\n",
      "Iteration 2875, loss = 0.11193712\n",
      "Iteration 2876, loss = 0.10708510\n",
      "Iteration 2877, loss = 0.11069524\n",
      "Iteration 2878, loss = 0.10222329\n",
      "Iteration 2879, loss = 0.10824522\n",
      "Iteration 2880, loss = 0.10554305\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 2881, loss = 0.11306613\n",
      "Iteration 2882, loss = 0.10892464\n",
      "Iteration 2883, loss = 0.10689396\n",
      "Iteration 2884, loss = 0.11199672\n",
      "Iteration 2885, loss = 0.11512700\n",
      "Iteration 2886, loss = 0.10760594\n",
      "Iteration 2887, loss = 0.10805146\n",
      "Iteration 2888, loss = 0.11127185\n",
      "Iteration 2889, loss = 0.12224329\n",
      "Iteration 2890, loss = 0.11093953\n",
      "Iteration 2891, loss = 0.10942177\n",
      "Iteration 2892, loss = 0.11327555\n",
      "Iteration 2893, loss = 0.11262295\n",
      "Iteration 2894, loss = 0.11304271\n",
      "Iteration 2895, loss = 0.11862177\n",
      "Iteration 2896, loss = 0.11327750\n",
      "Iteration 2897, loss = 0.12190575\n",
      "Iteration 2898, loss = 0.11368278\n",
      "Iteration 2899, loss = 0.12071733\n",
      "Iteration 2900, loss = 0.12177233\n",
      "Iteration 2901, loss = 0.10764671\n",
      "Iteration 2902, loss = 0.10847865\n",
      "Iteration 2903, loss = 0.10678869\n",
      "Iteration 2904, loss = 0.11528907\n",
      "Iteration 2905, loss = 0.10962208\n",
      "Iteration 2906, loss = 0.11579678\n",
      "Iteration 2907, loss = 0.11246375\n",
      "Iteration 2908, loss = 0.10868400\n",
      "Iteration 2909, loss = 0.13404730\n",
      "Iteration 2910, loss = 0.11325530\n",
      "Iteration 2911, loss = 0.10857690\n",
      "Iteration 2912, loss = 0.10327899\n",
      "Iteration 2913, loss = 0.11964217\n",
      "Iteration 2914, loss = 0.11542320\n",
      "Iteration 2915, loss = 0.10831687\n",
      "Iteration 2916, loss = 0.10688417\n",
      "Iteration 2917, loss = 0.10832784\n",
      "Iteration 2918, loss = 0.10535826\n",
      "Iteration 2919, loss = 0.11062845\n",
      "Iteration 2920, loss = 0.11081208\n",
      "Iteration 2921, loss = 0.11470366\n",
      "Iteration 2922, loss = 0.12790991\n",
      "Iteration 2923, loss = 0.11433164\n",
      "Iteration 2924, loss = 0.10257213\n",
      "Iteration 2925, loss = 0.10624019\n",
      "Iteration 2926, loss = 0.11015999\n",
      "Iteration 2927, loss = 0.10998403\n",
      "Iteration 2928, loss = 0.11220789\n",
      "Iteration 2929, loss = 0.10970536\n",
      "Iteration 2930, loss = 0.10517304\n",
      "Iteration 2931, loss = 0.10976311\n",
      "Iteration 2932, loss = 0.11566614\n",
      "Iteration 2933, loss = 0.10531050\n",
      "Iteration 2934, loss = 0.10564369\n",
      "Iteration 2935, loss = 0.10700596\n",
      "Iteration 2936, loss = 0.10623712\n",
      "Iteration 2937, loss = 0.10696965\n",
      "Iteration 2938, loss = 0.11156362\n",
      "Iteration 2939, loss = 0.10606775\n",
      "Iteration 2940, loss = 0.10560228\n",
      "Iteration 2941, loss = 0.10696128\n",
      "Iteration 2942, loss = 0.11046739\n",
      "Iteration 2943, loss = 0.11977767\n",
      "Iteration 2944, loss = 0.11271201\n",
      "Iteration 2945, loss = 0.15643146\n",
      "Iteration 2946, loss = 0.15896734\n",
      "Iteration 2947, loss = 0.21426346\n",
      "Iteration 2948, loss = 0.14154331\n",
      "Iteration 2949, loss = 0.11610346\n",
      "Iteration 2950, loss = 0.10829969\n",
      "Iteration 2951, loss = 0.13418667\n",
      "Iteration 2952, loss = 0.12173040\n",
      "Iteration 2953, loss = 0.12706697\n",
      "Iteration 2954, loss = 0.15894372\n",
      "Iteration 2955, loss = 0.12681712\n",
      "Iteration 2956, loss = 0.10983999\n",
      "Iteration 2957, loss = 0.12805673\n",
      "Iteration 2958, loss = 0.12718406\n",
      "Iteration 2959, loss = 0.10753664\n",
      "Iteration 2960, loss = 0.12947515\n",
      "Iteration 2961, loss = 0.10867834\n",
      "Iteration 2962, loss = 0.11597691\n",
      "Iteration 2963, loss = 0.10281887\n",
      "Iteration 2964, loss = 0.10607767\n",
      "Iteration 2965, loss = 0.11586825\n",
      "Iteration 2966, loss = 0.11544159\n",
      "Iteration 2967, loss = 0.12773694\n",
      "Iteration 2968, loss = 0.13025817\n",
      "Iteration 2969, loss = 0.12990703\n",
      "Iteration 2970, loss = 0.11319749\n",
      "Iteration 2971, loss = 0.11206780\n",
      "Iteration 2972, loss = 0.12331725\n",
      "Iteration 2973, loss = 0.10771526\n",
      "Iteration 2974, loss = 0.10937431\n",
      "Iteration 2975, loss = 0.10917511\n",
      "Iteration 2976, loss = 0.11429294\n",
      "Iteration 2977, loss = 0.10366207\n",
      "Iteration 2978, loss = 0.10722882\n",
      "Iteration 2979, loss = 0.11419678\n",
      "Iteration 2980, loss = 0.10485261\n",
      "Iteration 2981, loss = 0.11955831\n",
      "Iteration 2982, loss = 0.11040292\n",
      "Iteration 2983, loss = 0.10579396\n",
      "Iteration 2984, loss = 0.10567140\n",
      "Iteration 2985, loss = 0.10720915\n",
      "Iteration 2986, loss = 0.11287421\n",
      "Iteration 2987, loss = 0.12096030\n",
      "Iteration 2988, loss = 0.11010419\n",
      "Iteration 2989, loss = 0.11263370\n",
      "Iteration 2990, loss = 0.11945932\n",
      "Iteration 2991, loss = 0.10741943\n",
      "Iteration 2992, loss = 0.11047180\n",
      "Iteration 2993, loss = 0.10549009\n",
      "Iteration 2994, loss = 0.11120944\n",
      "Iteration 2995, loss = 0.11628643\n",
      "Iteration 2996, loss = 0.14420918\n",
      "Iteration 2997, loss = 0.10978338\n",
      "Iteration 2998, loss = 0.10496833\n",
      "Iteration 2999, loss = 0.11608085\n",
      "Iteration 3000, loss = 0.11411168\n",
      "Iteration 3001, loss = 0.10501119\n",
      "Iteration 3002, loss = 0.10884178\n",
      "Iteration 3003, loss = 0.10387580\n",
      "Iteration 3004, loss = 0.10474044\n",
      "Iteration 3005, loss = 0.10570575\n",
      "Iteration 3006, loss = 0.10747628\n",
      "Iteration 3007, loss = 0.10358809\n",
      "Iteration 3008, loss = 0.10329620\n",
      "Iteration 3009, loss = 0.10767785\n",
      "Iteration 3010, loss = 0.10448272\n",
      "Iteration 3011, loss = 0.12524033\n",
      "Iteration 3012, loss = 0.11030797\n",
      "Iteration 3013, loss = 0.11985153\n",
      "Iteration 3014, loss = 0.11038432\n",
      "Iteration 3015, loss = 0.10295461\n",
      "Iteration 3016, loss = 0.11070586\n",
      "Iteration 3017, loss = 0.12584030\n",
      "Iteration 3018, loss = 0.10381962\n",
      "Iteration 3019, loss = 0.11670876\n",
      "Iteration 3020, loss = 0.10796203\n",
      "Iteration 3021, loss = 0.10501196\n",
      "Iteration 3022, loss = 0.10646307\n",
      "Iteration 3023, loss = 0.10401975\n",
      "Iteration 3024, loss = 0.11673167\n",
      "Iteration 3025, loss = 0.11289219\n",
      "Iteration 3026, loss = 0.10700990\n",
      "Iteration 3027, loss = 0.11025661\n",
      "Iteration 3028, loss = 0.11092054\n",
      "Iteration 3029, loss = 0.10321444\n",
      "Iteration 3030, loss = 0.10801851\n",
      "Iteration 3031, loss = 0.10230524\n",
      "Iteration 3032, loss = 0.11952704\n",
      "Iteration 3033, loss = 0.12169614\n",
      "Iteration 3034, loss = 0.10988532\n",
      "Iteration 3035, loss = 0.10556003\n",
      "Iteration 3036, loss = 0.11025298\n",
      "Iteration 3037, loss = 0.10616856\n",
      "Iteration 3038, loss = 0.10286744\n",
      "Iteration 3039, loss = 0.11134145\n",
      "Iteration 3040, loss = 0.10619168\n",
      "Iteration 3041, loss = 0.10471811\n",
      "Iteration 3042, loss = 0.11898561\n",
      "Iteration 3043, loss = 0.10966841\n",
      "Iteration 3044, loss = 0.10702798\n",
      "Iteration 3045, loss = 0.11003361\n",
      "Iteration 3046, loss = 0.11688849\n",
      "Iteration 3047, loss = 0.10833944\n",
      "Iteration 3048, loss = 0.13073123\n",
      "Iteration 3049, loss = 0.17945545\n",
      "Iteration 3050, loss = 0.11663142\n",
      "Iteration 3051, loss = 0.11867755\n",
      "Iteration 3052, loss = 0.11554307\n",
      "Iteration 3053, loss = 0.10451022\n",
      "Iteration 3054, loss = 0.11384784\n",
      "Iteration 3055, loss = 0.10933100\n",
      "Iteration 3056, loss = 0.12645212\n",
      "Iteration 3057, loss = 0.12962830\n",
      "Iteration 3058, loss = 0.13132323\n",
      "Iteration 3059, loss = 0.11045502\n",
      "Iteration 3060, loss = 0.13059415\n",
      "Iteration 3061, loss = 0.20969985\n",
      "Iteration 3062, loss = 0.12765124\n",
      "Iteration 3063, loss = 0.16867942\n",
      "Iteration 3064, loss = 0.12784706\n",
      "Iteration 3065, loss = 0.13702155\n",
      "Iteration 3066, loss = 0.11430138\n",
      "Iteration 3067, loss = 0.11526442\n",
      "Iteration 3068, loss = 0.10535532\n",
      "Iteration 3069, loss = 0.11196742\n",
      "Iteration 3070, loss = 0.11970610\n",
      "Iteration 3071, loss = 0.13462966\n",
      "Iteration 3072, loss = 0.11248535\n",
      "Iteration 3073, loss = 0.15085641\n",
      "Iteration 3074, loss = 0.12015767\n",
      "Iteration 3075, loss = 0.15696866\n",
      "Iteration 3076, loss = 0.11238799\n",
      "Iteration 3077, loss = 0.13475245\n",
      "Iteration 3078, loss = 0.10721310\n",
      "Iteration 3079, loss = 0.10600339\n",
      "Iteration 3080, loss = 0.11127997\n",
      "Iteration 3081, loss = 0.10958809\n",
      "Iteration 3082, loss = 0.11035837\n",
      "Iteration 3083, loss = 0.10890604\n",
      "Iteration 3084, loss = 0.10827351\n",
      "Iteration 3085, loss = 0.11334395\n",
      "Iteration 3086, loss = 0.10862995\n",
      "Iteration 3087, loss = 0.11828021\n",
      "Iteration 3088, loss = 0.11905912\n",
      "Iteration 3089, loss = 0.12619361\n",
      "Iteration 3090, loss = 0.12683968\n",
      "Iteration 3091, loss = 0.10665056\n",
      "Iteration 3092, loss = 0.10924815\n",
      "Iteration 3093, loss = 0.10555707\n",
      "Iteration 3094, loss = 0.10626081\n",
      "Iteration 3095, loss = 0.10621751\n",
      "Iteration 3096, loss = 0.10634055\n",
      "Iteration 3097, loss = 0.10729026\n",
      "Iteration 3098, loss = 0.11473575\n",
      "Iteration 3099, loss = 0.11810437\n",
      "Iteration 3100, loss = 0.10835145\n",
      "Iteration 3101, loss = 0.10581035\n",
      "Iteration 3102, loss = 0.10594346\n",
      "Iteration 3103, loss = 0.10479071\n",
      "Iteration 3104, loss = 0.11376137\n",
      "Iteration 3105, loss = 0.11324133\n",
      "Iteration 3106, loss = 0.11945870\n",
      "Iteration 3107, loss = 0.18595657\n",
      "Iteration 3108, loss = 0.12090992\n",
      "Iteration 3109, loss = 0.10977803\n",
      "Iteration 3110, loss = 0.10794933\n",
      "Iteration 3111, loss = 0.11848206\n",
      "Iteration 3112, loss = 0.10927594\n",
      "Iteration 3113, loss = 0.11145742\n",
      "Iteration 3114, loss = 0.11130807\n",
      "Iteration 3115, loss = 0.12287826\n",
      "Iteration 3116, loss = 0.11102786\n",
      "Iteration 3117, loss = 0.10983997\n",
      "Iteration 3118, loss = 0.12007554\n",
      "Iteration 3119, loss = 0.12817436\n",
      "Iteration 3120, loss = 0.11325977\n",
      "Iteration 3121, loss = 0.10854470\n",
      "Iteration 3122, loss = 0.11524106\n",
      "Iteration 3123, loss = 0.11178748\n",
      "Iteration 3124, loss = 0.12402043\n",
      "Iteration 3125, loss = 0.11442484\n",
      "Iteration 3126, loss = 0.12374506\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 3127, loss = 0.10570272\n",
      "Iteration 3128, loss = 0.11372946\n",
      "Iteration 3129, loss = 0.10778778\n",
      "Iteration 3130, loss = 0.11441282\n",
      "Iteration 3131, loss = 0.12739169\n",
      "Iteration 3132, loss = 0.11566706\n",
      "Iteration 3133, loss = 0.11796775\n",
      "Iteration 3134, loss = 0.12168288\n",
      "Iteration 3135, loss = 0.11660752\n",
      "Iteration 3136, loss = 0.12297973\n",
      "Iteration 3137, loss = 0.11786401\n",
      "Iteration 3138, loss = 0.11742651\n",
      "Iteration 3139, loss = 0.11414092\n",
      "Iteration 3140, loss = 0.11300775\n",
      "Iteration 3141, loss = 0.10212285\n",
      "Iteration 3142, loss = 0.11838154\n",
      "Iteration 3143, loss = 0.10643599\n",
      "Iteration 3144, loss = 0.11296695\n",
      "Iteration 3145, loss = 0.12679118\n",
      "Iteration 3146, loss = 0.12751926\n",
      "Iteration 3147, loss = 0.14977335\n",
      "Iteration 3148, loss = 0.11170496\n",
      "Iteration 3149, loss = 0.12313166\n",
      "Iteration 3150, loss = 0.11331074\n",
      "Iteration 3151, loss = 0.12448709\n",
      "Iteration 3152, loss = 0.11600312\n",
      "Iteration 3153, loss = 0.12068439\n",
      "Iteration 3154, loss = 0.12653290\n",
      "Iteration 3155, loss = 0.12847841\n",
      "Iteration 3156, loss = 0.12882511\n",
      "Iteration 3157, loss = 0.14091085\n",
      "Iteration 3158, loss = 0.15103627\n",
      "Iteration 3159, loss = 0.13446400\n",
      "Iteration 3160, loss = 0.13203577\n",
      "Iteration 3161, loss = 0.11163411\n",
      "Iteration 3162, loss = 0.14181141\n",
      "Iteration 3163, loss = 0.12676360\n",
      "Iteration 3164, loss = 0.11657866\n",
      "Iteration 3165, loss = 0.13085762\n",
      "Iteration 3166, loss = 0.12535452\n",
      "Iteration 3167, loss = 0.12121565\n",
      "Iteration 3168, loss = 0.12970114\n",
      "Iteration 3169, loss = 0.11511273\n",
      "Iteration 3170, loss = 0.15024568\n",
      "Iteration 3171, loss = 0.11530604\n",
      "Iteration 3172, loss = 0.15243758\n",
      "Iteration 3173, loss = 0.17772385\n",
      "Iteration 3174, loss = 0.25720555\n",
      "Iteration 3175, loss = 0.16577773\n",
      "Iteration 3176, loss = 0.19701657\n",
      "Iteration 3177, loss = 0.19152754\n",
      "Iteration 3178, loss = 0.15370477\n",
      "Iteration 3179, loss = 0.13432324\n",
      "Iteration 3180, loss = 0.11040421\n",
      "Iteration 3181, loss = 0.12440773\n",
      "Iteration 3182, loss = 0.11510308\n",
      "Iteration 3183, loss = 0.11407288\n",
      "Iteration 3184, loss = 0.13654611\n",
      "Iteration 3185, loss = 0.12250445\n",
      "Iteration 3186, loss = 0.13260931\n",
      "Iteration 3187, loss = 0.13070297\n",
      "Iteration 3188, loss = 0.11710264\n",
      "Iteration 3189, loss = 0.13857763\n",
      "Iteration 3190, loss = 0.12567706\n",
      "Iteration 3191, loss = 0.12439082\n",
      "Iteration 3192, loss = 0.21972822\n",
      "Iteration 3193, loss = 0.33517734\n",
      "Iteration 3194, loss = 0.27923119\n",
      "Iteration 3195, loss = 0.28303458\n",
      "Iteration 3196, loss = 0.91593499\n",
      "Iteration 3197, loss = 3.64103709\n",
      "Iteration 3198, loss = 4.86721743\n",
      "Iteration 3199, loss = 2.24598345\n",
      "Iteration 3200, loss = 1.25737671\n",
      "Iteration 3201, loss = 0.91929681\n",
      "Iteration 3202, loss = 0.90546669\n",
      "Iteration 3203, loss = 0.97112069\n",
      "Iteration 3204, loss = 0.97463775\n",
      "Iteration 3205, loss = 0.80450492\n",
      "Iteration 3206, loss = 1.38685430\n",
      "Iteration 3207, loss = 1.00312047\n",
      "Iteration 3208, loss = 1.19321092\n",
      "Iteration 3209, loss = 0.92665797\n",
      "Iteration 3210, loss = 1.22300170\n",
      "Iteration 3211, loss = 0.96457961\n",
      "Iteration 3212, loss = 0.75567571\n",
      "Iteration 3213, loss = 0.92553128\n",
      "Iteration 3214, loss = 0.66751021\n",
      "Iteration 3215, loss = 0.94441280\n",
      "Iteration 3216, loss = 0.92516511\n",
      "Iteration 3217, loss = 0.74068144\n",
      "Iteration 3218, loss = 0.65918239\n",
      "Iteration 3219, loss = 0.66834040\n",
      "Iteration 3220, loss = 0.71827087\n",
      "Iteration 3221, loss = 0.63510674\n",
      "Iteration 3222, loss = 0.82266177\n",
      "Iteration 3223, loss = 0.55254132\n",
      "Iteration 3224, loss = 0.61315691\n",
      "Iteration 3225, loss = 0.47922461\n",
      "Iteration 3226, loss = 0.39648059\n",
      "Iteration 3227, loss = 0.56483117\n",
      "Iteration 3228, loss = 0.60350143\n",
      "Iteration 3229, loss = 0.62467398\n",
      "Iteration 3230, loss = 0.54560210\n",
      "Iteration 3231, loss = 0.43566054\n",
      "Iteration 3232, loss = 0.45508309\n",
      "Iteration 3233, loss = 0.62488175\n",
      "Iteration 3234, loss = 0.40398582\n",
      "Iteration 3235, loss = 0.41246726\n",
      "Iteration 3236, loss = 0.31667841\n",
      "Iteration 3237, loss = 0.33771295\n",
      "Iteration 3238, loss = 0.27423799\n",
      "Iteration 3239, loss = 0.13941898\n",
      "Iteration 3240, loss = 0.12715072\n",
      "Iteration 3241, loss = 0.23924661\n",
      "Iteration 3242, loss = 0.31135030\n",
      "Iteration 3243, loss = 0.35542192\n",
      "Iteration 3244, loss = 0.33838366\n",
      "Iteration 3245, loss = 0.29457187\n",
      "Iteration 3246, loss = 0.35715714\n",
      "Iteration 3247, loss = 0.23048525\n",
      "Iteration 3248, loss = 0.26498615\n",
      "Iteration 3249, loss = 0.20745336\n",
      "Iteration 3250, loss = 0.13274002\n",
      "Iteration 3251, loss = 0.15958843\n",
      "Iteration 3252, loss = 0.32023393\n",
      "Iteration 3253, loss = 0.52353709\n",
      "Iteration 3254, loss = 0.41634350\n",
      "Iteration 3255, loss = 0.34607741\n",
      "Iteration 3256, loss = 0.23803622\n",
      "Iteration 3257, loss = 0.16162503\n",
      "Iteration 3258, loss = 0.31141379\n",
      "Iteration 3259, loss = 0.28066388\n",
      "Iteration 3260, loss = 0.29715755\n",
      "Iteration 3261, loss = 0.33003847\n",
      "Iteration 3262, loss = 0.18858671\n",
      "Iteration 3263, loss = 0.33318488\n",
      "Iteration 3264, loss = 0.19207765\n",
      "Iteration 3265, loss = 0.16393912\n",
      "Iteration 3266, loss = 0.12130989\n",
      "Iteration 3267, loss = 0.13310995\n",
      "Iteration 3268, loss = 0.12215459\n",
      "Iteration 3269, loss = 0.17018302\n",
      "Iteration 3270, loss = 0.12875301\n",
      "Iteration 3271, loss = 0.12586967\n",
      "Iteration 3272, loss = 0.12646740\n",
      "Iteration 3273, loss = 0.12429160\n",
      "Iteration 3274, loss = 0.11819669\n",
      "Iteration 3275, loss = 0.11831054\n",
      "Iteration 3276, loss = 0.11366217\n",
      "Iteration 3277, loss = 0.11007957\n",
      "Iteration 3278, loss = 0.13066218\n",
      "Iteration 3279, loss = 0.12592360\n",
      "Iteration 3280, loss = 0.13179287\n",
      "Iteration 3281, loss = 0.13251175\n",
      "Iteration 3282, loss = 0.16822124\n",
      "Iteration 3283, loss = 0.14536073\n",
      "Iteration 3284, loss = 0.16353655\n",
      "Iteration 3285, loss = 0.21887403\n",
      "Iteration 3286, loss = 0.13633191\n",
      "Iteration 3287, loss = 0.14368958\n",
      "Iteration 3288, loss = 0.13191197\n",
      "Iteration 3289, loss = 0.14284288\n",
      "Iteration 3290, loss = 0.11494525\n",
      "Iteration 3291, loss = 0.14524561\n",
      "Iteration 3292, loss = 0.13512715\n",
      "Iteration 3293, loss = 0.42882651\n",
      "Iteration 3294, loss = 0.32337277\n",
      "Iteration 3295, loss = 0.24391510\n",
      "Iteration 3296, loss = 0.21542684\n",
      "Iteration 3297, loss = 0.40154959\n",
      "Iteration 3298, loss = 0.21847724\n",
      "Iteration 3299, loss = 0.27951989\n",
      "Iteration 3300, loss = 0.26277856\n",
      "Iteration 3301, loss = 0.14459617\n",
      "Iteration 3302, loss = 0.16870178\n",
      "Iteration 3303, loss = 0.12742883\n",
      "Iteration 3304, loss = 0.11903235\n",
      "Iteration 3305, loss = 0.14204043\n",
      "Iteration 3306, loss = 0.11119165\n",
      "Iteration 3307, loss = 0.11415768\n",
      "Iteration 3308, loss = 0.12682074\n",
      "Iteration 3309, loss = 0.10588903\n",
      "Iteration 3310, loss = 0.11381414\n",
      "Iteration 3311, loss = 0.16631956\n",
      "Iteration 3312, loss = 0.28038163\n",
      "Iteration 3313, loss = 0.15468589\n",
      "Iteration 3314, loss = 0.16359132\n",
      "Iteration 3315, loss = 0.18144580\n",
      "Iteration 3316, loss = 0.18614587\n",
      "Iteration 3317, loss = 0.12112316\n",
      "Iteration 3318, loss = 0.11682530\n",
      "Iteration 3319, loss = 0.11203732\n",
      "Iteration 3320, loss = 0.10952440\n",
      "Iteration 3321, loss = 0.13011236\n",
      "Iteration 3322, loss = 0.12098647\n",
      "Iteration 3323, loss = 0.14772429\n",
      "Iteration 3324, loss = 0.21026920\n",
      "Iteration 3325, loss = 0.14860877\n",
      "Iteration 3326, loss = 0.13665206\n",
      "Iteration 3327, loss = 0.11451323\n",
      "Iteration 3328, loss = 0.12891720\n",
      "Iteration 3329, loss = 0.14049484\n",
      "Iteration 3330, loss = 0.11246929\n",
      "Iteration 3331, loss = 0.11014530\n",
      "Iteration 3332, loss = 0.13265062\n",
      "Iteration 3333, loss = 0.13656108\n",
      "Iteration 3334, loss = 0.13200797\n",
      "Iteration 3335, loss = 0.15939365\n",
      "Iteration 3336, loss = 0.17004160\n",
      "Iteration 3337, loss = 0.35731844\n",
      "Iteration 3338, loss = 0.16963683\n",
      "Iteration 3339, loss = 0.15308422\n",
      "Iteration 3340, loss = 0.12887867\n",
      "Iteration 3341, loss = 0.11802561\n",
      "Iteration 3342, loss = 0.10858322\n",
      "Iteration 3343, loss = 0.10750905\n",
      "Iteration 3344, loss = 0.11421693\n",
      "Iteration 3345, loss = 0.12243513\n",
      "Iteration 3346, loss = 0.12573267\n",
      "Iteration 3347, loss = 0.12000296\n",
      "Iteration 3348, loss = 0.13598014\n",
      "Iteration 3349, loss = 0.13259764\n",
      "Iteration 3350, loss = 0.15507170\n",
      "Iteration 3351, loss = 0.13222985\n",
      "Iteration 3352, loss = 0.11611506\n",
      "Iteration 3353, loss = 0.10567225\n",
      "Iteration 3354, loss = 0.11037077\n",
      "Iteration 3355, loss = 0.10451033\n",
      "Iteration 3356, loss = 0.10922599\n",
      "Iteration 3357, loss = 0.11101739\n",
      "Iteration 3358, loss = 0.10995526\n",
      "Iteration 3359, loss = 0.10324697\n",
      "Iteration 3360, loss = 0.12944331\n",
      "Iteration 3361, loss = 0.13951563\n",
      "Iteration 3362, loss = 0.14330277\n",
      "Iteration 3363, loss = 0.12350324\n",
      "Iteration 3364, loss = 0.11204473\n",
      "Iteration 3365, loss = 0.12986808\n",
      "Iteration 3366, loss = 0.10779649\n",
      "Iteration 3367, loss = 0.10322310\n",
      "Iteration 3368, loss = 0.13897371\n",
      "Iteration 3369, loss = 0.16932838\n",
      "Iteration 3370, loss = 0.18755340\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 3371, loss = 0.27988960\n",
      "Iteration 3372, loss = 0.15330552\n",
      "Iteration 3373, loss = 0.17539021\n",
      "Iteration 3374, loss = 0.12427907\n",
      "Iteration 3375, loss = 0.10922173\n",
      "Iteration 3376, loss = 0.11376395\n",
      "Iteration 3377, loss = 0.14229787\n",
      "Iteration 3378, loss = 0.12803051\n",
      "Iteration 3379, loss = 0.14406568\n",
      "Iteration 3380, loss = 0.32387730\n",
      "Iteration 3381, loss = 0.22296882\n",
      "Iteration 3382, loss = 0.40418211\n",
      "Iteration 3383, loss = 0.26185287\n",
      "Iteration 3384, loss = 0.17058314\n",
      "Iteration 3385, loss = 0.16462243\n",
      "Iteration 3386, loss = 0.15276742\n",
      "Iteration 3387, loss = 0.11254720\n",
      "Iteration 3388, loss = 0.11355113\n",
      "Iteration 3389, loss = 0.10460916\n",
      "Iteration 3390, loss = 0.11536473\n",
      "Iteration 3391, loss = 0.13044638\n",
      "Iteration 3392, loss = 0.10996699\n",
      "Iteration 3393, loss = 0.11620853\n",
      "Iteration 3394, loss = 0.10946095\n",
      "Iteration 3395, loss = 0.11197487\n",
      "Iteration 3396, loss = 0.11614040\n",
      "Iteration 3397, loss = 0.11614046\n",
      "Iteration 3398, loss = 0.10615534\n",
      "Iteration 3399, loss = 0.12006200\n",
      "Iteration 3400, loss = 0.11458479\n",
      "Iteration 3401, loss = 0.12139748\n",
      "Iteration 3402, loss = 0.12510325\n",
      "Iteration 3403, loss = 0.11754646\n",
      "Iteration 3404, loss = 0.15856910\n",
      "Iteration 3405, loss = 0.13826850\n",
      "Iteration 3406, loss = 0.13367672\n",
      "Iteration 3407, loss = 0.14054871\n",
      "Iteration 3408, loss = 0.11679610\n",
      "Iteration 3409, loss = 0.14283644\n",
      "Iteration 3410, loss = 0.13558333\n",
      "Iteration 3411, loss = 0.11610079\n",
      "Iteration 3412, loss = 0.12567969\n",
      "Iteration 3413, loss = 0.11647211\n",
      "Iteration 3414, loss = 0.11828595\n",
      "Iteration 3415, loss = 0.11671017\n",
      "Iteration 3416, loss = 0.11626997\n",
      "Iteration 3417, loss = 0.11224183\n",
      "Iteration 3418, loss = 0.10590048\n",
      "Iteration 3419, loss = 0.16349591\n",
      "Iteration 3420, loss = 0.11621232\n",
      "Iteration 3421, loss = 0.11833218\n",
      "Iteration 3422, loss = 0.13172401\n",
      "Iteration 3423, loss = 0.12310572\n",
      "Iteration 3424, loss = 0.11762487\n",
      "Iteration 3425, loss = 0.12454380\n",
      "Iteration 3426, loss = 0.11754136\n",
      "Iteration 3427, loss = 0.11754605\n",
      "Iteration 3428, loss = 0.11051407\n",
      "Iteration 3429, loss = 0.11120916\n",
      "Iteration 3430, loss = 0.11540652\n",
      "Iteration 3431, loss = 0.14301381\n",
      "Iteration 3432, loss = 0.11478753\n",
      "Iteration 3433, loss = 0.11425930\n",
      "Iteration 3434, loss = 0.12584280\n",
      "Iteration 3435, loss = 0.12707720\n",
      "Iteration 3436, loss = 0.11398451\n",
      "Iteration 3437, loss = 0.10859244\n",
      "Iteration 3438, loss = 0.10798054\n",
      "Iteration 3439, loss = 0.12190592\n",
      "Iteration 3440, loss = 0.14434641\n",
      "Iteration 3441, loss = 0.17180354\n",
      "Iteration 3442, loss = 0.14244349\n",
      "Iteration 3443, loss = 0.12279615\n",
      "Iteration 3444, loss = 0.10765360\n",
      "Iteration 3445, loss = 0.10426617\n",
      "Iteration 3446, loss = 0.10433023\n",
      "Iteration 3447, loss = 0.10934235\n",
      "Iteration 3448, loss = 0.11495935\n",
      "Iteration 3449, loss = 0.11270208\n",
      "Iteration 3450, loss = 0.10804398\n",
      "Iteration 3451, loss = 0.10363540\n",
      "Iteration 3452, loss = 0.12338776\n",
      "Iteration 3453, loss = 0.11681748\n",
      "Iteration 3454, loss = 0.11153380\n",
      "Iteration 3455, loss = 0.11815509\n",
      "Iteration 3456, loss = 0.10431997\n",
      "Iteration 3457, loss = 0.11421970\n",
      "Iteration 3458, loss = 0.10380707\n",
      "Iteration 3459, loss = 0.12551904\n",
      "Iteration 3460, loss = 0.12209470\n",
      "Iteration 3461, loss = 0.10349280\n",
      "Iteration 3462, loss = 0.10566694\n",
      "Iteration 3463, loss = 0.10644472\n",
      "Iteration 3464, loss = 0.11248089\n",
      "Iteration 3465, loss = 0.12123552\n",
      "Iteration 3466, loss = 0.13699221\n",
      "Iteration 3467, loss = 0.11521338\n",
      "Iteration 3468, loss = 0.11283429\n",
      "Iteration 3469, loss = 0.12447093\n",
      "Iteration 3470, loss = 0.11520164\n",
      "Iteration 3471, loss = 0.10862547\n",
      "Iteration 3472, loss = 0.10329460\n",
      "Iteration 3473, loss = 0.10721628\n",
      "Iteration 3474, loss = 0.11373475\n",
      "Iteration 3475, loss = 0.12973697\n",
      "Iteration 3476, loss = 0.10809408\n",
      "Iteration 3477, loss = 0.11131363\n",
      "Iteration 3478, loss = 0.10545164\n",
      "Iteration 3479, loss = 0.10692471\n",
      "Iteration 3480, loss = 0.11410464\n",
      "Iteration 3481, loss = 0.10683408\n",
      "Iteration 3482, loss = 0.10786834\n",
      "Iteration 3483, loss = 0.11032943\n",
      "Iteration 3484, loss = 0.13313586\n",
      "Iteration 3485, loss = 0.10214207\n",
      "Iteration 3486, loss = 0.10910391\n",
      "Iteration 3487, loss = 0.10332962\n",
      "Iteration 3488, loss = 0.10342828\n",
      "Iteration 3489, loss = 0.11269860\n",
      "Iteration 3490, loss = 0.10636709\n",
      "Iteration 3491, loss = 0.10825747\n",
      "Iteration 3492, loss = 0.10648144\n",
      "Iteration 3493, loss = 0.13065926\n",
      "Iteration 3494, loss = 0.11572527\n",
      "Iteration 3495, loss = 0.12145834\n",
      "Iteration 3496, loss = 0.11368543\n",
      "Iteration 3497, loss = 0.12216875\n",
      "Iteration 3498, loss = 0.11406662\n",
      "Iteration 3499, loss = 0.11303314\n",
      "Iteration 3500, loss = 0.11501494\n",
      "Iteration 3501, loss = 0.11369154\n",
      "Iteration 3502, loss = 0.12100004\n",
      "Iteration 3503, loss = 0.10907529\n",
      "Iteration 3504, loss = 0.12354983\n",
      "Iteration 3505, loss = 0.12731462\n",
      "Iteration 3506, loss = 0.19263296\n",
      "Iteration 3507, loss = 0.30294991\n",
      "Iteration 3508, loss = 0.19375792\n",
      "Iteration 3509, loss = 0.38245319\n",
      "Iteration 3510, loss = 0.25453930\n",
      "Iteration 3511, loss = 0.25941488\n",
      "Iteration 3512, loss = 0.44844280\n",
      "Iteration 3513, loss = 0.30362698\n",
      "Iteration 3514, loss = 0.16095456\n",
      "Iteration 3515, loss = 0.13032927\n",
      "Iteration 3516, loss = 0.12485165\n",
      "Iteration 3517, loss = 0.12659385\n",
      "Iteration 3518, loss = 0.11950934\n",
      "Iteration 3519, loss = 0.11366331\n",
      "Iteration 3520, loss = 0.12150339\n",
      "Iteration 3521, loss = 0.11404556\n",
      "Iteration 3522, loss = 0.10223354\n",
      "Iteration 3523, loss = 0.10583852\n",
      "Iteration 3524, loss = 0.10984659\n",
      "Iteration 3525, loss = 0.10997779\n",
      "Iteration 3526, loss = 0.10421971\n",
      "Iteration 3527, loss = 0.10858508\n",
      "Iteration 3528, loss = 0.10684442\n",
      "Iteration 3529, loss = 0.11229862\n",
      "Iteration 3530, loss = 0.11228555\n",
      "Iteration 3531, loss = 0.12618110\n",
      "Iteration 3532, loss = 0.10189610\n",
      "Iteration 3533, loss = 0.11207546\n",
      "Iteration 3534, loss = 0.11017902\n",
      "Iteration 3535, loss = 0.12093907\n",
      "Iteration 3536, loss = 0.12214488\n",
      "Iteration 3537, loss = 0.10940316\n",
      "Iteration 3538, loss = 0.13205402\n",
      "Iteration 3539, loss = 0.10749144\n",
      "Iteration 3540, loss = 0.10686123\n",
      "Iteration 3541, loss = 0.10893216\n",
      "Iteration 3542, loss = 0.10466175\n",
      "Iteration 3543, loss = 0.10768982\n",
      "Iteration 3544, loss = 0.11350675\n",
      "Iteration 3545, loss = 0.13673861\n",
      "Iteration 3546, loss = 0.14557119\n",
      "Iteration 3547, loss = 0.12379071\n",
      "Iteration 3548, loss = 0.13369624\n",
      "Iteration 3549, loss = 0.11592364\n",
      "Iteration 3550, loss = 0.11708433\n",
      "Iteration 3551, loss = 0.11687941\n",
      "Iteration 3552, loss = 0.10988479\n",
      "Iteration 3553, loss = 0.10665681\n",
      "Iteration 3554, loss = 0.10925623\n",
      "Iteration 3555, loss = 0.10510314\n",
      "Iteration 3556, loss = 0.10461819\n",
      "Iteration 3557, loss = 0.10557924\n",
      "Iteration 3558, loss = 0.10788349\n",
      "Iteration 3559, loss = 0.11450929\n",
      "Iteration 3560, loss = 0.15403652\n",
      "Iteration 3561, loss = 0.11248146\n",
      "Iteration 3562, loss = 0.11254912\n",
      "Iteration 3563, loss = 0.10738175\n",
      "Iteration 3564, loss = 0.10644675\n",
      "Iteration 3565, loss = 0.10633573\n",
      "Iteration 3566, loss = 0.12343363\n",
      "Iteration 3567, loss = 0.11207152\n",
      "Iteration 3568, loss = 0.11261946\n",
      "Iteration 3569, loss = 0.10998113\n",
      "Iteration 3570, loss = 0.11778659\n",
      "Iteration 3571, loss = 0.11205214\n",
      "Iteration 3572, loss = 0.10883601\n",
      "Iteration 3573, loss = 0.11178160\n",
      "Iteration 3574, loss = 0.12231283\n",
      "Iteration 3575, loss = 0.10393891\n",
      "Iteration 3576, loss = 0.11278310\n",
      "Iteration 3577, loss = 0.10865821\n",
      "Iteration 3578, loss = 0.10558107\n",
      "Iteration 3579, loss = 0.10632042\n",
      "Iteration 3580, loss = 0.10889541\n",
      "Iteration 3581, loss = 0.10922028\n",
      "Iteration 3582, loss = 0.10677248\n",
      "Iteration 3583, loss = 0.11885854\n",
      "Iteration 3584, loss = 0.11829142\n",
      "Iteration 3585, loss = 0.11076481\n",
      "Iteration 3586, loss = 0.11351911\n",
      "Iteration 3587, loss = 0.11305432\n",
      "Iteration 3588, loss = 0.11091227\n",
      "Iteration 3589, loss = 0.10678209\n",
      "Iteration 3590, loss = 0.10253858\n",
      "Iteration 3591, loss = 0.10717393\n",
      "Iteration 3592, loss = 0.10670734\n",
      "Iteration 3593, loss = 0.11163467\n",
      "Iteration 3594, loss = 0.11210709\n",
      "Iteration 3595, loss = 0.10989126\n",
      "Iteration 3596, loss = 0.12060710\n",
      "Iteration 3597, loss = 0.11320160\n",
      "Iteration 3598, loss = 0.10840132\n",
      "Iteration 3599, loss = 0.10746145\n",
      "Iteration 3600, loss = 0.10401026\n",
      "Iteration 3601, loss = 0.10429010\n",
      "Iteration 3602, loss = 0.11096111\n",
      "Iteration 3603, loss = 0.11466882\n",
      "Iteration 3604, loss = 0.10385351\n",
      "Iteration 3605, loss = 0.10811152\n",
      "Iteration 3606, loss = 0.11280168\n",
      "Iteration 3607, loss = 0.13235607\n",
      "Iteration 3608, loss = 0.11327789\n",
      "Iteration 3609, loss = 0.12495551\n",
      "Iteration 3610, loss = 0.12068292\n",
      "Iteration 3611, loss = 0.11975125\n",
      "Iteration 3612, loss = 0.12068438\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 3613, loss = 0.14308710\n",
      "Iteration 3614, loss = 0.13111624\n",
      "Iteration 3615, loss = 0.12796521\n",
      "Iteration 3616, loss = 0.15030504\n",
      "Iteration 3617, loss = 0.13970228\n",
      "Iteration 3618, loss = 0.11343307\n",
      "Iteration 3619, loss = 0.12572371\n",
      "Iteration 3620, loss = 0.15362489\n",
      "Iteration 3621, loss = 0.16999986\n",
      "Iteration 3622, loss = 0.13316831\n",
      "Iteration 3623, loss = 0.13763628\n",
      "Iteration 3624, loss = 0.15702361\n",
      "Iteration 3625, loss = 0.12725351\n",
      "Iteration 3626, loss = 0.14632628\n",
      "Iteration 3627, loss = 0.13772765\n",
      "Iteration 3628, loss = 0.20409169\n",
      "Iteration 3629, loss = 0.19963516\n",
      "Iteration 3630, loss = 0.18871135\n",
      "Iteration 3631, loss = 0.14512638\n",
      "Iteration 3632, loss = 0.13447971\n",
      "Iteration 3633, loss = 0.11925860\n",
      "Iteration 3634, loss = 0.11511430\n",
      "Iteration 3635, loss = 0.12655596\n",
      "Iteration 3636, loss = 0.11880121\n",
      "Iteration 3637, loss = 0.11111733\n",
      "Iteration 3638, loss = 0.11559773\n",
      "Iteration 3639, loss = 0.14105646\n",
      "Iteration 3640, loss = 0.15910883\n",
      "Iteration 3641, loss = 0.15801048\n",
      "Iteration 3642, loss = 0.12327912\n",
      "Iteration 3643, loss = 0.13439365\n",
      "Iteration 3644, loss = 0.14503533\n",
      "Iteration 3645, loss = 0.13803046\n",
      "Iteration 3646, loss = 0.11757889\n",
      "Iteration 3647, loss = 0.10893173\n",
      "Iteration 3648, loss = 0.10489145\n",
      "Iteration 3649, loss = 0.10576979\n",
      "Iteration 3650, loss = 0.10698525\n",
      "Iteration 3651, loss = 0.11065300\n",
      "Iteration 3652, loss = 0.11279776\n",
      "Iteration 3653, loss = 0.10585471\n",
      "Iteration 3654, loss = 0.11335584\n",
      "Iteration 3655, loss = 0.11025294\n",
      "Iteration 3656, loss = 0.11143763\n",
      "Iteration 3657, loss = 0.12774726\n",
      "Iteration 3658, loss = 0.11964360\n",
      "Iteration 3659, loss = 0.13609558\n",
      "Iteration 3660, loss = 0.15140424\n",
      "Iteration 3661, loss = 0.12511224\n",
      "Iteration 3662, loss = 0.12366197\n",
      "Iteration 3663, loss = 0.11218267\n",
      "Iteration 3664, loss = 0.10882736\n",
      "Iteration 3665, loss = 0.11151685\n",
      "Iteration 3666, loss = 0.12559411\n",
      "Iteration 3667, loss = 0.13319185\n",
      "Iteration 3668, loss = 0.11518570\n",
      "Iteration 3669, loss = 0.10562947\n",
      "Iteration 3670, loss = 0.12411661\n",
      "Iteration 3671, loss = 0.11405774\n",
      "Iteration 3672, loss = 0.10447365\n",
      "Iteration 3673, loss = 0.11438754\n",
      "Iteration 3674, loss = 0.11776450\n",
      "Iteration 3675, loss = 0.10575121\n",
      "Iteration 3676, loss = 0.12269554\n",
      "Iteration 3677, loss = 0.13950102\n",
      "Iteration 3678, loss = 0.11613372\n",
      "Iteration 3679, loss = 0.12364664\n",
      "Iteration 3680, loss = 0.10883252\n",
      "Iteration 3681, loss = 0.10561066\n",
      "Iteration 3682, loss = 0.11453851\n",
      "Iteration 3683, loss = 0.10727701\n",
      "Iteration 3684, loss = 0.11057082\n",
      "Iteration 3685, loss = 0.11202198\n",
      "Iteration 3686, loss = 0.11371381\n",
      "Iteration 3687, loss = 0.11114962\n",
      "Iteration 3688, loss = 0.11897828\n",
      "Iteration 3689, loss = 0.11230847\n",
      "Iteration 3690, loss = 0.10324480\n",
      "Iteration 3691, loss = 0.12733556\n",
      "Iteration 3692, loss = 0.11131090\n",
      "Iteration 3693, loss = 0.11119326\n",
      "Iteration 3694, loss = 0.10657758\n",
      "Iteration 3695, loss = 0.10987893\n",
      "Iteration 3696, loss = 0.10721537\n",
      "Iteration 3697, loss = 0.10364126\n",
      "Iteration 3698, loss = 0.10711484\n",
      "Iteration 3699, loss = 0.10530368\n",
      "Iteration 3700, loss = 0.11273111\n",
      "Iteration 3701, loss = 0.11189898\n",
      "Iteration 3702, loss = 0.11802021\n",
      "Iteration 3703, loss = 0.12175365\n",
      "Iteration 3704, loss = 0.17212777\n",
      "Iteration 3705, loss = 0.11730131\n",
      "Iteration 3706, loss = 0.15392954\n",
      "Iteration 3707, loss = 0.20119455\n",
      "Iteration 3708, loss = 0.28502766\n",
      "Iteration 3709, loss = 0.42258523\n",
      "Iteration 3710, loss = 0.58139113\n",
      "Iteration 3711, loss = 0.65676519\n",
      "Iteration 3712, loss = 0.54608972\n",
      "Iteration 3713, loss = 0.89075323\n",
      "Iteration 3714, loss = 1.94774841\n",
      "Iteration 3715, loss = 1.15798766\n",
      "Iteration 3716, loss = 0.94903062\n",
      "Iteration 3717, loss = 1.35622865\n",
      "Iteration 3718, loss = 1.04510727\n",
      "Iteration 3719, loss = 1.13712551\n",
      "Iteration 3720, loss = 0.67601829\n",
      "Iteration 3721, loss = 0.70390023\n",
      "Iteration 3722, loss = 0.74404443\n",
      "Iteration 3723, loss = 0.57644880\n",
      "Iteration 3724, loss = 0.73471644\n",
      "Iteration 3725, loss = 0.53593441\n",
      "Iteration 3726, loss = 0.41304370\n",
      "Iteration 3727, loss = 0.23974371\n",
      "Iteration 3728, loss = 0.29839261\n",
      "Iteration 3729, loss = 0.43076464\n",
      "Iteration 3730, loss = 0.28502897\n",
      "Iteration 3731, loss = 0.15601349\n",
      "Iteration 3732, loss = 0.22204982\n",
      "Iteration 3733, loss = 0.26217562\n",
      "Iteration 3734, loss = 0.22525430\n",
      "Iteration 3735, loss = 0.18840968\n",
      "Iteration 3736, loss = 0.22101541\n",
      "Iteration 3737, loss = 0.35136199\n",
      "Iteration 3738, loss = 0.53667815\n",
      "Iteration 3739, loss = 0.29422550\n",
      "Iteration 3740, loss = 0.36569381\n",
      "Iteration 3741, loss = 1.23133481\n",
      "Iteration 3742, loss = 0.79869283\n",
      "Iteration 3743, loss = 0.71883949\n",
      "Iteration 3744, loss = 0.71784974\n",
      "Iteration 3745, loss = 0.64425621\n",
      "Iteration 3746, loss = 0.59034776\n",
      "Iteration 3747, loss = 1.23009654\n",
      "Iteration 3748, loss = 1.02449211\n",
      "Iteration 3749, loss = 0.88148533\n",
      "Iteration 3750, loss = 0.51075917\n",
      "Iteration 3751, loss = 0.87470390\n",
      "Iteration 3752, loss = 1.28085342\n",
      "Iteration 3753, loss = 0.86702656\n",
      "Iteration 3754, loss = 0.59349490\n",
      "Iteration 3755, loss = 0.71697297\n",
      "Iteration 3756, loss = 0.55530296\n",
      "Iteration 3757, loss = 0.33214016\n",
      "Iteration 3758, loss = 0.57748033\n",
      "Iteration 3759, loss = 0.65941799\n",
      "Iteration 3760, loss = 0.65061214\n",
      "Iteration 3761, loss = 0.68346945\n",
      "Iteration 3762, loss = 0.52313302\n",
      "Iteration 3763, loss = 0.44211250\n",
      "Iteration 3764, loss = 0.45964281\n",
      "Iteration 3765, loss = 0.46206230\n",
      "Iteration 3766, loss = 0.21246465\n",
      "Iteration 3767, loss = 0.17666735\n",
      "Iteration 3768, loss = 0.13980651\n",
      "Iteration 3769, loss = 0.13485155\n",
      "Iteration 3770, loss = 0.11838420\n",
      "Iteration 3771, loss = 0.14305021\n",
      "Iteration 3772, loss = 0.11379304\n",
      "Iteration 3773, loss = 0.11138025\n",
      "Iteration 3774, loss = 0.11936363\n",
      "Iteration 3775, loss = 0.15128704\n",
      "Iteration 3776, loss = 0.12661553\n",
      "Iteration 3777, loss = 0.11736672\n",
      "Iteration 3778, loss = 0.11725084\n",
      "Iteration 3779, loss = 0.12097142\n",
      "Iteration 3780, loss = 0.11916124\n",
      "Iteration 3781, loss = 0.12066010\n",
      "Iteration 3782, loss = 0.12893475\n",
      "Iteration 3783, loss = 0.13913985\n",
      "Iteration 3784, loss = 0.11491174\n",
      "Iteration 3785, loss = 0.12522553\n",
      "Iteration 3786, loss = 0.12630150\n",
      "Iteration 3787, loss = 0.11524537\n",
      "Iteration 3788, loss = 0.11850155\n",
      "Iteration 3789, loss = 0.11074239\n",
      "Iteration 3790, loss = 0.11884934\n",
      "Iteration 3791, loss = 0.11142568\n",
      "Iteration 3792, loss = 0.10943310\n",
      "Iteration 3793, loss = 0.11823270\n",
      "Iteration 3794, loss = 0.12039968\n",
      "Iteration 3795, loss = 0.12626669\n",
      "Iteration 3796, loss = 0.10984355\n",
      "Iteration 3797, loss = 0.10740759\n",
      "Iteration 3798, loss = 0.10594344\n",
      "Iteration 3799, loss = 0.11443340\n",
      "Iteration 3800, loss = 0.11953828\n",
      "Iteration 3801, loss = 0.12115054\n",
      "Iteration 3802, loss = 0.11077401\n",
      "Iteration 3803, loss = 0.11216942\n",
      "Iteration 3804, loss = 0.13139320\n",
      "Iteration 3805, loss = 0.11449826\n",
      "Iteration 3806, loss = 0.11341224\n",
      "Iteration 3807, loss = 0.10773502\n",
      "Iteration 3808, loss = 0.10823663\n",
      "Iteration 3809, loss = 0.10918861\n",
      "Iteration 3810, loss = 0.10503778\n",
      "Iteration 3811, loss = 0.10823847\n",
      "Iteration 3812, loss = 0.10763067\n",
      "Iteration 3813, loss = 0.10524120\n",
      "Iteration 3814, loss = 0.11714379\n",
      "Iteration 3815, loss = 0.11264431\n",
      "Iteration 3816, loss = 0.11750455\n",
      "Iteration 3817, loss = 0.10535070\n",
      "Iteration 3818, loss = 0.10934922\n",
      "Iteration 3819, loss = 0.09977467\n",
      "Iteration 3820, loss = 0.11489986\n",
      "Iteration 3821, loss = 0.11848005\n",
      "Iteration 3822, loss = 0.11688251\n",
      "Iteration 3823, loss = 0.10897879\n",
      "Iteration 3824, loss = 0.11367628\n",
      "Iteration 3825, loss = 0.12826119\n",
      "Iteration 3826, loss = 0.10706255\n",
      "Iteration 3827, loss = 0.11361281\n",
      "Iteration 3828, loss = 0.11208626\n",
      "Iteration 3829, loss = 0.11174261\n",
      "Iteration 3830, loss = 0.10484113\n",
      "Iteration 3831, loss = 0.10619719\n",
      "Iteration 3832, loss = 0.11554891\n",
      "Iteration 3833, loss = 0.11536655\n",
      "Iteration 3834, loss = 0.10701326\n",
      "Iteration 3835, loss = 0.10466999\n",
      "Iteration 3836, loss = 0.10700871\n",
      "Iteration 3837, loss = 0.10785295\n",
      "Iteration 3838, loss = 0.11277717\n",
      "Iteration 3839, loss = 0.12521459\n",
      "Iteration 3840, loss = 0.10880581\n",
      "Iteration 3841, loss = 0.10932964\n",
      "Iteration 3842, loss = 0.10738583\n",
      "Iteration 3843, loss = 0.10408586\n",
      "Iteration 3844, loss = 0.10485409\n",
      "Iteration 3845, loss = 0.10520893\n",
      "Iteration 3846, loss = 0.11174600\n",
      "Iteration 3847, loss = 0.10601840\n",
      "Iteration 3848, loss = 0.11281817\n",
      "Iteration 3849, loss = 0.11841815\n",
      "Iteration 3850, loss = 0.11888336\n",
      "Iteration 3851, loss = 0.12954457\n",
      "Iteration 3852, loss = 0.12748977\n",
      "Iteration 3853, loss = 0.11329532\n",
      "Iteration 3854, loss = 0.10518980\n",
      "Iteration 3855, loss = 0.10356417\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 3856, loss = 0.10853560\n",
      "Iteration 3857, loss = 0.10649308\n",
      "Iteration 3858, loss = 0.10427729\n",
      "Iteration 3859, loss = 0.10464779\n",
      "Iteration 3860, loss = 0.10592975\n",
      "Iteration 3861, loss = 0.10546195\n",
      "Iteration 3862, loss = 0.10495408\n",
      "Iteration 3863, loss = 0.10540241\n",
      "Iteration 3864, loss = 0.10915685\n",
      "Iteration 3865, loss = 0.10413405\n",
      "Iteration 3866, loss = 0.10744033\n",
      "Iteration 3867, loss = 0.10232381\n",
      "Iteration 3868, loss = 0.10564815\n",
      "Iteration 3869, loss = 0.10702440\n",
      "Iteration 3870, loss = 0.10847256\n",
      "Iteration 3871, loss = 0.10552468\n",
      "Iteration 3872, loss = 0.11193946\n",
      "Iteration 3873, loss = 0.10724600\n",
      "Iteration 3874, loss = 0.10315093\n",
      "Iteration 3875, loss = 0.10893772\n",
      "Iteration 3876, loss = 0.10059060\n",
      "Iteration 3877, loss = 0.12140672\n",
      "Iteration 3878, loss = 0.11020185\n",
      "Iteration 3879, loss = 0.10284752\n",
      "Iteration 3880, loss = 0.11248887\n",
      "Iteration 3881, loss = 0.11358811\n",
      "Iteration 3882, loss = 0.11359480\n",
      "Iteration 3883, loss = 0.12156486\n",
      "Iteration 3884, loss = 0.10326694\n",
      "Iteration 3885, loss = 0.11020211\n",
      "Iteration 3886, loss = 0.11120598\n",
      "Iteration 3887, loss = 0.10734774\n",
      "Iteration 3888, loss = 0.11031815\n",
      "Iteration 3889, loss = 0.10653209\n",
      "Iteration 3890, loss = 0.10473208\n",
      "Iteration 3891, loss = 0.11507194\n",
      "Iteration 3892, loss = 0.10652663\n",
      "Iteration 3893, loss = 0.11348734\n",
      "Iteration 3894, loss = 0.10101083\n",
      "Iteration 3895, loss = 0.14081044\n",
      "Iteration 3896, loss = 0.11274961\n",
      "Iteration 3897, loss = 0.12681014\n",
      "Iteration 3898, loss = 0.12442701\n",
      "Iteration 3899, loss = 0.11389450\n",
      "Iteration 3900, loss = 0.12277293\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No handles with labels found to put in legend.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall Accuracy of svm model is: 96.0\n",
      "\n",
      "Per-Class Accuracy\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           2       0.98      0.96      0.97       101\n",
      "           4       0.90      0.95      0.92        39\n",
      "\n",
      "   micro avg       0.96      0.96      0.96       140\n",
      "   macro avg       0.94      0.95      0.95       140\n",
      "weighted avg       0.96      0.96      0.96       140\n",
      "\n",
      "\n",
      "Confusion matrix\n",
      "[[97  4]\n",
      " [ 2 37]]\n",
      "classification error = 4.285714285714278\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x648 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No handles with labels found to put in legend.\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZIAAAEWCAYAAABMoxE0AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAIABJREFUeJztvXucXVV99//+nMvcZ3IlQ8gFAgQCAR+EQECpRhABa8FbWzCitLapPkKt2loUipTCC9qf2kcf0RoqAkqNVhDzKBSREq0tasJFYAKBJHKZhATIfZK5nMv398fe+8yeM2cuyZkzt/N9v177dfZee6211zpzZn3297tuMjMcx3Ec51BJjHUBHMdxnImNC4njOI5TFi4kjuM4Tlm4kDiO4zhl4ULiOI7jlIULieM4jlMWLiSOM8JIul/Sh8e6HI4zWriQOJMGSS9IevtYl8PMLjSzOyqRt6QWSf9H0kuSOiRtDK9nVuJ5jjMcXEgc5yCQlBrDZ9cADwGLgQuAFuBNwA7gjEPIb8zq4kwuXEicqkDSuyQ9IWm3pP+R9IbYvaskbZK0T9J6Se+J3btc0n9L+mdJO4HrwrBfSvqCpF2SfifpwliaNZL+LJZ+sLgLJP0ifPbPJN0i6TsDVONDwHzgPWa23szyZvaqmf2Dmd0X5meSjo3lf7ukG8LzZZLaJf2tpG3AtyQ9I+ldsfgpSa9LOjW8PjP8vnZL+q2kZeX8HZzJiQuJM+kJG8XbgL8AZgDfAFZLqg2jbAJ+D5gC/D3wHUmzY1ksBTYDs4AbY2EbgJnAPwHflKQBijBY3H8DfhOW6zrgskGq8nbgP8ysY+haD8jhwHTgSGAF8F3g0tj984HXzewxSXOAnwA3hGn+Grhb0mFlPN+ZhLiQONXAnwPfMLNfm1ku7L/oBs4EMLN/N7Ot4Rv+94Dn6esq2mpm/9fMsmbWGYa9aGa3mlkOuAOYDbQO8PyScSXNB04HrjWzHjP7JbB6kHrMAF45pG+glzzweTPrDuvyb8BFkhrC+x8IwwA+CNxnZveF382DwDrgnWWWwZlkuJA41cCRwKdD98xuSbuBecARAJI+FHN77QZOIrAeIl4ukee26MTMDoSnTQM8f6C4RwA7Y2EDPStiB4EIlcNrZtYVK89G4BngD0IxuYheITkS+MOi7+3sESiDM8nwzjanGngZuNHMbiy+IelI4FbgXOARM8tJegKIu6kqtUT2K8B0SQ0xMZk3SPyfATdIajSz/QPEOQA0xK4PB9pj16XqErm3EsD6UFwg+N6+bWZ/PkQ9nCrHLRJnspGWVBc7UgRC8VFJSxXQKOn3JTUDjQSN62sAkv6EwCKpOGb2IoGr6DpJNZLOAv5gkCTfJmjc75a0SFJC0gxJn5MUuZueAD4gKSnpAuCtwyjKKuAdwMfotUYAvkNgqZwf5lcXdtjPPciqOpMcFxJnsnEf0Bk7rjOzdQT9JF8FdgEbgcsBzGw98EXgEWA7cDLw36NY3uXAWQRuqxuA7xH03/TDzLoJOtyfBR4E9hJ01M8Efh1G+wSBGO0O8753qAKY2SsE9X9T+Pwo/GXgYuBzBEL7MvA3eLvhFCHf2Mpxxg+Svgc8a2afH+uyOM5w8TcLxxlDJJ0u6ZjQTXUBgQUwpBXhOOOJigqJpNskvSrp6QHuS9JXwmUenowmQYX3Pizp+fD4cCz8NElPhWm+MsjYfceZCBwOrAE6gK8AHzOzx8e0RI5zkFTUtSXpLQT/IHeaWb8OzLCD8EqCcelLgS+b2VJJ0wk6IZcQdIQ+CpxmZrsk/YbAD/wrAn/4V8zs/opVwnEcxxmUilokZvYLYOcgUS4mEBkzs18BU8MZxecDD5rZTjPbRdCxeEF4r8XMHrFAAe8E3l3JOjiO4ziDM9bzSObQdwJWexg2WHh7ifB+SFpBsAQE9fX1p82bN9jw/PFBPp8nkaiubqtqq3O11Reqr86Tqb7PPffc62Y25JI4Yy0kpfo37BDC+wearQRWAixZssTWrVt3qGUcNdasWcOyZcvGuhijSrXVudrqC9VX58lUX0kvDifeWMtmO31n8s4Ftg4RPrdEuOM4jjNGjLWQrAY+FI7eOhPYE06OegB4h6RpkqYRzLp9ILy3L1zaWgTLav9ozErvOI7jVNa1Jem7wDJgpqR24PNAGsDM/oVg1NU7CWYaHwD+JLy3U9I/AGvDrK43s6jT/mPA7UA9cH94OI7jOGNERYXEzC4d4r4BHx/g3m0Ee0gUh69jlNZCchzHmSxkMhna29vp6urqd6+uro65c+eSTqcPKe+x7mx3HMdxRoH29naam5s56qijiM/jNjN27NhBe3s7CxYsOKS8x7qPxHEcxxkFurq6mDFjBsWLgUhixowZJS2V4eJC4jiOUyUMtKJUuStNuZA4juM4ZeF9JM7wMIN8vvSRzfY90mmorw8+U6ng09fWdJxJiwtJtTKQKORyfUUhkwk+8/lATKC/KCQSQVgiERwHDsC+fUGaKG4kLsUCUyXkLU8un8MwDmQOkMvn6Mn1kM1nAUio1zkQnZcKi5/H3RGKLfoQhZcKi4cPN2w4eToTAzMr+Xcrd/FeF5LJQGQt5HKDi0I22xs2EJEgxIWhri74HC6lBCKXKy0wPT2wbduEtWDMjJzlyOVzgVhYjkwuQyafIZPL0JPrIWc58vk8CHqyPbTvaQcFghCJQql/ZIut/hPdj4f1WRxIvfEKjX2pXecH2ol+kPRD5gmFtaUSMW951GD15Hp4cXew0sZwBVNSr7ihQl7Rd5ZMJBEqXEux81h8p5e6ujp27NjRr8M9GrVVV1d3yHm7kIw3DsaFFAlD3FqIkEqLQk1NIAyjTTIZHKU4GAtmlBoIMysIQ2RNZPPZgkhE1kTOcmBBAy8JjEKjlkwkSSVS1KimtyFMJGiqbRqVOowWcREsJX7QKyp5yxfi5Sw3YPqB3pANwyw4BhPFhBIk6P0bJJQglUgVzqtRiObOnUt7ezuvvfZav3vRPJJDxYWk0gzHfRQd3d3w/PMD51UsCqlUIAzj4Ud/zz1w882wdSsccQRcdRW8971Dp5NKC1s2OzyBiUTmIL6DSBgioYhEoifXQ0+uh0w+QzaXBcXexsPsk0oWGqLaVG2ft+lqZSB3WMGIkUglRrepiV4EDCOTz/S5joSoIP70tboMI5lIFv7WAwlRJDrFYjReSafThzxPZChcSIagK9tV8Csqb8iMhFE4V95QKWthIBeSWWlrIZUKPpsm4NvqPffAZz4DnZ3B9ZYtwTUMT0xKkUoFRzEDCUxNDVZXR642TT6VJJdMkEuKnOV7BSKXIWvZwM0EQUMXvskmEolCg5BOpKlLjYHV5owYkkhqAAt4GBQLUd7yBfHJW35QV2F3tpuNOzf2EaK4GEUiNJAQTUSLyIVkCLZsfoLc/o5AGAwi47vPH1oilUwjJUgkUyQSSRLJJKlUDYGBLRKJBCmlUOyHIiARfkp5CH+kE+6HdNNNvSIS0dkZWCiHKiRFFKwHcuSSefIJoyeXoScfuJqyHd1kd3X3Wn0ShpGoqSVR10Cirp5kTS316VpUM3H6YJyxoRwhSiQS1Kfq+whRd667pBDFraLiPqekkgXLqNgqKnbFFbvnRhsXkiGwjg4a61tQMjlg4xP9QAo/FIys5ejOHAh9vYH45C3f5y24IEihP7g718PGvb/rfUuO+XkT0Y8kvE6SCN6iKX6b6e2cLLzdFIRrBARq5054+ml46qneY+sAK/lv2QLvehcsXgwnnRQcixYFbqkYUV9DzvLkLR/0QeQzgbspnyWby2Cy8HsJBEJAUgmkBEklqKmpp662sX8ZcjnoycKBPX3Do76i2tpe99hBusgcZyBGyiLKW56MDU+I4u65uBC1NrZSm6otu06D4UIyHCIX1AAURpiU2QYltI+mVG9jGP/hBH794A0nnw2sF4vFiZUmSBs2tvFgMwvMbRIoEVhKqURwXRAlAn92ApF49VWST68n2baeRNt6Ek+3oa2v9JZv/nxYvBjt3Al79/arjzU1YXW1aPWP0He+E4Qlk2SPPoruExbStehYGqfP5oWmDPmpLVjeUIKwFME/YkoJalL1hy6AUSd/bdE/UjSKrLjcLjDOOCASoiSHJkaREO3P7Cebz1KLC0nVEgnUSJqqxdZTJpfFLE+yfQs1bRtIrt9Aav0Gap99ntSOXUEaiZ4F8+l+40l0f+DddJ1wHN2LFpKf1gIGzT9+kNbP/xOJru7Cc/J1tWz/u0+y713nYWakt7xC3TMbqXv2eeqeeZ66Xz1K0+r/YGYYPztnNpkTjidz4vFkTlxE5sTjybfOqlwD7gIz+pj1jkqMzqPr4vvx0YiFeUx5yNvA85kOlj7u6fKyAvXml8nAK68MHn3QrFR23QQkgUSuE+paoaaEtT6CuJBUGcrnSf/uRdJtz5JeHx0bSOzrAMBSSbLHHkPPst+j48RFZE88nsyi47DGhkIeSaAhlqe9593sSqaZ8qWvkXxlO7nZrez71BXYRRdSGDqwYCEsWEjXOy8kWhousWMnW/7zVyzc9Srp9RtIP7OBuod+jsKGIjdtaq+wnHA82ROOI3vU/IGHEY8ELjABxQ19/Lr4yOXCPkTrHaYeNfr5PHT3wKZN8czp30s9wCRX6DswZQQa2T51jBeh3DziYYPN1TqYvA6VKK/9u2BWZuTyHQAXkslMT4bUxk3UtD0bCMczG0g9+xyJzqApt9paMosW0vmu84PGevEJZBYe3b8RHQbdF/0+r170+weVJj9jOjtPO5WOow8vhKljP+kNz5MKhSW9/lmabr8LZYJ/zHxDPdnjF/a1Xo47JmjQK8mwBcZA4Xyd2tr+AlMJihv2wRr+gSauRuclG8EhGv6ooY/O4w1/KgkJQWNl34jHFdKYr9pQv/p+mr/0VWa/sh2bMycY+LJ8ecWe50IySVBnJ6lnnw8sjMjaeH5TbwPc2EjmxOM58MfvDRrhxYvIHn1U5Rq3Q8SaGuk57RR6TjulN7AnQ2rT70g/E1hP6fUbqP/RfTT+278HaVJJssccHQpLKC6LFmLNzZUv8MEKTE8GXnutV2CSyb4NPfQ26AM19tF1PM6gxBr++Ft9/EgkgkYfjZ+5Sc4hUb/6fqZccwOJcFl4tbfDihXBzQqJyfhqRZxhob37grf1tqhhfZbU5heC+SxAbuoUMosX0XH5cjKLF5E5cRG5+XMPbpmT8URNOnBrnXAcndFo4nye5MtbCq659PoN1P7XIzT88MeFZNl5cwr9LZEFk5912OiUuZTAmAF7Yf/+vgIzkIN+oEY/etNnhF09zthjBpkM6u5G3T2ouwei855u1BWFd0MUFsaL0jTefldBRAocOABXXz0xhUTSBcCXCdzq/2pmNxfdP5JgO93DgJ3AB82sXdLbgH+ORV0EXGJm90q6HXgrEI3nvNzMnqhkPcaSxI6dfa2M9RtIvdReuJ9rnUVm8SK6zj+XzOJF9CxeRP7w1tFvXHK5YGZ+ONwZJQ5p1vmwSSTIHTmP3JHz6LrwvN7g114vCEtkwdQ/8FBvMWfO6HWLnXDc6IqswpF9Y7FEzQQnctXE++A6L7qwMg/LZoMGuyfWiMcadvWEjXi/e93Q3c2x23fRUp8uNPIUpS2Ehc/ok3d399DlG4IBe1peeqnsvAeiYkIiKQncApwHtANrJa02s/WxaF8A7jSzOySdA9wEXGZmDwOnhPlMBzYCP42l+xsz+0Glyj4mmFH72mvUbe61MtJtz5Lc/mohSnbeHDKLF3Hg/Rf3jmyaOWPsypzNBosuWh5SaZg2LZgjYhaISmdncETikkz1unMqRP6wmXS/dSbdb31zIUz79pGO3H6R9fLIr1E2WOsp39hIZtHCvh37xx4NNdWzOvG4xYz6u1cz5e//kUTYyKa2bmPq5/6e9JNPk3nD4rBhDhvkWMPc29j3bfApxBsgLJcrq8hNqRTU1mK1NVhtTe95TfCZb6iHaVP7hFldLVZbG6zQUFuDFdLXQm0NVtM3zGproCit1dZAOs2sc/6A1NZt/Qs2f35Z9RqMSlokZwAbzWwzgKRVwMVAXEhOBD4Znj8M3Fsin/cD95vZgQqWdXSJ3DJtzxQ6wdNtz3LErt0AWCIRzLVYelrYCR40btYyCj7/wQjNbjLhKJC6Opg5M/gs7uyur4epU3s7bzMZ6OoKTOz9+/vmmc9BonLiYs3N9Jx+Kj2nn9ob2NND+vlNMetlAw13rybx7e8FadIpMguPIXPiIrKLjgtEZtFxWFMVdRqPFGboQCfau5fEnr0k9u4jsWdveL2PxN69KPxM7N4bXofx9u4t9PPFUU+GpjtXlX5cIhE0rjWxRrzQmAdh+ZbmfmGFeGHaQiMehfcJ6xWKSAwI07W9+BqLYwNIRpt9n7qiTx8JAA0NcOONFXtmJYVkDvBy7LodWFoU57fA+wjcX+8BmiXNMLMdsTiXAF8qSnejpGuBh4CrzKx8e7BSZLOkNr/Qx8pIP7OBREfQmEYNVte5b+WlWUcw861nkD1+IdZQP0TGo0Q+H1gduWzgrmpogBkzAt//cDrqoxEs6XSQdvr0IM9MJsh3ewdkspDt6hu/0kNoa2qCUWqLT+gNy+VIvvhyQVjS65+l7qGfk/zBj4BgPk3uyHmxEWOBBZOfMb1y5RwvmKGurt4Gf88+Env2lBaDUAQiMTh8zx4SJcSgkLWEtTSTb2kmP6UFa2khN/tw8lNayLc007Ty9pK9SCbx6gP39L71h2/zk2L4dRlELr/IFWhz5pCo8KgtlbuhyYAZS38InG9mfxZeXwacYWZXxuIcAXwVWAD8gkBUFpvZnvD+bOBJ4Agzy8TCtgE1wEpgk5ldX+L5K4AVAK2traetWlX67WUoug/sIzFMV4x6MjS9+AItGzfRvGkTzRs30bz5dyR7egDI1dayb8EC9h17DHuPPYZ9xxxDx5FHYqELpas7S13tOBn/kA/dURC4ohKJQEhG+P+za38XdY11/Yeo9hmJpN7+hdHGjNodO2jetDn4e27aRMumzdRv316I0jVjBvuOXsC+Y45h37HHsO+Yo+k8/PCSjdmY/o3NSHR3k+7oINXRQbqjg/S+3vNURwfpffv6h4XHUGKQbWwg09xMtqmJTHhkm5rorG+AqS29Yc3NwXlzcD/b0DBoH9XZH7qc+lf7L33eOeswfnnn7SPxzYwo4+n/OJ/Lkq5tIJE8tPK87W1ve9TMlgwVr5JCchZwnZmdH15/FsDMbhogfhPwrJnNjYV9gkBYVgyQZhnw12b2rsHKsmTJElu3bt3BVeCuu+Dqq7GXXirZuacDnaSefY5027PURJ3gz2/s9bs3NYYuqdA1tXhRMJlukLf4ts3bxs4kLu7vaG4OLIja2oq+3bWtbWPx6Yv734jcaNls4BLbvz8oHwTlSSYDy2WMRqJpz97Qaul1jaU2v1Dwr+ebm2Kd+sFn9uijaHt5B4uPPry8zuOuroIVkNi9d1CXUcEyCA9lBp6cZhLW3ES+pYX8lGYs/AyuW7ApLYV7+ZboOrQimpsG/FuU+7suHs4KkK+rY88N11Suw70MRvz/2Cz4vzT6zvcprAoQH/nXdxRgR66TOQtPo7Hl0PpSJQ1LSCopm2uBhZIWAFsIXFQfiEeQNBPYaWZ54LMEI7jiXBqGx9PMNrNXFCy+9G7g6REv+V13BeOuDxxARJ1711O75pcgSLc9S+p3L/bOwJ4+LRg59ZYPBQ3H4kXk5s4Z/8Nte3ogEzbONbWB26m+/pAmJI44Cucz1NT0dYn19AQCE3XkZzMULJbRcImF2JQWes48nZ4zT+8N7Ooi/dymPiPGGlbdXVg6xmpqaDzySGqntVD7+G8Lvv9C5/Hax8gduyAmDkViEIYpEtQByDc3BW6hyE208OheMQgb/nxLc0wYwntNjZVdNeAQKXbVVHzUViWIGvxotn/x5NECA8zyTySCv000sTV+XTzzP4ovQfbAqIwSrJiQmFlW0hXAAwTDf28zszZJ1wPrzGw1sAy4SZIRuLY+HqWXdBQwD/h5UdZ3STqM4Nt+AvjoiBf+6quDTuEY6umh4cf/QXZ2K5kTF9H5++cX5mjkWw+bGD5Zs6AhjmYu19cHI63q6sZ8Ju6wiLb9rasLLCbo7cjv7g7+Zp2dwdsbMatltBrHujoyb1hM5g0xCyubJfXCS4URY9nHnqJl7WOFl5AI9WRo+t49heuCGLQElkHu2KN7G//o6CMGoZXQ3DQuxaBcOi+6cGyFo9TKAcUrCETk8+GAkpgoFBr+JKRqeucZRaIwkBAMsWDseKGijjwzuw+4ryjs2tj5D4CSw3jN7AWCDvvi8HNGtpQlGGC8tUm8+vP7St4btxR3ljc1BUdt7eRocKI3tPgosWhkWTRKrKuLwtyW0XaJpVJkjz2a7LFH03nRO2nbvI23X1jaE2sS23790KQVgzFnSBfREKRSoQAkgqHsccsg2mZCgtc7g6G2cVGY5IyPHqHxxvz58OKL/YJzs1vHoDCHQGFyYD74wbe09LqsJvuPOu4Sa2wMRphFYtrT0+sSy4VWWSLmLhilN7/c7NaS4/xzs1uxqVNGpQwTlmG7iEoQNfrRjqSRMETXA7mIDtYqSIz9WlujjQtJKW68sdBHEpGvq2Pfp64Yw0INQTScFoN0TW9/h6+b1Ncl1tIShPVxie2PTZyk4i6xUuP8x/3vq1JEVkLe+q4fNpAoxF1E6dq+fQUDuYjiYU5FcCEpRTTeepBRW2NOob8jmhxYD7NmTZz+jrFmKJfY/v29LjFiHfkjYNFNis7jwYgvLpkPRSI+CRUofK99hKGu93uOLIXiw8VgXOJCMhDLl8Py5Wx67GfUN05F48ElFO/vIFyae+bM4U8OdAamlEssl+u19Do7Aws1cq0kYlbLITRuY955fDCUWo24T59C0UijSKSj32VqL7S29n5X8VFILgyTAm99xjv5XLAxUD4f/PM1NwcNXTX0d4w1USdqKZdYVxd0Hoi5P8O1xGrSFV3uZUSI3Em5fP8RSKWILIRIIOLWmdS376HUb3LztmCAhzNpcSEZjxQmB1rwDzt1am9nub/BjS1xl9i0aX2HVEdWSya2xtEIusQGJN7PELcYhuxnSAUiGZ27O8k5RFxIxgORfz6fh/0dUDvIYojO+ELq3Qkx2gUw7hKL5rZErqB8uIjlUG6dSAjie5cX3EkldihMpXo7oCOxG8hqcGFwRhgXkrEiWmo96u9oaAjeXo88yvs7JjqlXGLRci+v7g8a8gNDLGYdWQjpdPAyER+ZFC0RE7caHGcM8RZrNCn0d+RKTw5s3+kiMlmJVkBOJWHOnF6XWC5XugParQZnAuGtVqWJ7xyYSsGUKYF/va7OG4tqJnKJOcPinmfu4eZf3szWfVs5ovkIrjr7Kt57wnuHTuiMCi4klaAwOZDALeGTAx3nkLnnmXv4zIOfoTPbCcCWfVv4zIOfAXAxGSe4kIwEpRZD9MmBziBM9jdsMyNnOTK5DPuz+9nZuZNsPksmnyGTywTn0We+9zqTD45srjf82oevLYhIRGe2k2sfvpZkIkk6kSaVSJFOpEkn073X4Xk62Xs/Hh6dJ5VEk+wFL/77mtsyl5vefhPLT67cxlYuJIdK8eTApqZgjsdkWQzRqRhDvWHn8rk+jWs2n6Un39OncS1uiKNGuNAwx+L25Hp60wxwrzi8T4M/wL1CWYruRfn24ZGR/x53de3if//kf49IXjXJmkHFJpVIUZOoIZUcIE4iTSoZxNm7Yy+tHa2DxhlOPn2ePUT54mJY/Pt6ee/LrPh/wZZOlRITF5KDoXgxxPjmTz5yximiM9PJto5tbN+/ne0d29m2fxttm9u4b/t9Jd+wr7z/Sv7y/r/EGGD+xwgi1K+BLG6oihvPhnRDoaEr2bCG99KJdJ/zHVt2MPfIub33ihvOeMNYIr8/+v4fsW1//0UuWxtbWfX+VYML5wBWTikBHTROLK9sLsuBzAGy3aXjdHV3YTutjxCPBpHYdGY6+/2GDmQOcPVDV7uQjCkHDgTD9lPpYBJaQ4P3d1QxmVyG1w68FohEx3a279/OKx2vFM6j8D3de/qlrU3U0p3vHjDvK5de2a+BHvRtdgA3TqmGPe7iSY7i7Pu2tW0sPrXELpjD5Oq3XN3nDRugPlXPNW+5huNmHDcSRRxRinf9NLM+FmEf63EAi7NYDAeLE4lbFGfloytLluulPaW3xxgJXEiGoqUF6pp7O8udSUve8uzq3MW2/dvYtq/Xknil45Veq6JjG68feL3fG19SSWY1zuLwpsM5ZtoxvGnumzi8+XBaG1s5vKn38+UnX+ZPf/unbNm3pd/z5zTP4W/f/LejVd0JQ9R3NFH7lKTA+ksn09RTX/Hn/eS5n5T8fc2fMr9iz3QhGYrp0yFV79bHBGdf976CtTCQJbG9Y3tJN8SM+hm0NgVCcPKskwvnrU2tHN54OIc3Hc70+unDestvVztXnX1VyTfsq86+akTrPJl47wnvnTDCMdaU+n01pBu48dwbK/ZMFxJnQtOd7e7TB1EQiSJLYn+meBlzaK5pprWpldbGVpbOWdrHcojEYlbjLGqSI2uJTvQ3bGd8U/z78lFbTtWSy+d4/cDrhc7qYksiut7Vtatf2tpkbUEgFh+2mHMWnFOwHFqbWguWRGNN4xjULMDfsJ1KEv2+Ono6mNM8p+K/9YoKiaQLgC8DSeBfzezmovtHArcBhwE7gQ+aWXt4Lwc8FUZ9ycwuCsMXAKuA6cBjwGVmVjTW0BlthjsvwszY3bW7IAaPbXuMn/36Z30siW0d23j1wKvkre8+2gklmNUwi9amVuZPmc/pc04vWBCRNdHa1Mq0ummTbl6A44xnKiYkkpLALcB5QDuwVtJqM1sfi/YF4E4zu0PSOcBNwGXhvU4zO6VE1v8I/LOZrZL0L8BHgK9Xqh7O0JSaF/GpBz7FQ5sf4rDGw/oMgd3esZ2uXFffDJ6HaXXTCmKwaOaiguUwu2l2QSAOazhsVEcbOY4zPCppkZwBbDSzzQCSVgEXA3EhORH4ZHj+MHDvYBkqeM08B/hAGHQHcB0uJCOOmbG3ey87Onew48COvp9FYc+8/kw/6yGTz3DvhntpSDeqbHZtAAAe4UlEQVQUBOLU2af2upcaA5HYs3kPZ591NnWpujGqqeM45VJJIZkDvBy7bgeWFsX5LfA+AvfXe4BmSTPMbAdQJ2kdkAVuNrN7gRnAbjPLxvKcU+rhklYAKwBaW1tZs2bNIVWiO9dNQqMz2bBrfxdta9sqkreZ0ZHtYHdmN3syewqf8fP4597MXrKFr7kvDckGpqSnFI5iEYkQ4odLf9jfzZQD9gZHIpdg0+ObRray45hK/o3HK9VW5/FU37zlaU+0V7wNq6SQlHJSF0/Z/Wvgq5IuB34BbCEQDoD5ZrZV0tHAf0p6iqD5GSrPINBsJbASYMmSJbZs2bKDrgDAxp0bqU/Vj4rPvXgi02DkLc/urt3s7NxZsA5eP/A6Ozp3sPPAzn6WQ7TWUSmaa5qZUT+D6Q3TOWb6McxsmFm4nlE/o991sfVwxq1nlBy3fkTzEZx0xkkjVufJQLXVF6qvzuOpvpOhs70dmBe7ngtsjUcws63AewEkNQHvM7M9sXuY2WZJa4A3AncDUyWlQqukX54Tlbzl2ZPZw/M7nh9QFF4/8HrhemfnTnKWK5lXS20L0+uDRn/+lPm88fA39hOFGQ0zCnFqU+UtZ+7zIhynuqmkkKwFFoajrLYAl9DbtwGApJnATjPLA58lGMGFpGnAATPrDuO8GfgnMzNJDwPvJxi59WHgR5Uo/F1P3cXVD13NS3teOqRx/rl8jt1du/uIwo4DgQAUX0fCkLc8/Kp/XlNqpzC9fjozG2Zy1NSjOO2I0wrXxaIwvX562cJwsPi8CMepbiomJGaWlXQF8ADB8N/bzKxN0vXAOjNbDSwDbpJkBK6tj4fJTwC+ISkPJAj6SKJO+r8FVkm6AXgc+OZIl/2up+5ixf9bwYFMsB1qtDrrvp59LJ2ztI+7aCCR2NW5a8DF96bWTmVGQyAAR087miVHLGFGwwwyr2U4adFJgSg0zGBm/Uym108nnRz/S9H7vAjHqV4qOo/EzO4D7isKuzZ2/gPgByXS/Q9w8gB5biYYEVYxrn7o6oKIRHRmO/ncQ58rGX9a3bRAGOpnsHD6QpY2LGVm/cxC2PSG6YXraXXTBhSGtrVtLF40PnyrjuM4w8VntpdgsFUyv/b7X+sjEtPqp5FK+NfoOE714i1gCeZPmc+Le17sFz6neQ4XH3/xGJTIcRxn/OK7MZXgxnNvpCHd0CfMRyE5juOUxoWkBMtPXs7KP1jJkVOORIg5zXP4p/P+yTuTHcdxSuCurQFYfvJylp+8fFQnJDqO40xE3CJxHMdxysKFxHEcxykLFxLHcRynLFxIHMdxnLJwIXEcx3HKwoXEcRzHKQsXEsdxHKcsXEgcx3GcsnAhcRzHccrChcRxHMcpC18ixXEcZxxhFmyIF22MF78uda84XiEfjEwuMypldiFxHGfScrCNcKlGeaAGXQhUiBQgyOfzdHR3lLw3WLroXiIROIoSocMoWucvoQSSgjhKFMKiz1JhQqOy9bYLieM4Y4KZkbc8RvgZNuzRZ97yYEHDLanQ6BZfD9ZAl2qUSza4B9lAR3kFj1ef8y3JLcyfOj8oT1G86HqwexORigqJpAuALxPs2f6vZnZz0f0jgduAw4CdwAfNrF3SKcDXgRYgB9xoZt8L09wOvBXYE2ZzuZk9Ucl6OI7TS9ToRyIQnRfuFb2x5y18Q4d+b95JJUkoQTqRLjTaqUSq8Blv4OMiUNx4Q+mGfSyQRF2qbsyePxZUTEgkJYFbgPOAdmCtpNVmtj4W7QvAnWZ2h6RzgJuAy4ADwIfM7HlJRwCPSnrAzHaH6f4m3O/dcZxhEH/bH8wKCCKHiQZ4048a+LgAxBv/eKMfvaEfNe2ownVcEJzJQSUtkjOAjWa2GUDSKuBiIC4kJwKfDM8fBu4FMLPnoghmtlXSqwRWy24cp4qIu3mKrYDCp1mfRr+U60eIpJJI6tfoR5/REReB+Hl072ARoiZZM7JfjDOuqKSQzAFejl23A0uL4vwWeB+B++s9QLOkGWa2I4og6QygBtgUS3ejpGuBh4CrzKy7+OGSVgArAFpbW1mzZs0hVaI71z1qb09d+7toW9s2Ks8aL1RbnTv3d/L0b57u+/Yv+jT6hfDwuuC6CS2DAf3rccshFj7WdHR0HPL/30Sk2uoLlRWSUr9iK7r+a+Crki4HfgFsAbKFDKTZwLeBD5uFTlj4LLCNQFxWAn8LXN/vQWYrw/ssWbLEli1bdkiVGM0dEtvWtrH49MUVf854YjLUOW95cvkcecsH55YLbsQ6iiOLYNPjm3jD0jeQSqSoSdaUtALinb8TtfM1zpo1azjU/7+JSLXVFyorJO3AvNj1XGBrPIKZbQXeCyCpCXifme0Jr1uAnwDXmNmvYmleCU+7JX2LQIwcZ8QpCENMJEoN/UwpRSqZoi5ZR02yhlQiRSqRIpkIOpKjDmVJvJR8idam1rGtmOOMMJUUkrXAQkkLCCyNS4APxCNImgnsDK2NzxKM4EJSDfBDgo74fy9KM9vMXlHwqvZu4OkK1sGZhJgZOcv1FYiwnyHuUoo6k+tSdQULIupPSCaSfQTCcaqZigmJmWUlXQE8QDD89zYza5N0PbDOzFYDy4CbJBmBa+vjYfI/At4CzAjdXtA7zPcuSYcR/Ns/AXy0UnVwJhZRZ3QkEoaRz+f7dD4bRjKRJJ1IU5OsKRyRMMStCBcIxxkeFZ1HYmb3AfcVhV0bO/8B0G8Yr5l9B/jOAHmeM8LFdMY5cYGILIh8PuwyKzEvoSZZQ2O6kVQiRTqZLlgOkUj40FPHGVl8Zrszthhkcpk+IlE8mzkashq5lqLPuHspEgnHcUYfFxKnIgxnJFN0nlCiTz9E3L3kAuE44x8XEqcszIxMPkM2nyWXzxVGM6UUuJWiPoh0Ih1YEEUjmbYmtzJvyryhH+Q4zrjFhcQ5KLL5bMEVZdZrTUypn0JtqjawKLyj2nGqChcSZ0Dylqcn11MYAYVBTbKGltoW6tP1BUvDRcNxqhsXEgfodVFlcpnCpLt0Ik1DuoGGdAM1qZrCTGzHcZw4LiRVSiYX9Gtk89nCchwN6Qam1E6hLlVHOpkmlfCfh+M4Q+MtRRWQy+eCDvFctjBiqjZZy5TaKQUXVbQ0uOM4zsHiQjLJyFu+YG1Emw2lk2ka0400NDQE/RrJtLuoHMcZMVxIJjBmFoyiymcKS4EkE0ka0g1MT0/vs/yH4zhOpRi2kEg6G1hoZt8K17pqMrPfVa5oTjHR0NtsPluYr1GXqmNa3TTq0/WkE2nSyfRYF9NxnCpjWEIi6fPAEuB44FtAmmAtrDdXrmjVTbGLSoh0Mk1zbTMN6YbCooPer+E4zlgzXIvkPcAbgcegsP1tc8VKVWVEQ2/zlmdf975gE6TQRdWQbqA2VVuYGe44jjPeGK6Q9JiZhcu9I6mxgmWa9Aw0OzyVSDFvyrzCKCrHcZyJwHBbq+9L+gYwVdKfA38K3Fq5Yk0eotnh2Vy2sHHSQLPDN2kTDemGsS6y4zjOQTEsITGzL0g6D9hL0E9yrZk9WNGSTUCKZ4dDsHhhQ7qBhnqfHe44zuRkSCGRlAQeMLO3Ay4eMXx2uOM4zjCExMxykg5ImmJme0ajUOORXD7XZwFDnx3uOI4TMNzX5S7gKUkPAvujQDP7y8ESSboA+DLBnu3/amY3F90/ErgNOAzYCXzQzNrDex8Grgmj3mBmd4ThpwG3A/UE2/h+wsxsmPU4aBJK0NHTQTqZpqmmKVjA0GeHO47jFBiukPwkPIZN6BK7BTgPaAfWSlptZutj0b4A3Glmd0g6B7gJuEzSdCCau2LAo2HaXcDXgRXArwiE5ALg/oMp28Ewt2VuYac+x3Ecpz/D7Wy/Q1INcFwYtMHMMkMkOwPYaGabASStAi4G4kJyIvDJ8Pxh4N7w/HzgQTPbGaZ9ELhA0hqgxcweCcPvBN5NBYWkJllTqawdx3EmBcOd2b4MuAN4gWAQ6zxJHzazXwySbA7wcuy6HVhaFOe3wPsI3F/vAZolzRgg7ZzwaC8RXqrMKwgsF1pbW1mzZs0gRR0fdHR0TIhyjiTVVudqqy9UX52rrb4wfNfWF4F3mNkGAEnHAd8FThskTale5+K+jL8GvirpcuAXwBYgO0ja4eQZBJqtBFYCLFmyxJYtWzZIUccHa9asYSKUcySptjpXW32h+upcbfWF4QtJOhIRADN7TtJQqwO2A/Ni13OBrfEIZrYVeC+ApCbgfWa2R1I7sKwo7Zowz7mD5ek4juOMLsMddrRO0jclLQuPW4FHh0izFlgoaUHYv3IJsDoeQdJMqTD06bMEI7gAHgDeIWmapGnAOwjmsrwC7JN0poJxth8CfjTMOjiO4zgVYLhC8jGgDfhL4BMEHeYfHSyBmWWBKwhE4Rng+2bWJul6SReF0ZYBGyQ9B7QCN4ZpdwL/QCBGa4Hro473sCz/CmwENlHBjnbHcRxnaIbr2koBXzazL0FhaG/tUInM7D6CIbrxsGtj5z8AfjBA2tvotVDi4euAk4ZZbsdxHKfCDNcieYhgAmBEPfCzkS+O4ziOM9EYrpDUmVlHdBGe+zK1juM4zrCFZL+kU6MLSUuAzsoUyXEcx5lIDLeP5K+Af5e0lWDexhHAH1esVI7jOM6EYVCLRNLpkg43s7XAIuB7BBMG/wP43SiUz3EcxxnnDOXa+gbQE56fBXyOYCHGXYSzxh3HcZzqZijXVjI2f+OPgZVmdjdwt6QnKls0x3EcZyIwlEWSlBSJzbnAf8bu+dZ/juM4zpBi8F3g55JeJxil9V8Ako4Fqna3RMdxHKeXQYXEzG6U9BAwG/hpbCfCBHBlpQvnOI7jjH+Gs2f7r0qEPVeZ4jiO4zgTDd903HEcxykLFxLHcRynLFxIHMdxnLJwIXEcx3HKwoXEcRzHKQsXEsdxHKcsXEgcx3GcsqiokEi6QNIGSRslXVXi/nxJD0t6XNKTkt4Zhi+X9ETsyEs6Jby3JswzujerknVwHMdxBqdi62WF+7rfApwHtANrJa02s/WxaNcA3zezr0s6kWB/96PM7C7grjCfk4EfmVl8kcjl4d7tjuM4zhhTSYvkDGCjmW02sx5gFXBxURwDWsLzKcDWEvlcSrDml+M4jjMOUe/yWSOcsfR+4AIz+7Pw+jJgqZldEYszG/gpMA1oBN5uZo8W5bMJuNjMng6v1wAzgBxwN3CDlaiEpBXACoDW1tbTVq1aNeJ1HGk6Ojpoamoa62KMKtVW52qrL1RfnSdTfd/2trc9amZLhopXyaXgVSKsuMG/FLjdzL4o6Szg25JOMrM8gKSlwIFIREKWm9kWSc0EQnIZcGe/B5mtJNx8a8mSJbZs2bKyK1Rp1qxZw0Qo50hSbXWutvpC9dW52uoLlXVttQPzYtdz6e+6+gjwfQAzewSoA2bG7l9CkVvLzLaEn/uAfyNwoTmO4zhjRCWFZC2wUNICSTUEorC6KM5LBBtmIekEAiF5LbxOAH9I0LdCGJaSNDM8TwPvAp7GcRzHGTMq5toys6ykK4AHgCRwm5m1SboeWGdmq4FPA7dK+iSB2+vyWH/HW4B2M9scy7YWeCAUkSTwM+DWStXBcRzHGZqKbpdrZvcRDOmNh10bO18PvHmAtGuAM4vC9gOnjXhBHcdxnEPGZ7Y7juM4ZeFC4jiO45SFC4njOI5TFi4kjuM4Tlm4kDiO4zhl4ULiOI7jlIULieM4jlMWLiSO4zhOWbiQOI7jOGXhQuI4juOUhQuJ4ziOUxYuJI7jOE5ZuJA4juM4ZeFC4jiO45SFC4njOI5TFi4kjuM4Tlm4kDiO4zhl4ULiOI7jlEVFhUTSBZI2SNoo6aoS9+dLeljS45KelPTOMPwoSZ2SngiPf4mlOU3SU2GeX5GkStbBcRzHGZyKCYmkJHALcCFwInCppBOLol0DfN/M3ghcAnwtdm+TmZ0SHh+NhX8dWAEsDI8LKlUHx3EcZ2gqaZGcAWw0s81m1gOsAi4uimNAS3g+Bdg6WIaSZgMtZvaImRlwJ/DukS224ziOczCkKpj3HODl2HU7sLQoznXATyVdCTQCb4/dWyDpcWAvcI2Z/VeYZ3tRnnNKPVzSCgLLhdbWVtasWXPIFRktOjo6JkQ5R5Jqq3O11Reqr87VVl+orJCU6ruwoutLgdvN7IuSzgK+Lekk4BVgvpntkHQacK+kxcPMMwg0WwmsBFiyZIktW7bsEKsxeqxZs4aJUM6RpNrqXG31heqrc7XVFyorJO3AvNj1XPq7rj5C2MdhZo9IqgNmmtmrQHcY/qikTcBxYZ5zh8jTcRzHGUUq2UeyFlgoaYGkGoLO9NVFcV4CzgWQdAJQB7wm6bCwsx5JRxN0qm82s1eAfZLODEdrfQj4UQXr4DiO4wxBxSwSM8tKugJ4AEgCt5lZm6TrgXVmthr4NHCrpE8SuKguNzOT9BbgeklZIAd81Mx2hll/DLgdqAfuDw/HcRxnjKikawszuw+4ryjs2tj5euDNJdLdDdw9QJ7rgJNGtqSO4zjOoeIz2x3HcZyycCFxHMdxysKFxHEcxykLFxLHcRynLFxIHMdxnLJwIXEcx3HKwoXEcRzHKQsXEsdxHKcsXEgcx3GcsnAhcRzHccrChcRxHMcpCxcSx3EcpyxcSBzHcZyycCFxHMdxysKFxHEcxykLFxLHcRynLFxIHMdxnLJwIXEcx3HKoqJCIukCSRskbZR0VYn78yU9LOlxSU9KemcYfp6kRyU9FX6eE0uzJszzifCYVck6OI7jOINTsT3bJSWBW4DzgHZgraTV4T7tEdcA3zezr0s6kWB/96OA14E/MLOtkk4CHgDmxNItD/dudxzHccaYSlokZwAbzWyzmfUAq4CLi+IY0BKeTwG2ApjZ42a2NQxvA+ok1VawrI7jOM4hUkkhmQO8HLtup69VAXAd8EFJ7QTWyJUl8nkf8LiZdcfCvhW6tf5OkkawzI7jOM5BUjHXFlCqgbei60uB283si5LOAr4t6SQzywNIWgz8I/COWJrlZrZFUjNwN3AZcGe/h0srgBUAra2trFmzptz6VJyOjo4JUc6RpNrqXG31heqrc7XVFyorJO3AvNj1XELXVYyPABcAmNkjkuqAmcCrkuYCPwQ+ZGabogRmtiX83Cfp3whcaP2ExMxWAisBlixZYsuWLRuhalWONWvWMBHKOZJUW52rrb5QfXWutvpCZV1ba4GFkhZIqgEuAVYXxXkJOBdA0glAHfCapKnAT4DPmtl/R5ElpSTNDM/TwLuApytYB8dxHGcIKiYkZpYFriAYcfUMweisNknXS7oojPZp4M8l/Rb4LnC5mVmY7ljg74qG+dYCD0h6EngC2ALcWqk6OI7jOENTSdcWZnYfQSd6POza2Pl64M0l0t0A3DBAtqeNZBkdx3Gc8vCZ7Y7jOE5ZuJA4juM4ZeFC4jiO45SFC4njOI5TFi4kjuM4Tlm4kDiO4zhl4ULiOI7jlIULieM4jlMWLiSO4zhOWbiQOI7jOGXhQuI4juOUhQuJ4ziOUxYuJI7jOE5ZuJA4juM4ZeFC4jiO45SFC4njOI5TFi4kjuM4Tlm4kDiO4zhl4ULiOI7jlEVFhUTSBZI2SNoo6aoS9+dLeljS45KelPTO2L3Phuk2SDp/uHk6juM4o0vFhERSErgFuBA4EbhU0olF0a4Bvm9mbwQuAb4Wpj0xvF4MXAB8TVJymHk6juM4o0glLZIzgI1mttnMeoBVwMVFcQxoCc+nAFvD84uBVWbWbWa/AzaG+Q0nT8dxHGcUSVUw7znAy7HrdmBpUZzrgJ9KuhJoBN4eS/urorRzwvOh8gRA0gpgRXjZIWnDQZZ/LJgJvD7WhRhlqq3O1VZfqL46T6b6HjmcSJUUEpUIs6LrS4HbzeyLks4Cvi3ppEHSlrKgivMMAs1WAisPorxjjqR1ZrZkrMsxmlRbnautvlB9da62+kJlhaQdmBe7nkuv6yriIwR9IJjZI5LqCNR8sLRD5ek4juOMIpXsI1kLLJS0QFINQef56qI4LwHnAkg6AagDXgvjXSKpVtICYCHwm2Hm6TiO44wiFbNIzCwr6QrgASAJ3GZmbZKuB9aZ2Wrg08Ctkj5J4KK63MwMaJP0fWA9kAU+bmY5gFJ5VqoOY8CEcsWNENVW52qrL1Rfnautvihotx3HcRzn0PCZ7Y7jOE5ZuJA4juM4ZeFCMopIuk3Sq5KejoVNl/SgpOfDz2lhuCR9JVwK5klJp45dyQ8NSfPCJXCekdQm6RNh+GSuc52k30j6bVjnvw/DF0j6dVjn74WDRQgHlHwvrPOvJR01luU/VMKVJx6X9OPwerLX9wVJT0l6QtK6MGzS/q6HwoVkdLmdcLhzjKuAh8xsIfBQeA3BMjALw2MF8PVRKuNIkgU+bWYnAGcCHw+XtJnMde4GzjGz/wWcAlwg6UzgH4F/Duu8i2DoO+HnLjM7FvjnMN5E5BPAM7HryV5fgLeZ2SmxOSOT+Xc9OGbmxygewFHA07HrDcDs8Hw2sCE8/wZwaal4E/UAfgScVy11BhqAxwhWX3gdSIXhZwEPhOcPAGeF56kwnsa67AdZz7kEDec5wI8JJhRP2vqGZX8BmFkUVhW/61KHWyRjT6uZvQIQfs4Kw0stMTOHCUrowngj8GsmeZ1DN88TwKvAg8AmYLeZZcMo8XoV6hze3wPMGN0Sl83/AT4D5MPrGUzu+kIwXeGnkh4Nl2OCSf67HoxKzmx3ymM4S8xMCCQ1AXcDf2Vme6VSVQuilgibcHW2YM7TKZKmAj8ETigVLfyc0HWW9C7gVTN7VNKyKLhE1ElR3xhvNrOtkmYBD0p6dpC4k6XOA+IWydizXdJsgPDz1TB8OEvMjHskpQlE5C4zuycMntR1jjCz3cAagv6hqZKiF7d4vQp1Du9PAXaObknL4s3ARZJeIFiN+xwCC2Wy1hcAM9safr5K8LJwBlXyuy6FC8nYsxr4cHj+YYJ+hCj8Q+GIjzOBPZHZPFFQYHp8E3jGzL4UuzWZ63xYaIkgqZ5gRetngIeB94fRiuscfRfvB/7TQkf6RMDMPmtmc83sKIIli/7TzJYzSesLIKlRUnN0DrwDeJpJ/LsekrHupKmmA/gu8AqQIXhL+QiBf/gh4Pnwc3oYVwSbeG0CngKWjHX5D6G+ZxOY8E8CT4THOyd5nd8APB7W+Wng2jD8aIL14jYC/w7UhuF14fXG8P7RY12HMuq+DPjxZK9vWLffhkcbcHUYPml/10MdvkSK4ziOUxbu2nIcx3HKwoXEcRzHKQsXEsdxHKcsXEgcx3GcsnAhcRzHccrChcSZFEiaEa7E+oSkbZK2xK5rhpnHtyQdP0Scj0taPjKlHh9I+qWkU8a6HM7ExYf/OpMOSdcBHWb2haJwEfzm8yUTVimSfglcYWZPjHVZnImJWyTOpEbSsZKelvQvBCvxzpa0UtK6cL+Qa2NxfynpFEkpSbsl3RzuK/JIuKYSkm6Q9Fex+Dcr2H9kg6Q3heGNku4O0343fFa/N35Jp0v6ebjw3/2SWiWlw+uzwzj/n3r3NPl7SWuj+oTCGJXjS5L+S9J6SUsk/VDBvhjXxb6HNknfVrCPxvfDmffFZbowrO9jCvYNaYyVY72C/TQm8tLvTgVwIXGqgROBb5rZG81sC3CVBXtI/C/gPAV7pBQzBfi5BfuKPAL86QB5y8zOAP4GiETpSmBbmPZmglWP+yaSaoEvA+8zs9OA7wD/YGYZ4E+AlZLeQbB21Q1hsi+b2enAyWH54nvbdJrZ7xEsSXMv8NEw3opoyZbwe7jFzE4GuoC/KCrTLII9NM41s1MJZud/QlIrwYoEi83sDcBNA3wXTpXiQuJUA5vMbG3s+lJJjxFYKCcQNLDFdJrZ/eH5owT7yJTinhJxziZYwBAzi5bRKOYEYDHwMwVLzl9FuLCfmT0Zpv8R8CehuACcK+k3BEtzvDVMH7E6/HwKeMrMtptZF8G+GXPDe78zs1+F598JyxnnTQTfxf+EZVoe1mknwRLxt0p6D7B/gO/CqVJ8GXmnGig0fJIWEuzmd4aZ7Zb0HYL1n4rpiZ3nGPh/pbtEnAHXyY8h4MnQiijFSQR7dUQutQbgq8CpZrZF0g1F5Y7KkY+dR9dRuYo7RIuvBfyHmV3Wr7DSEoJNyS4BPkawUKHjAG6RONVHC7AP2Bsu9X1+BZ7xS+CPACSdTGmLZz0wR9IZYbwaSYvD8z8GmggWQbxFUgtQTyAKr4crz77vEMq1QNLp4fmlYTnj/A/wVklHh+VolLQwfF6Lmf0Y+CQlXHVOdeMWiVNtPEbQiD8NbAb+uwLP+L/AnZKeDJ/3NIF1UcDMuiW9H/hK2FCngC9Keo2gT2RZaHl8g2Dv849IuiPM60WCnSYPljbgzyV9E3gWWFlUpu2SPgJ8LzZk+nNAJ3BP2K+TAD51CM92JjE+/NdxRhgFGzalzKwrdKX9FFhovVvPjkWZjgV+YGY+X8QZcdwicZyRpwl4KBQUAX8xliLiOJXGLRLHcRynLLyz3XEcxykLFxLHcRynLFxIHMdxnLJwIXEcx3HKwoXEcRzHKYv/H8lXgVjV4okWAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall Accuracy=64.28571428571429 \n",
      "[[97  4]\n",
      " [ 3 36]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           2       0.97      0.96      0.97       101\n",
      "           4       0.90      0.92      0.91        39\n",
      "\n",
      "   micro avg       0.95      0.95      0.95       140\n",
      "   macro avg       0.94      0.94      0.94       140\n",
      "weighted avg       0.95      0.95      0.95       140\n",
      "\n",
      "35.71428571428571\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x504 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No handles with labels found to put in legend.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x504 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%run group9_test.ipynb\n",
    "\n",
    "import ipywidgets as wg\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "clump_thickness=wg.IntSlider(value=0,min=0,max=10,step=1,description=\"Clump Thickness: \")\n",
    "size_uniformity=wg.IntSlider(value=0,min=0,max=10,step=1,description=\"Size Uniformity: \")\n",
    "shape_uniformity=wg.IntSlider(value=0,min=0,max=10,step=1,description=\"Shape Uniformity: \")\n",
    "marginal_adhesion=wg.IntSlider(value=0,min=0,max=10,step=1,description=\"Marginal Adhesion: \")\n",
    "epithelial_size=wg.IntSlider(value=0,min=0,max=10,step=1,description=\"Epithelial Size: \")\n",
    "bare_nucleoli=wg.IntSlider(value=0,min=0,max=10,step=1,description=\"Bare Nucleoli: \")\n",
    "bland_chromatin=wg.IntSlider(value=0,min=0,max=10,step=1,description=\"Bland Chromatin: \")\n",
    "normal_nucleoli=wg.IntSlider(value=0,min=0,max=10,step=1,description=\"Normal Nucleoli: \")\n",
    "mitoses=wg.IntSlider(value=0,min=0,max=10,step=1,description=\"Mitoses: \")\n",
    "resetB=wg.Button(description=\"RESET\")\n",
    "nnbutton = wg.Button(description=\"Neural Networks\")\n",
    "nnbutton.style.button_color='pink'\n",
    "svmbutton = wg.Button(description=\"Support Vector Machines\")\n",
    "svmbutton.style.button_color='pink'\n",
    "lrbutton = wg.Button(description=\"Logistic Regression\")\n",
    "lrbutton.style.button_color='pink'\n",
    "readbutton = wg.Button(description=\"Read File\")\n",
    "readbutton.style.button_color='pink'\n",
    "input_text = wg.Text()\n",
    "inputT = wg.Text()\n",
    "file=open(\"bg4-02.jpeg\", \"rb\")\n",
    "image=file.read()\n",
    "file2=open(\"p2.jpeg\", \"rb\")\n",
    "image2=file2.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os,io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "logo=wg.Image(value=image,format='jpeg',width=600,height=200)\n",
    "cred=wg.Image(value=image2,format='jpeg',width=400,height=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipywidgets import Layout, Button, VBox, HBox, Box, FloatText, Textarea, Dropdown, Label, IntSlider\n",
    "window = Layout(\n",
    "    display='flex',\n",
    "    flex_flow='row',\n",
    "    justify_content='space-between'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "windowItems = [logo,HBox([VBox([Label(value='Edit the int sliders below:'),clump_thickness,size_uniformity,shape_uniformity,marginal_adhesion,epithelial_size,\n",
    "               bare_nucleoli,bland_chromatin,normal_nucleoli,mitoses]),\n",
    "                          VBox([Label(value='Click on the Machine Learning Algorithm of your choice to get a prediction:'),nnbutton,svmbutton,lrbutton,Label(value='Read in a text file: Enter the file name and click on \"Read file\" button to get a prediction.'),input_text,readbutton,cred])])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "windowShow = Box(windowItems, layout=Layout(\n",
    "    display='flex',\n",
    "    flex_flow='column',\n",
    "    border='solid 2px',\n",
    "    align_items='center',\n",
    "    width='90%', height='70',\n",
    "    justifycontent='space-around',\n",
    "    flexwrap='wrap-reverse', align_content='flex-start'\n",
    "))\n",
    "#print(Xnew)\n",
    "# make a prediction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read(b):\n",
    "    fileName=str(input_text.value)\n",
    "    try:\n",
    "        with open(fileName) as f:\n",
    "            lines=f.readlines()\n",
    "        for line in lines:\n",
    "            #a,b,c,d,e,f,g,h,i = np.loadtxt(line,delimiter=\",\",usecols=(0,1,2,3,4,5,6,7,8),unpack=True)#,unpack=True)\n",
    "            a,b,c,d,e,f,g,h,i = np.fromstring(line,sep=\",\",dtype=int)#,unpack=True)\n",
    "            Xnew = [[0,0,0,0,0,0,0,0,0]]\n",
    "            Xnew[0][0]=a\n",
    "            Xnew[0][1]=b\n",
    "            Xnew[0][2]=c\n",
    "            Xnew[0][3]=d\n",
    "            Xnew[0][4]=e\n",
    "            Xnew[0][5]=f\n",
    "            Xnew[0][6]=g\n",
    "            Xnew[0][7]=h\n",
    "            Xnew[0][8]=i\n",
    "            #print(Xnew)\n",
    "            ynewnn = mlp.predict(Xnew)\n",
    "            if(ynewnn[0]==4):\n",
    "                print(\"Neural Network Prediction: Benign\")\n",
    "            else:\n",
    "                print(\"Neural Network Prediction: Malignant\")\n",
    "            ynewsvm = classifier.predict(Xnew)\n",
    "            if(ynewsvm[0]==4):\n",
    "                print(\"Support Vector Machine Prediction: Benign\")\n",
    "            else:\n",
    "                print(\"Support Vector Machine Prediction: Malignant\")\n",
    "            ynewlr = logistic_model.predict(Xnew)\n",
    "            if(ynewlr[0]==4):\n",
    "                print(\"Logistic Regressionn Prediction: Benign\")\n",
    "                print(\"-------------------------------------------------------\")\n",
    "            else:\n",
    "                print(\"Logistic Regressionn Prediction: Malignant\")\n",
    "                print(\"-------------------------------------------------------\")\n",
    "    except FileNotFoundError:\n",
    "        print(\"File Not Found: Incorrect file name or wrong path\")\n",
    "    \n",
    "def nnPrediction(b):\n",
    "    Xnew = [[0,0,0,0,0,0,0,0,0]]\n",
    "    Xnew[0][0]=clump_thickness.value\n",
    "    Xnew[0][1]=size_uniformity.value\n",
    "    Xnew[0][2]=shape_uniformity.value\n",
    "    Xnew[0][3]=marginal_adhesion.value\n",
    "    Xnew[0][4]=epithelial_size.value\n",
    "    Xnew[0][5]=bare_nucleoli.value\n",
    "    Xnew[0][6]=bland_chromatin.value\n",
    "    Xnew[0][7]=normal_nucleoli.value\n",
    "    Xnew[0][8]=mitoses.value\n",
    "    ynew = mlp.predict(Xnew)\n",
    "    #print(\"X=%s, Predicted=%s\" % (Xnew[0], ynew[0]))\n",
    "    #print(ynew[0])\n",
    "    if(ynew[0]==4):\n",
    "        print(\"Neural Network Prediction: Benign\")\n",
    "        print(\"-------------------------------------------------------\")\n",
    "    elif (ynew[0]==2):\n",
    "        print(\"Neural Network Prediction: Malignant\")\n",
    "        print(\"-------------------------------------------------------\")\n",
    "\n",
    "def lrPrediction(b):\n",
    "    Xnew = [[0,0,0,0,0,0,0,0,0]]\n",
    "    Xnew[0][0]=clump_thickness.value\n",
    "    Xnew[0][1]=size_uniformity.value\n",
    "    Xnew[0][2]=shape_uniformity.value\n",
    "    Xnew[0][3]=marginal_adhesion.value\n",
    "    Xnew[0][4]=epithelial_size.value\n",
    "    Xnew[0][5]=bare_nucleoli.value\n",
    "    Xnew[0][6]=bland_chromatin.value\n",
    "    Xnew[0][7]=normal_nucleoli.value\n",
    "    Xnew[0][8]=mitoses.value\n",
    "    ynew = logistic_model.predict(Xnew)\n",
    "    #print(\"X=%s, Predicted=%s\" % (Xnew[0], ynew[0]))\n",
    "    #print(ynew[0])\n",
    "    if(ynew[0]==4):\n",
    "        print(\"Logistic Regressionn Prediction: Benign\")\n",
    "        print(\"-------------------------------------------------------\")\n",
    "    elif (ynew[0]==2):\n",
    "        print(\"Logistic Regressionn Prediction: Malignant\")\n",
    "        print(\"-------------------------------------------------------\")\n",
    "        \n",
    "def svmPrediction(b):\n",
    "    Xnew = [[0,0,0,0,0,0,0,0,0]]\n",
    "    Xnew[0][0]=clump_thickness.value\n",
    "    Xnew[0][1]=size_uniformity.value\n",
    "    Xnew[0][2]=shape_uniformity.value\n",
    "    Xnew[0][3]=marginal_adhesion.value\n",
    "    Xnew[0][4]=epithelial_size.value\n",
    "    Xnew[0][5]=bare_nucleoli.value\n",
    "    Xnew[0][6]=bland_chromatin.value\n",
    "    Xnew[0][7]=normal_nucleoli.value\n",
    "    Xnew[0][8]=mitoses.value\n",
    "    ynew = classifier.predict(Xnew)\n",
    "    #print(\"X=%s, Predicted=%s\" % (Xnew[0], ynew[0]))\n",
    "    #print(ynew[0])\n",
    "    if(ynew[0]==4):\n",
    "        print(\"Support Vector Machine Prediction: Benign\")\n",
    "        print(\"-------------------------------------------------------\")\n",
    "    elif (ynew[0]==2):\n",
    "        print(\"Support Vector Machine Prediction: Malignant\")\n",
    "        print(\"-------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "nnbutton.on_click(nnPrediction)\n",
    "lrbutton.on_click(lrPrediction)\n",
    "svmbutton.on_click(svmPrediction)\n",
    "readbutton.on_click(read)\n",
    "inputT.on_submit(input_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ff72284d53748899c136d666171ab12",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Box(children=(Image(value=b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x01\\x01\\x01\\x00H\\x00H\\x00\\x00\\xff\\xe1\\x01nExif\\x0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "windowShow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
